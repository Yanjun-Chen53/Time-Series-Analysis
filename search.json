[
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "Data Visulization",
    "section": "",
    "text": "Code\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(tidyverse) \nlibrary(dplyr)"
  },
  {
    "objectID": "visualization.html#long-run-evolution-of-power-generation-mix",
    "href": "visualization.html#long-run-evolution-of-power-generation-mix",
    "title": "Data Visulization",
    "section": "Long-Run Evolution of Power Generation Mix",
    "text": "Long-Run Evolution of Power Generation Mix\nThe data, sourced from the International Energy Agency (IEA), highlights a clear structural shift in the global energy system. While fossil fuels and hydro power historically dominated capacity additions, the past two decades have been characterized by the rapid acceleration of solar and wind energy. In particular, solar capacity has exhibited exponential growth since the early 2010s, outpacing all other sources, while wind energy has demonstrated steady, sustained expansion. By contrast, hydro capacity additions have remained relatively stable, reflecting geographical and environmental constraints. Nuclear additions appear limited in scale, indicating stagnation compared to renewables. Overall, the figure underscores the transition towards low-carbon energy systems, with solar and wind emerging as the primary drivers of global renewable capacity growth.\n\n\nCode\ndata &lt;- read.csv(\"data/renewable-capacity.csv\")\np &lt;- ggplot(data, aes(x = Year, y = Capacity, color = Entity)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Global Renewable Energy Capacity by Source\",\n    subtitle = \"Comparison across Solar, Wind, Hydro, etc.\",\n    x = \"Year\",\n    y = \"Capacity (GW)\",\n    color = \"Energy Source\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\ninteractive_plot &lt;- ggplotly(p, tooltip = c(\"x\", \"y\", \"Entity\"))\ninteractive_plot\n\n\n\n\n\n\n\n\nCode\ndf &lt;- read.csv(\"data/electric.csv\")\ndf &lt;- df %&gt;%\n  mutate(\n    Description = str_extract(Description, \"(?&lt;=From ).*?(?=,)\"),\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))\n\ndf_clean &lt;- df %&gt;%\n  mutate(\n    source = case_when(\n      Description == \"Coal\" ~ \"coal\",\n      Description == \"Natural Gas\" ~ \"natural_gas\",\n      Description == \"Conventional Hydroelectric Power\" ~ \"hydro\",\n      Description == \"Wind\" ~ \"wind\",\n      Description == \"Solar\" ~ \"solar\",\n      Description == \"Nuclear Electric Power\" ~ \"nuclear\",\n      TRUE ~ NA_character_\n    )\n  ) %&gt;%\n  filter(!is.na(source))\n\ndf_wide &lt;- df_clean %&gt;%\n  select(Date, source, Value) %&gt;%\n  pivot_wider(names_from = source, values_from = Value)\n\ndf_wide &lt;- df_wide %&gt;%\n  arrange(Date)\n\ndf_wide_clean &lt;- df_wide %&gt;%\n  mutate(\n    Year = year(Date),\n    Month = month(Date),\n    coal = parse_number(coal),\n    natural_gas = parse_number(natural_gas),\n    nuclear = parse_number(nuclear),\n    hydro = parse_number(hydro),\n    solar = parse_number(solar),\n    wind = parse_number(wind)\n  )\n\n\n\n\nCode\nlibrary(tidyr)\n\ndf_long &lt;- df_wide_clean %&gt;%\n  pivot_longer(\n    cols = coal:wind,\n    names_to = \"Energy\",\n    values_to = \"Value\"\n  )\n\nlibrary(ggplot2)\nlibrary(scales)\n\ndf_yearly &lt;- df_long %&gt;%\n  group_by(Year, Energy) %&gt;%\n  summarise(Value = sum(Value, na.rm = TRUE), .groups = \"drop\")\ndf_yearly &lt;- df_yearly %&gt;% filter(Year &lt; 2025)\nggplot(df_yearly, aes(x = Year, y = Value, color = Energy)) +\n  geom_line(linewidth = 1.2) +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Long-Run Evolution of U.S. Electricity Generation\",\n    subtitle = \"Annual generation by energy source (Million kWh)\",\n    x = \"Year\",\n    y = \"Generation (Million kWh)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf_share &lt;- df_yearly %&gt;%\n  group_by(Year) %&gt;%\n  mutate(Share = Value / sum(Value))\n\nggplot(df_share, aes(x = Year, y = Share, fill = Energy)) +\n  geom_area(alpha = 0.9) +\n  scale_y_continuous(labels = percent) +\n  labs(\n    title = \"Electricity Generation Mix Over Time\",\n    subtitle = \"Share of total U.S. electricity generation\",\n    x = \"Year\",\n    y = \"Share\"\n  ) +\n  theme_minimal(base_size = 14)"
  },
  {
    "objectID": "visualization.html#seasonality-climate-drivers",
    "href": "visualization.html#seasonality-climate-drivers",
    "title": "Data Visulization",
    "section": "Seasonality & Climate Drivers",
    "text": "Seasonality & Climate Drivers\nThe graph shows a positive correlation between wind power generation and temperature anomalies, due to the long-term upward trend of both. As global warming intensifies, temperature anomalies are gradually increasing; simultaneously, wind power generation is also showing a continuous upward trend due to renewable energy policies and sustained growth in installed capacity. Therefore, this correlation primarily reflects a shared temporal trend and should not be interpreted as a direct driver of wind power output by temperature anomalies.\n\n\nCode\ndf &lt;- read.csv(\"data/Global_Temperature_2000onwards.csv\")\ndf &lt;- df[order(df$Year, df$Month), ]\ndf_temp &lt;- df %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nselected_energies &lt;- c(\"coal\", \"natural_gas\", \"solar\", \"wind\")\n\ndf_energy &lt;- df_wide_clean %&gt;%\n  select(Date, all_of(selected_energies))\n\ndf_combined &lt;- df_energy %&gt;%\n  left_join(df_temp %&gt;% select(Date, Monthly_Anomaly), by = \"Date\")\n\ndf_long &lt;- df_combined %&gt;%\n  pivot_longer(cols = all_of(selected_energies),\n               names_to = \"Energy\",\n               values_to = \"Generation\")\n\nggplot(df_combined, aes(x = Monthly_Anomaly, y = solar)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Solar Generation vs Temperature Anomaly\",\n    x = \"Temperature Anomaly (°C)\",\n    y = \"Solar Generation (Million kWh)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df_combined, aes(x = Monthly_Anomaly, y = wind)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Wind Generation vs Temperature Anomaly\",\n    x = \"Temperature Anomaly (°C)\",\n    y = \"Wind Generation (Million kWh)\"\n  ) +\n  theme_minimal(base_size = 14)"
  },
  {
    "objectID": "visualization.html#linkages-and-causality-in-energy-prices",
    "href": "visualization.html#linkages-and-causality-in-energy-prices",
    "title": "Data Visulization",
    "section": "Linkages and Causality in Energy Prices",
    "text": "Linkages and Causality in Energy Prices\nFrom the figure, one can observe several key patterns. Periods of sharp volatility in oil prices—such as the downturn around 2008 and the collapse in early 2020—are mirrored by fluctuations in energy-sector equities, though the magnitude and persistence of these responses differ across renewable and traditional ETFs. Notably, while XLE tends to correlate more closely with oil price movements, ICLN demonstrates partial decoupling, reflecting the structural shift toward renewable energy sources whose valuation drivers are less directly dependent on crude oil prices.\n\n\nCode\nwti &lt;- read.csv(\"data/WTIprice.csv\")\n\nwti &lt;- wti %&gt;%\n  rename(date = observation_date) %&gt;%\n  mutate(date = as.Date(date)) %&gt;%\n  rename(WTI = POILWTIUSDM) %&gt;%\n  filter(!is.na(WTI))\n\ndf_n &lt;- read.csv(\"data/naturalgasprice.csv\")\ndf_n &lt;- df_n %&gt;%\n  mutate(\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Value = as.numeric(Value)) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))%&gt;%\n  arrange(Date)\n\nfig &lt;- plot_ly() %&gt;%\n  \n  add_lines(data = wti, x = ~date, y = ~WTI,\n            name = \"WTI Crude Oil\", yaxis = \"y1\",\n            line = list(color = \"green\")) %&gt;%\n  \n  add_lines(data = df_n, x = ~Date, y = ~Value,\n            name = \"Natural gas price\", yaxis = \"y1\",\n            line = list(color = \"blue\")) %&gt;%\n  \n  layout(\n    title = \"WTI crude oil vs Henry Hub natural gas\",\n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"Price (USD)\"),\n    legend = list(x = 0.05, y = 0.95)\n  )\n\nfig"
  },
  {
    "objectID": "visualization.html#financial-dynamics-of-clean-energy-assets-return-volatility-behavior",
    "href": "visualization.html#financial-dynamics-of-clean-energy-assets-return-volatility-behavior",
    "title": "Data Visulization",
    "section": "Financial Dynamics of Clean Energy Assets (Return & Volatility Behavior)",
    "text": "Financial Dynamics of Clean Energy Assets (Return & Volatility Behavior)\nFrom the figure, one can observe several key patterns. Periods of sharp volatility in oil prices—such as the downturn around 2008 and the collapse in early 2020—are mirrored by fluctuations in energy-sector equities, though the magnitude and persistence of these responses differ across renewable and traditional ETFs. Notably, while XLE tends to correlate more closely with oil price movements, ICLN demonstrates partial decoupling, reflecting the structural shift toward renewable energy sources whose valuation drivers are less directly dependent on crude oil prices.\n\n\nCode\nlibrary(plotly)\n\netf_symbols &lt;- c(\"ICLN\", \"XLE\")\n\netf_data &lt;- tq_get(etf_symbols,\n                   from = \"2005-01-01\",\n                   to = Sys.Date(),\n                   get = \"stock.prices\")\n\netf_data &lt;- etf_data %&gt;%\n  select(symbol, date, adjusted)\n\nfig &lt;- plot_ly() %&gt;%\n  # ICLN\n  add_lines(data = subset(etf_data, symbol == \"ICLN\"),\n            x = ~date, y = ~adjusted,\n            name = \"ICLN (Renewable ETF)\",\n            line = list(color = \"green\")) %&gt;%\n  \n  # XLE\n  add_lines(data = subset(etf_data, symbol == \"XLE\"),\n            x = ~date, y = ~adjusted,\n            name = \"XLE (Energy ETF)\",\n            line = list(color = \"blue\")) %&gt;%\n  \n  layout(\n    title = \"Clean energy (ICLN) vs traditional energy (XLE)\",\n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"ETF Price (USD)\"),\n    legend = list(x = 0.05, y = 0.95)\n  )\n\nfig"
  },
  {
    "objectID": "source.html",
    "href": "source.html",
    "title": "Data Souces",
    "section": "",
    "text": "The International Energy Agency (IEA) provides comprehensive, high-quality datasets on global energy production and consumption. Specifically, their renewable energy statistics track solar, wind, hydro, and bioenergy generation across different countries and regions. This dataset enables analysis of seasonality, structural growth, and geographic distribution of renewable adoption over time. The data is primarily available in annual and monthly time-series formats and is widely used in policy and academic research. For this project, we will focus on renewable generation from 1990 to the present. Data can be accessed through the IEA Data Browser"
  },
  {
    "objectID": "source.html#data-source-1-international-energy-agency-iea",
    "href": "source.html#data-source-1-international-energy-agency-iea",
    "title": "Data Souces",
    "section": "",
    "text": "The International Energy Agency (IEA) provides comprehensive, high-quality datasets on global energy production and consumption. Specifically, their renewable energy statistics track solar, wind, hydro, and bioenergy generation across different countries and regions. This dataset enables analysis of seasonality, structural growth, and geographic distribution of renewable adoption over time. The data is primarily available in annual and monthly time-series formats and is widely used in policy and academic research. For this project, we will focus on renewable generation from 1990 to the present. Data can be accessed through the IEA Data Browser"
  },
  {
    "objectID": "source.html#data-source-2-u.s.-energy-information-administration-eia",
    "href": "source.html#data-source-2-u.s.-energy-information-administration-eia",
    "title": "Data Souces",
    "section": "Data Source 2 – U.S. Energy Information Administration (EIA)",
    "text": "Data Source 2 – U.S. Energy Information Administration (EIA)\n\n\n\n\n\nThe U.S. Energy Information Administration (EIA) publishes official statistics on global energy markets, including fossil fuel consumption, production, and pricing. This dataset includes historical oil prices (e.g., Brent crude), natural gas benchmarks, and coal usage, which provide insight into the decline of fossil fuels and volatility in energy markets. The data is updated regularly and made available via the EIA Open Data API, which allows time-series extraction of daily, monthly, and annual series. For this project, fossil fuel consumption and pricing trends from 1980 onward will be analyzed to compare against renewable energy adoption."
  },
  {
    "objectID": "source.html#data-source-3-yahoo-finance",
    "href": "source.html#data-source-3-yahoo-finance",
    "title": "Data Souces",
    "section": "Data Source 3 – Yahoo Finance",
    "text": "Data Source 3 – Yahoo Finance\n\n\n\n\n\nYahoo Finance provides historical financial market data, including stock prices, indices, and exchange rates. For this project, we will collect stock price information for major clean energy companies (e.g., NextEra Energy, Tesla, Ørsted, Enphase) and fossil fuel companies (e.g., ExxonMobil, Chevron). This allows us to compare market valuation trends and volatility between renewable and traditional energy firms. We will also track clean energy ETFs (e.g., ICLN, TAN) to measure sector-level performance. You can find the data at Yahoo Finance"
  },
  {
    "objectID": "source.html#data-source-4-federal-reserve-economic-data-fred",
    "href": "source.html#data-source-4-federal-reserve-economic-data-fred",
    "title": "Data Souces",
    "section": "Data Source 4 – Federal Reserve Economic Data (FRED)",
    "text": "Data Source 4 – Federal Reserve Economic Data (FRED)\n\n\n\n\n\nFRED, maintained by the Federal Reserve Bank of St. Louis, provides macroeconomic time-series data such as energy consumption, electricity generation, and commodity prices. For this project, we will extract U.S. time-series on renewable electricity production, natural gas prices, and West Texas Intermediate (WTI) crude oil prices. This dataset will be used to study energy price cycles, structural breaks, and relationships between fossil fuel prices and renewable adoption. You can find the data at FRED API"
  },
  {
    "objectID": "source.html#data-source-5-world-bank-carbon-pricing-dashboard",
    "href": "source.html#data-source-5-world-bank-carbon-pricing-dashboard",
    "title": "Data Souces",
    "section": "Data Source 5 – World Bank Carbon Pricing Dashboard",
    "text": "Data Source 5 – World Bank Carbon Pricing Dashboard\n\n\n\n\n\nThe World Bank Carbon Pricing Dashboard provides global data on carbon taxes and emissions trading systems. These time-series are valuable for analyzing policy shocks and their impact on renewable adoption and energy investment flows. For example, we can test whether countries that introduced carbon pricing mechanisms show faster growth in renewable energy capacity. Data is freely available from the World Bank."
  },
  {
    "objectID": "multivariate.html",
    "href": "multivariate.html",
    "title": "ARIMAX, SARIMAX, and VAR",
    "section": "",
    "text": "Energy transition is both a result of technological evolution and a dynamic process driven by the combined effects of economics, climate, and policy. Numerous studies have shown that fossil fuel prices (such as crude oil and natural gas) have a significant impact on the development of renewable energy: when oil or natural gas prices rise, the relative cost of fossil fuels increases, enhancing the relative competitiveness of clean energy, thereby driving growth in renewable power generation or related investment. Simultaneously, climate and weather variables (temperature, irradiance, degree-days) directly affect the short-term output of renewable power generation: solar power is affected by solar irradiance and temperature (high temperatures may slightly reduce photovoltaic efficiency), while wind power is affected by seasonal wind speeds and extreme weather. Finally, policy (subsidies, feed-in tariffs, carbon prices) is a structural driver: policy shocks typically produce lasting trend changes or step responses.\n\n\n\nLiterature divides price transmission into supply-side and demand-side mechanisms: Price increases make renewable energy more attractive by raising the cost of fossil fuel power generation (or the marginal cost of fuel power generation) (substitution effect); another channel is the financial market: oil and gas prices affect the earnings and stock performance of related energy companies, which in turn affects ETFs or capital flows (ICLE, XLE, etc.). These financial variables then feed back into investment and project construction decisions.\n\n\n\nIn empirical methods, researchers widely use ARIMAX/SARIMAX (modeling a single response variable under exogenous shocks) to characterize the short-term impact of exogenous variables such as weather/prices on power generation or prices; while VAR/VECM/VARMA are used to study the dynamic interactions between several endogenous variables (e.g., how wind, solar, natural gas, and coal power generation interact), and to conduct impact response analysis (IRFs) and variance decomposition to identify shock sources and propagation paths. Model selection typically considers the seasonality, trend, and cointegration of time series data.\n\n\n\nETFs (such as clean energy ETFs vs. traditional energy ETFs) are often used as market signals for the energy transition. Empirical research shows that energy ETFs are sensitive to oil and gas prices, macroeconomic and policy news, and can reflect investors’ expectations for the transition prospects. Therefore, using ETFs as financial indicators can supplement the dimension of market expectations that cannot be directly captured by physical electricity generation sequences."
  },
  {
    "objectID": "multivariate.html#literature-review",
    "href": "multivariate.html#literature-review",
    "title": "ARIMAX, SARIMAX, and VAR",
    "section": "",
    "text": "Energy transition is both a result of technological evolution and a dynamic process driven by the combined effects of economics, climate, and policy. Numerous studies have shown that fossil fuel prices (such as crude oil and natural gas) have a significant impact on the development of renewable energy: when oil or natural gas prices rise, the relative cost of fossil fuels increases, enhancing the relative competitiveness of clean energy, thereby driving growth in renewable power generation or related investment. Simultaneously, climate and weather variables (temperature, irradiance, degree-days) directly affect the short-term output of renewable power generation: solar power is affected by solar irradiance and temperature (high temperatures may slightly reduce photovoltaic efficiency), while wind power is affected by seasonal wind speeds and extreme weather. Finally, policy (subsidies, feed-in tariffs, carbon prices) is a structural driver: policy shocks typically produce lasting trend changes or step responses.\n\n\n\nLiterature divides price transmission into supply-side and demand-side mechanisms: Price increases make renewable energy more attractive by raising the cost of fossil fuel power generation (or the marginal cost of fuel power generation) (substitution effect); another channel is the financial market: oil and gas prices affect the earnings and stock performance of related energy companies, which in turn affects ETFs or capital flows (ICLE, XLE, etc.). These financial variables then feed back into investment and project construction decisions.\n\n\n\nIn empirical methods, researchers widely use ARIMAX/SARIMAX (modeling a single response variable under exogenous shocks) to characterize the short-term impact of exogenous variables such as weather/prices on power generation or prices; while VAR/VECM/VARMA are used to study the dynamic interactions between several endogenous variables (e.g., how wind, solar, natural gas, and coal power generation interact), and to conduct impact response analysis (IRFs) and variance decomposition to identify shock sources and propagation paths. Model selection typically considers the seasonality, trend, and cointegration of time series data.\n\n\n\nETFs (such as clean energy ETFs vs. traditional energy ETFs) are often used as market signals for the energy transition. Empirical research shows that energy ETFs are sensitive to oil and gas prices, macroeconomic and policy news, and can reflect investors’ expectations for the transition prospects. Therefore, using ETFs as financial indicators can supplement the dimension of market expectations that cannot be directly captured by physical electricity generation sequences."
  },
  {
    "objectID": "multivariate.html#key-research-questions",
    "href": "multivariate.html#key-research-questions",
    "title": "ARIMAX, SARIMAX, and VAR",
    "section": "Key Research Questions",
    "text": "Key Research Questions\n\nDoes the price of fossil fuels drive the growth of solar power generation through substitution effects?\n\nWhat are the immediate or lagged responses of solar power if WTI or HH rises? (Examine the β parameter and impulse response)\n\nWhat are the short-term and seasonal effects of weather variables (temp or degree-days) on solar output? Are there nonlinearities (e.g., excessively high temperatures reduce efficiency)?\n\nIt is necessary to examine the linear/quadratic terms of temp, as well as the seasonal interaction term.\n\nAre there substitution or complementarity relationships in the power generation structure (wind, solar, coal, natural gas)? How do shocks (e.g., rising natural gas prices) propagate between different energy sources?\n\nVAR can be used to obtain the impulse response function (IRF) and variance decomposition to answer these questions.\n\nHow do financial markets (ICLE vs XLE) reflect expectations of energy transition? Are these ETFs leading/lagging relationships with actual power generation data or fuel prices?\n\nVAR can be used to test Granger causality and interaction.\n\nHave policies or structural events altered the long-term relationships between energy variables (e.g., trend abrupt changes or changes in cointegration structures)?\n\nExamine structural breakpoints and incorporate policy dummy variables to quantify policy effects.\n\nForecasting: How does the ARIMAX model perform in short-term solar forecasting, considering the uncertainty of exogenous variables? Is it a significant improvement compared to using an autoregressive model alone?\n\n\nTest model stability using time series cross-validation (tsCV) and RMSE comparisons."
  },
  {
    "objectID": "multivariate.html#arimax-solar-power-generation-temperature-oil-prices-gas-prices",
    "href": "multivariate.html#arimax-solar-power-generation-temperature-oil-prices-gas-prices",
    "title": "ARIMAX, SARIMAX, and VAR",
    "section": "(1) ARIMAX: Solar power generation ~ temperature + oil prices + gas prices",
    "text": "(1) ARIMAX: Solar power generation ~ temperature + oil prices + gas prices\n\n\nCode\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggplot2)\nlibrary(seasonal)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(gridExtra)\nlibrary(fpp2)\nlibrary(prophet)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(patchwork)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tsibble)\nlibrary(knitr)\n\ndf &lt;- read.csv(\"data/electric.csv\")\ndf &lt;- df %&gt;%\n  mutate(\n    Description = str_extract(Description, \"(?&lt;=From ).*?(?=,)\"),\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  filter(Year &lt;= 2024) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))\n\n\n\n\nCode\nsolar_df &lt;- df %&gt;%\n  filter(Description == \"Solar\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  rename(Solar = Value) %&gt;%\n  mutate(Solar = log(pmax(Solar, .Machine$double.eps))) %&gt;%\n  arrange(Date)\n\nts_solar &lt;- ts(solar_df$Solar,\n              start = c(min(solar_df$Year), min(solar_df$Month)),\n              frequency = 12)\n\nwti &lt;- read.csv(\"data/WTIprice.csv\")\nwti &lt;- wti %&gt;%\n  rename(Date = observation_date) %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  filter(Date &gt;= as.Date(\"2000-01-01\")) %&gt;%\n  filter(Date &lt;= as.Date(\"2024-12-01\")) %&gt;%\n  rename(WTI = POILWTIUSDM) %&gt;%\n  mutate(WTI = as.numeric(WTI))%&gt;%\n  arrange(Date)\n\nts_wti &lt;- ts(wti$WTI,\n              start = c(2000, 1),\n              frequency = 12)\n\ndf_n &lt;- read.csv(\"data/naturalgasprice.csv\")\ndf_n &lt;- df_n %&gt;%\n  mutate(\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  filter(Year &lt;= 2024) %&gt;%\n  mutate(HH = as.numeric(Value)) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))%&gt;%\n  mutate(HH = log(pmax(HH, .Machine$double.eps))) %&gt;%\n  arrange(Date)\n\nts_np &lt;- ts(df_n$HH,\n              start = c(min(df_n$Year), min(df_n$Month)),\n              frequency = 12)\n\ndf &lt;- read.csv(\"data/Global_Temperature_2000onwards.csv\")\ndf &lt;- df[order(df$Year, df$Month), ]\ndf_temp &lt;- df %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))\n\nts_anomaly &lt;- ts(df_temp$Monthly_Anomaly,\n                 start = c(2000, 1),   \n                 frequency = 12)     \n\n\n\nVisualizationauto.arima()Manual ModelModel DiagnosticsCVFinal Model FitForecasting\n\n\n\nThe relationship between temperature (temp) and solar power generation: Solar power generation is closely related to temperature and irradiance, but extreme high temperatures can reduce the efficiency of photovoltaic panels.\nThe substitution effect of fossil fuel prices on clean energy: When oil prices (WTI) or natural gas prices (HH) rise, clean energy (especially wind and solar power) becomes more economically attractive.\n\n\n\nCode\ndata_all &lt;- solar_df %&gt;%\n  full_join(df_temp, by = \"Date\") %&gt;%\n  full_join(wti, by = \"Date\") %&gt;%\n  full_join(df_n, by = \"Date\") %&gt;%\n  arrange(Date)\n\n# Create individual plots for each variable with y-axis labels\np1 &lt;- plot_ly(data_all, x = ~Date, y = ~Solar, type = 'scatter', mode = 'lines', name = \"Solar Electricity Generation\") %&gt;%\n  layout(yaxis = list(title = \"Value\"))\n\np2 &lt;- plot_ly(data_all, x = ~Date, y = ~Monthly_Anomaly, type = 'scatter', mode = 'lines', name = \"Global Average Temperature Anomaly\") %&gt;%\n  layout(yaxis = list(title = \"Temperature (C)\"))\n\np3 &lt;- plot_ly(data_all, x = ~Date, y = ~WTI, type = 'scatter', mode = 'lines', name = \"WTI Oil price\") %&gt;%\n  layout(yaxis = list(title = \"Price\"))\n\np4 &lt;- plot_ly(data_all, x = ~Date, y = ~HH, type = 'scatter', mode = 'lines', name = \"Henry Hub Natural Gas price\") %&gt;%\n  layout(yaxis = list(title = \"Price\"))\n\n# Combine the individual plots into a single figure with subplots and y-axis labels\nfinal_plot &lt;- subplot(p2, p3, p4, p1, nrows = 4, shareX = TRUE, titleX = TRUE) %&gt;%\n  layout(\n    title = \"Time Series of Solar power generation, temperature, and oil and gas prices\",\n    yaxis = list(title = \"Value\"), \n    yaxis2 = list(title = \"Temperature (C)\"), \n    yaxis3 = list(title = \"Price\"),\n    yaxis4 = list(title = \"Price\"),\n    xaxis = list(title = \"Year\")\n  )\n\nfinal_plot\n\n\n\n\n\n\n\n\n\n\nCode\nfit_auto &lt;- auto.arima(\n  ts_solar,\n  xreg = cbind(ts_anomaly, ts_wti, ts_np))\n\nsummary(fit_auto)\n\n\nSeries: ts_solar \nRegression with ARIMA(0,1,0)(2,0,0)[12] errors \n\nCoefficients:\n        sar1    sar2  ts_anomaly   ts_wti   ts_np\n      0.7384  0.0343     -0.2005  -0.0035  0.1222\ns.e.  0.0623  0.0655      0.1178   0.0024  0.2867\n\nsigma^2 = 0.0832:  log likelihood = -55.29\nAIC=122.58   AICc=122.87   BIC=144.78\n\nTraining set error measures:\n                      ME      RMSE       MAE        MPE     MAPE      MASE\nTraining set 0.007005674 0.2855417 0.1738749 -0.5963215 5.174797 0.5206869\n                   ACF1\nTraining set -0.3249882\n\n\nCode\ncheckresiduals(fit_auto)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(0,1,0)(2,0,0)[12] errors\nQ* = 75.679, df = 22, p-value = 8.212e-08\n\nModel df: 2.   Total lags used: 24\n\n\nThe auto.arima() fits a Regression with (0,1,0)(2,0,0)[12] errors. The ACF plot and Ljung–Box test all indicate that the model does not fully capture the seasonal structure.\n\n\n\n\nCode\nlm_fit &lt;- lm(Solar ~ Monthly_Anomaly + WTI + HH, data = data_all)\nsummary(lm_fit)\n\n\n\nCall:\nlm(formula = Solar ~ Monthly_Anomaly + WTI + HH, data = data_all)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.4115 -1.0282  0.0462  1.2208  4.0037 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     -4.819000   0.880666  -5.472 9.49e-08 ***\nMonthly_Anomaly  7.017950   0.397215  17.668  &lt; 2e-16 ***\nWTI              0.009648   0.004100   2.353   0.0193 *  \nHH               1.839612   0.389946   4.718 3.68e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.585 on 296 degrees of freedom\nMultiple R-squared:  0.5961,    Adjusted R-squared:  0.592 \nF-statistic: 145.6 on 3 and 296 DF,  p-value: &lt; 2.2e-16\n\n\nFrom the regression model, all variables are statistically significant, indicating that WTI oil price, natural gas price and temperature have a meaningful impact on total solar electricity generation. This suggests that changes in these factors directly influence solar electricity generation.\n\n\nCode\nacf(residuals(lm_fit))\n\n\n\n\n\n\n\n\n\nMoreover, the residuals exhibit a high correlation, indicating significant serial correlation that remains unexplained. This suggests that traditional machine learning models may struggle to fully capture the underlying temporal patterns in these time series variables.\n\n\nCode\nres.fit &lt;- ts(residuals(lm_fit), frequency = 12)\np1 &lt;- ggAcf(res.fit)\np2 &lt;- ggPacf(res.fit)\n(p1 | p2)\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(patchwork)\nfirst_diff &lt;- diff(res.fit)  \n\nseasonal_diff &lt;- diff(first_diff, lag = 12)\n\n###### Plot ACF and PACF for the Differenced Series ######\np1 &lt;- ggAcf(seasonal_diff) +\n  ggtitle(\"ACF of Seasonally Differenced Residuals\") +\n  theme_minimal()\n\np2 &lt;- ggPacf(seasonal_diff) +\n  ggtitle(\"PACF of Seasonally Differenced Residuals\") +\n  theme_minimal()\n\n# Display plots\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nThis series appears closer to weak stationarity. The ACF plot shows clear autocorrelations at lags q = 0,1,2,3 and Q = 1,2.\nAdditionally, both first-order differencing (d = 1) and seasonal differencing (D = 1) have been applied to the data.\nThe PACF plot shows clear autocorrelations at lags p = 0,1,2,3 and P = 0,1,2.\n\n\nCode\n###### Define SARIMA Model Comparison Function ######\nSARIMA.c &lt;- function(p_range, d_range, q_range, P_range, D_range, Q_range, data) {\n  \n  # Set seasonal period\n  s &lt;- 12\n  \n  # Initialize results storage\n  results_list &lt;- list()\n  \n  # Iterate over parameter combinations\n  for (p in p_range) {\n    for (d in d_range) {\n      for (q in q_range) {\n        for (P in P_range) {\n          for (D in D_range) {\n            for (Q in Q_range) {\n              \n              if (p + d + q + P + D + Q &lt;= 10) {\n                result &lt;- tryCatch({\n                  model &lt;- Arima(\n                    data,\n                    order = c(p, d, q),\n                    seasonal = list(order = c(P, D, Q), period = s)\n                  )\n                  \n                  c(p, d, q, P, D, Q,\n                    AIC(model),\n                    BIC(model),\n                    model$aicc)\n                  \n                }, error = function(e) {\n                  c(p, d, q, P, D, Q, NA, NA, NA)\n                })\n                \n                results_list[[length(results_list) + 1]] &lt;- result\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  \n  # Convert results to a tidy data frame\n  results_df &lt;- as.data.frame(do.call(rbind, results_list))\n  colnames(results_df) &lt;- c(\"p\", \"d\", \"q\", \"P\", \"D\", \"Q\", \"AIC\", \"BIC\", \"AICc\")\n  \n  return(results_df)\n}\n\n###### Run SARIMA Model Comparison ######\noutput &lt;- SARIMA.c(\n  p_range = 0:3, q_range = 0:3, \n  d_range = 1, D_range = 1, \n  P_range = 0:2, Q_range = 0:2, \n  data = res.fit\n)\n\n###### Identify Models with Minimum AIC and BIC ######\nminaic &lt;- output[which.min(output$AIC), ]\nminbic &lt;- output[which.min(output$BIC), ]\n\n###### Display Best Models Based on AIC and BIC ######\nprint(minaic)\n\n\n   p d q P D Q      AIC      BIC     AICc\n96 2 1 2 1 1 2 729.6844 758.9602 730.2023\n\n\n\n\nThe model ARIMA(2,1,2)x(1,1,2)[12] works siginificantly better than ARIMA(0,1,0)x(2,0,0)[12] due to the lower AIC, BIC, and AICc numbers.\n\n\nCode\nmodel_output_1 &lt;- capture.output(sarima(res.fit, 2, 1, 2, 1, 1, 2, 12))\n\n\n\n\n\n\n\n\n\nCode\n###### Function to Extract Model Diagnostics ######\nextract_model_diagnostics &lt;- function(model_output) {\n  start_line &lt;- grep(\"Coefficients\", model_output)  # Find where coefficients start\n  end_line &lt;- length(model_output)  # Capture till the last line\n  if (length(start_line) &gt; 0) {\n    cat(model_output[start_line:end_line], sep = \"\\n\")  # Print coefficient section\n  } else {\n    cat(\"No coefficient details found.\\n\")  # Handle cases where output format changes\n  }\n}\n\n###### Extract and Print Model Diagnostics ######\ncat(\"### ARIMA(2,1,2)x(1,1,2)[12] ###\\n\")\n\n\n### ARIMA(2,1,2)x(1,1,2)[12] ###\n\n\nCode\nextract_model_diagnostics(model_output_1)\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1   -0.0857 0.1575  -0.5444  0.5866\nar2    0.4865 0.0843   5.7725  0.0000\nma1   -0.3514 0.1644  -2.1372  0.0335\nma2   -0.4945 0.1338  -3.6948  0.0003\nsar1  -0.9712 0.0467 -20.7861  0.0000\nsma1   0.1310 0.0839   1.5613  0.1196\nsma2  -0.7351 0.0832  -8.8318  0.0000\n\nsigma^2 estimated as 0.6651609 on 280 degrees of freedom \n \nAIC = 2.542454  AICc = 2.543853  BIC = 2.644461 \n \n\n\n\n\nCode\nmodel_output_2 &lt;- capture.output(sarima(res.fit, 0, 1, 0, 2, 0, 0, 12))\n\n\n\n\n\n\n\n\n\nCode\n###### Extract and Print Model Diagnostics ######\ncat(\"### ARIMA(0,1,0)x(2,0,0)[12] ###\\n\")\n\n\n### ARIMA(0,1,0)x(2,0,0)[12] ###\n\n\nCode\nextract_model_diagnostics(model_output_2)\n\n\nCoefficients: \n         Estimate     SE t.value p.value\nsar1       0.1181 0.0579  2.0389  0.0423\nsar2       0.1333 0.0592  2.2503  0.0252\nconstant  -0.0069 0.0691 -0.0993  0.9210\n\nsigma^2 estimated as 0.8323154 on 296 degrees of freedom \n \nAIC = 2.68328  AICc = 2.683552  BIC = 2.732784 \n \n\n\n\n\nUsing corss validation, we can confirm that ARIMA(0,1,0)x(2,0,0)[12] is the better model since is stays at a lower RMSE for the majority of the time in the plot below.\n\n\nCode\ny &lt;- as.numeric(res.fit)\nn &lt;- length(y)\nk &lt;- 92   # initial training size\n\nrmse1 &lt;- matrix(NA, 52, 4)\nrmse2 &lt;- matrix(NA, 52, 4)\n\nfor (i in 1:52) {\n\n  # training = first (k+i-1) observations\n  xtrain &lt;- y[1:(k+i-1)]\n  \n  # test = next 4 observations\n  xtest  &lt;- y[(k+i):(k+i+3)]\n  \n  # fit ARIMA models\n  fit &lt;- Arima(ts(xtrain, frequency=12),\n               order=c(2,1,2),\n               seasonal=list(order=c(1,1,2), period=12))\n\n  fcast &lt;- forecast(fit, h=4)\n\n  fit2 &lt;- Arima(ts(xtrain, frequency=12),\n                order=c(0,1,0),\n                seasonal=list(order=c(2,0,0), period=12))\n\n  fcast2 &lt;- forecast(fit2, h=4)\n\n  # ensure xtest length = 4\n  if (length(xtest)==4 && length(fcast$mean)==4) {\n    rmse1[i,] &lt;- sqrt((fcast$mean - xtest)^2)\n    rmse2[i,] &lt;- sqrt((fcast2$mean - xtest)^2)\n  }\n}\n\n# final RMSE\ncolMeans(rmse1, na.rm=TRUE)\n\n\n[1] 0.8445689 1.0799366 1.2584144 1.3675548\n\n\nCode\ncolMeans(rmse2, na.rm=TRUE)\n\n\n[1] 0.7018249 0.9072551 1.0266301 1.0813421\n\n\n\n\nCode\n##### RMSE Plot using Plotly #####\n# Create a dataframe for RMSE values by quarter\nqr &lt;- c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")\n\nrmse11 &lt;- data.frame(Quarter = qr, RMSE = colMeans(rmse1, na.rm = TRUE))\nrmse22 &lt;- data.frame(Quarter = qr, RMSE = colMeans(rmse2, na.rm = TRUE))\n\n# Generate an interactive RMSE comparison plot\nplot_ly() %&gt;%\n  add_lines(data = rmse11, x = ~Quarter, y = ~RMSE, \n            color = I(\"blue\"), name = \"RMSE1: ARIMA(2,1,2)x(1,1,2)[12]\") %&gt;%\n  add_lines(data = rmse22, x = ~Quarter, y = ~RMSE, \n            color = I(\"red\"), name = \"RMSE2: ARIMA(0,1,0)x(2,0,0)[12]\") %&gt;%\n  layout(\n    title = \"Cross-Validation RMSE\",\n    xaxis = list(title = \"Quarter\"),\n    yaxis = list(title = \"RMSE\"),\n    legend = list(title = \"Model\")\n  )\n\n\n\n\n\n\n\n\n\n\nCode\n# Define the dependent variable (TotalVehicleSales)\ny &lt;- ts_solar\n\n# Define external regressors (all variables except TotalVehicleSales)\nxreg &lt;- cbind(ts_anomaly, ts_wti, ts_np)\n\n# Fit ARIMA(2,1,0)x(0,0,1)[12] with external regressors\nfit &lt;- Arima(y, order = c(0,1,0), seasonal = list(order = c(2,0,0), period = 12), xreg = xreg)\n#fit1 &lt;- Arima(y, order = c(2,1,2), seasonal = list(order = c(1,1,2), period = 12), xreg = xreg)\n# Display model summary\nsummary(fit)\n\n\nSeries: y \nRegression with ARIMA(0,1,0)(2,0,0)[12] errors \n\nCoefficients:\n        sar1    sar2  ts_anomaly   ts_wti   ts_np\n      0.7384  0.0343     -0.2005  -0.0035  0.1222\ns.e.  0.0623  0.0655      0.1178   0.0024  0.2867\n\nsigma^2 = 0.0832:  log likelihood = -55.29\nAIC=122.58   AICc=122.87   BIC=144.78\n\nTraining set error measures:\n                      ME      RMSE       MAE        MPE     MAPE      MASE\nTraining set 0.007005674 0.2855417 0.1738749 -0.5963215 5.174797 0.5206869\n                   ACF1\nTraining set -0.3249882\n\n\n\n\nThis model successfully captured the long-term upward trend in solar power generation and accurately reproduced the monthly seasonal patterns. Short-term forecasts have high reliability, while medium- and long-term forecasts exhibit reasonable confidence interval expansion, reflecting the uncertainties in the energy sector. Although the ARIMA model slightly exaggerates the long-term growth slope, the overall trend direction is highly consistent with the structural changes in the US energy market. Therefore, this forecast can serve as a reliable baseline for future solar power generation growth.\n\n\nCode\n# Fit ARIMA model to each external regressor\ntmp_fit &lt;- auto.arima(xreg[, \"ts_anomaly\"])\n#summary(FinR_fit)\nftmp &lt;- forecast(tmp_fit, h = 32)  # Forecast next 32 periods\n\nwti_fit &lt;- auto.arima(xreg[, \"ts_wti\"])\n#summary(Imp_fit)\nfwti &lt;- forecast(wti_fit, h = 32)\n\nhh_fit &lt;- auto.arima(xreg[, \"ts_np\"])\n#summary(CPI_fit)\nfhh &lt;- forecast(hh_fit, h = 32)\n\n\n\n\nCode\n# Create future external regressor matrix using forecasted values\nfxreg &lt;- cbind(Temperature = ftmp$mean, \n               WTI = fwti$mean, \n               HH = fhh$mean)\n\n# Fit ARIMA(2,0,2)x(0,0,1)[12] with external regressors\nfit &lt;- Arima(y, order = c(0,1,0), seasonal = list(order = c(2,0,0), period = 12), xreg = xreg)\n# Forecast TotalVehicleSales using future external regressors\nfcast &lt;- forecast(fit, xreg = fxreg, h = 32)\n\n# Plot the forecast\nautoplot(fcast) +\n  ggtitle(\"Solar Electricity Net Generation Forecast\") +\n  xlab(\"Year\") +\n  ylab(\"Value\") +\n  theme_minimal()"
  },
  {
    "objectID": "multivariate.html#arimax-icln-xle-oil-prices-gas-prices",
    "href": "multivariate.html#arimax-icln-xle-oil-prices-gas-prices",
    "title": "ARIMAX, SARIMAX, and VAR",
    "section": "(2) ARIMAX: ICLN ~ XLE + oil prices + gas prices",
    "text": "(2) ARIMAX: ICLN ~ XLE + oil prices + gas prices\n\n\nCode\netf_symbols &lt;- c(\"ICLN\", \"XLE\")\n\netf_data &lt;- tq_get(etf_symbols,\n                   from = \"2000-01-01\",\n                   to = \"2024-12-01\",\n                   get = \"stock.prices\")\n\nicln_monthly &lt;- etf_data %&gt;%\n  filter(symbol == \"ICLN\") %&gt;%\n  tq_transmute(select = adjusted,\n               mutate_fun = to.monthly,\n               indexAt = \"lastof\",\n               col_rename = \"adjusted\")\n\nts_icln &lt;- ts(icln_monthly$adjusted,\n              start = c(year(min(icln_monthly$date)), month(min(icln_monthly$date))),\n              frequency = 12)\n\nxle_monthly &lt;- etf_data %&gt;%\n  filter(symbol == \"XLE\") %&gt;%\n  tq_transmute(select = adjusted,\n               mutate_fun = to.monthly,\n               indexAt = \"lastof\",\n               col_rename = \"adjusted\")\n\nts_xle &lt;- ts(xle_monthly$adjusted,\n              start = c(year(min(xle_monthly$date)), month(min(xle_monthly$date))),\n              frequency = 12)\n\n\n\nVisualizationauto.arima()Manual ModelModel DiagnosticsCVFinal Model FitForecasting\n\n\n\nFuel Prices → Substitution/Competition Channel for Clean Energy: When fossil fuel prices (especially natural gas or oil) rise, the costs for fossil power generation and related companies increase, making renewable energy (and related listed companies) more economically attractive, thereby boosting their valuations and ETF performance.\nTraditional Energy ETFs (XLE) as a Transmission of Industry Sentiment/Risk Premium: XLE represents the market performance of the traditional energy sector, reflecting industry prosperity, capital flows, and investor risk appetite. The correlation between ICLN and XLE can capture “sector rotation” or the market transmission of funds from traditional energy to clean energy. If the two move in opposite directions, it indicates a substitution relationship between fund flows and market expectations.\n\n\n\nCode\nwti &lt;- read.csv(\"data/WTIprice.csv\")\nwti &lt;- wti %&gt;%\n  rename(Date = observation_date) %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  filter(Date &gt;= as.Date(\"2008-01-01\")) %&gt;%\n  filter(Date &lt;= as.Date(\"2024-12-01\")) %&gt;%\n  rename(WTI = POILWTIUSDM) %&gt;%\n  mutate(WTI = as.numeric(WTI))%&gt;%\n  arrange(Date)\n\nts_wti &lt;- ts(wti$WTI,\n              start = c(2008, 1),\n              frequency = 12)\n\ndf_n &lt;- read.csv(\"data/naturalgasprice.csv\")\ndf_n &lt;- df_n %&gt;%\n  mutate(\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2008) %&gt;%\n  filter(Year &lt;= 2024) %&gt;%\n  mutate(HH = as.numeric(Value)) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))%&gt;%\n  mutate(HH = log(pmax(HH, .Machine$double.eps))) %&gt;%\n  arrange(Date)\n\nts_np &lt;- ts(df_n$HH,\n              start = c(min(df_n$Year), min(df_n$Month)),\n              frequency = 12)\n\ndf_icln &lt;- data.frame(\n  Date = as.Date(time(ts_icln)),   \n  ICLN = as.numeric(ts_icln)\n)\n\ndf_xle &lt;- data.frame(\n  Date = as.Date(time(ts_xle)),  \n  XLE = as.numeric(ts_xle)\n)\n\ndata_all &lt;- df_icln %&gt;%\n  full_join(df_n, by = \"Date\") %&gt;%\n  full_join(wti, by = \"Date\") %&gt;%\n  full_join(df_xle, by = \"Date\") %&gt;%\n  arrange(Date)\n\ndata_all &lt;- subset(data_all, Date &gt;= as.Date(\"2008-06-01\"))\n\n\n\n\nCode\ncommon_start &lt;- c(2008, 6)\ncommon_end   &lt;- c(2024, 11)\n\nts_icln &lt;- window(ts_icln, start = common_start, end = common_end)\nts_xle  &lt;- window(ts_xle,  start = common_start, end = common_end)\nts_wti  &lt;- window(ts_wti,  start = common_start, end = common_end)\nts_np   &lt;- window(ts_np,   start = common_start, end = common_end)\n\n\n\n\nCode\n# Create individual plots for each variable with y-axis labels\np1 &lt;- plot_ly(data_all, x = ~Date, y = ~ICLN, type = 'scatter', mode = 'lines', name = \"Renewable Energy ETF (ICLN)\") %&gt;%\n  layout(yaxis = list(title = \"Price\"))\n\np2 &lt;- plot_ly(data_all, x = ~Date, y = ~XLE, type = 'scatter', mode = 'lines', name = \"Energy Select Sector SPDR Fund (XLE)\") %&gt;%\n  layout(yaxis = list(title = \"Price\"))\n\np3 &lt;- plot_ly(data_all, x = ~Date, y = ~WTI, type = 'scatter', mode = 'lines', name = \"WTI Oil price\") %&gt;%\n  layout(yaxis = list(title = \"Price\"))\n\np4 &lt;- plot_ly(data_all, x = ~Date, y = ~HH, type = 'scatter', mode = 'lines', name = \"Henry Hub Natural Gas price\") %&gt;%\n  layout(yaxis = list(title = \"Price\"))\n\n# Combine the individual plots into a single figure with subplots and y-axis labels\nfinal_plot &lt;- subplot(p2, p3, p4, p1, nrows = 4, shareX = TRUE, titleX = TRUE) %&gt;%\n  layout(\n    title = \"Time Series of ICLN, XLE, WTI and HH price\",\n    yaxis = list(title = \"Price\"), \n    yaxis2 = list(title = \"Price\"), \n    yaxis3 = list(title = \"Price\"),\n    yaxis4 = list(title = \"Price\"),\n    xaxis = list(title = \"Year\")\n  )\n\nfinal_plot\n\n\n\n\n\n\n\n\n\n\nCode\nfit_auto &lt;- auto.arima(\n  ts_icln,\n  xreg = cbind(ts_xle, ts_wti, ts_np)\n)\n\nsummary(fit_auto)\n\n\nSeries: ts_icln \nRegression with ARIMA(0,1,1)(2,0,0)[12] errors \n\nCoefficients:\n         ma1     sar1     sar2  ts_xle  ts_wti   ts_np\n      0.3556  -0.0975  -0.0040  0.1480  0.0094  1.4393\ns.e.  0.0688   0.0940   0.0955  0.0256  0.0180  0.8832\n\nsigma^2 = 1.837:  log likelihood = -336.51\nAIC=687.02   AICc=687.62   BIC=710.01\n\nTraining set error measures:\n                     ME     RMSE       MAE        MPE     MAPE      MASE\nTraining set -0.1154497 1.331195 0.8690734 -0.8413412 6.832752 0.2816481\n                    ACF1\nTraining set 0.002878523\n\n\nCode\ncheckresiduals(fit_auto)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(0,1,1)(2,0,0)[12] errors\nQ* = 24.12, df = 21, p-value = 0.2873\n\nModel df: 3.   Total lags used: 24\n\n\nThe auto.arima() fits a Regression with ARIMA(0,1,1)(2,0,0)[12] errors. It shows well-behaved residuals. - The residual time series fluctuates randomly around zero with no noticeable pattern. - The ACF plot does not exhibit significant autocorrelation, and most spikes remain within the 95% confidence bounds, indicating that the model successfully captures the serial dependence in the data. - The Ljung–Box test (p = 0.2873) confirms that we cannot reject the null hypothesis of no autocorrelation, meaning the residuals are consistent with white noise. - Therefore, this ARIMA model adequately accounts for the strong temporal dependence in the series\n\n\n\n\nCode\nlm_fit &lt;- lm(ICLN ~ XLE + WTI + HH, data = data_all)\nsummary(lm_fit)\n\n\n\nCall:\nlm(formula = ICLN ~ XLE + WTI + HH, data = data_all)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.3476 -3.9395 -0.8801  2.4945 18.6202 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -9.38427    3.69562  -2.539   0.0119 *  \nXLE         -0.02889    0.02691  -1.073   0.2844    \nWTI          0.03615    0.01855   1.948   0.0528 .  \nHH           7.89197    1.52241   5.184 5.43e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.357 on 194 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.1566,    Adjusted R-squared:  0.1436 \nF-statistic: 12.01 on 3 and 194 DF,  p-value: 3.025e-07\n\n\nOnly HH (natural gas price) has a stable and significant effect on ICLN.\nXLE has no significant effect at all; WTI has only a weak correlation.\n\n\nCode\nacf(residuals(lm_fit))\n\n\n\n\n\n\n\n\n\nMoreover, the residuals exhibit a high correlation, indicating significant serial correlation that remains unexplained. This suggests that traditional machine learning models may struggle to fully capture the underlying temporal patterns in these time series variables.\n\n\nCode\nres.fit &lt;- ts(residuals(lm_fit), frequency = 12)\np1 &lt;- ggAcf(res.fit)\np2 &lt;- ggPacf(res.fit)\n(p1 | p2)\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(patchwork)\nfirst_diff &lt;- diff(res.fit)  \n\nseasonal_diff &lt;- diff(first_diff, lag = 12)\n\n###### Plot ACF and PACF for the Differenced Series ######\np3 &lt;- ggAcf(seasonal_diff) +\n  ggtitle(\"ACF of Seasonally Differenced Residuals\") +\n  theme_minimal()\n\np4 &lt;- ggPacf(seasonal_diff) +\n  ggtitle(\"PACF of Seasonally Differenced Residuals\") +\n  theme_minimal()\n\n# Display plots\ngridExtra::grid.arrange(p3, p4, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\nCode\n###### Define SARIMA Model Comparison Function ######\nSARIMA.c &lt;- function(p_range, d_range, q_range, P_range, D_range, Q_range, data) {\n  \n  # Set seasonal period\n  s &lt;- 12\n  \n  # Initialize results storage\n  results_list &lt;- list()\n  \n  # Iterate over parameter combinations\n  for (p in p_range) {\n    for (d in d_range) {\n      for (q in q_range) {\n        for (P in P_range) {\n          for (D in D_range) {\n            for (Q in Q_range) {\n              \n              if (p + d + q + P + D + Q &lt;= 10) {\n                result &lt;- tryCatch({\n                  model &lt;- Arima(\n                    data,\n                    order = c(p, d, q),\n                    seasonal = list(order = c(P, D, Q), period = s)\n                  )\n                  \n                  c(p, d, q, P, D, Q,\n                    AIC(model),\n                    BIC(model),\n                    model$aicc)\n                  \n                }, error = function(e) {\n                  c(p, d, q, P, D, Q, NA, NA, NA)\n                })\n                \n                results_list[[length(results_list) + 1]] &lt;- result\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  \n  # Convert results to a tidy data frame\n  results_df &lt;- as.data.frame(do.call(rbind, results_list))\n  colnames(results_df) &lt;- c(\"p\", \"d\", \"q\", \"P\", \"D\", \"Q\", \"AIC\", \"BIC\", \"AICc\")\n  \n  return(results_df)\n}\n\n###### Run SARIMA Model Comparison ######\noutput &lt;- SARIMA.c(\n  p_range = 0:3, q_range = 0:2, \n  d_range = 1, D_range = 1, \n  P_range = 0:2, Q_range = 0:2, \n  data = res.fit\n)\n\n###### Identify Models with Minimum AIC and BIC ######\nminaic &lt;- output[which.min(output$AIC), ]\nminbic &lt;- output[which.min(output$BIC), ]\n\n###### Display Best Models Based on AIC and BIC ######\nprint(minaic)\n\n\n    p d q P D Q      AIC      BIC     AICc\n101 3 1 2 0 1 1 698.2813 720.8238 698.9141\n\n\n\n\nThe model ARIMA(3,1,2)x(0,1,1)[12] works siginificantly better than ARIMA(0,1,1)x(2,0,0)[12] due to the lower AIC, BIC, and AICc numbers.\n\n\nCode\nmodel_output_1 &lt;- capture.output(sarima(res.fit, 3, 1, 2, 0, 1, 1, 12))\n\n\n\n\n\n\n\n\n\nCode\n###### Function to Extract Model Diagnostics ######\nextract_model_diagnostics &lt;- function(model_output) {\n  start_line &lt;- grep(\"Coefficients\", model_output)  # Find where coefficients start\n  end_line &lt;- length(model_output)  # Capture till the last line\n  if (length(start_line) &gt; 0) {\n    cat(model_output[start_line:end_line], sep = \"\\n\")  # Print coefficient section\n  } else {\n    cat(\"No coefficient details found.\\n\")  # Handle cases where output format changes\n  }\n}\n\n###### Extract and Print Model Diagnostics ######\ncat(\"### ARIMA(3,1,2)x(0,1,1)[12] ###\\n\")\n\n\n### ARIMA(3,1,2)x(0,1,1)[12] ###\n\n\nCode\nextract_model_diagnostics(model_output_1)\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1    0.9859 0.0710  13.8849       0\nar2   -1.1419 0.0560 -20.3825       0\nar3    0.3433 0.0736   4.6611       0\nma1   -0.8266 0.0208 -39.6988       0\nma2    1.0000 0.0320  31.2944       0\nsma1  -0.7952 0.0752 -10.5762       0\n\nsigma^2 estimated as 2.125083 on 179 degrees of freedom \n \nAIC = 3.774494  AICc = 3.777044  BIC = 3.896345 \n \n\n\n\n\nCode\nmodel_output_2 &lt;- capture.output(sarima(res.fit, 0, 1, 1, 2, 0, 0, 12))\n\n\n\n\n\n\n\n\n\nCode\n###### Extract and Print Model Diagnostics ######\ncat(\"### ARIMA(0,1,1)x(2,0,0)[12] ###\\n\")\n\n\n### ARIMA(0,1,1)x(2,0,0)[12] ###\n\n\nCode\nextract_model_diagnostics(model_output_2)\n\n\nCoefficients: \n         Estimate     SE t.value p.value\nma1        0.2613 0.0752  3.4767  0.0006\nsar1       0.2153 0.0838  2.5676  0.0110\nsar2       0.2064 0.0865  2.3857  0.0180\nconstant  -0.1597 0.2338 -0.6830  0.4954\n\nsigma^2 estimated as 2.540722 on 193 degrees of freedom \n \nAIC = 3.831405  AICc = 3.832463  BIC = 3.914736 \n \n\n\n\n\nUsing corss validation, we can find that ARIMA(3,1,2)x(0,1,1)[12] is the better model since is stays at a lower RMSE for the majority of the time in the plot below.\n\n\nCode\ny &lt;- as.numeric(res.fit)\nn &lt;- length(y)\nk &lt;- 90   # initial training size\n\nrmse1 &lt;- matrix(NA, 27, 4)\nrmse2 &lt;- matrix(NA, 27, 4)\n\nfor (i in 1:27) {\n\n  # training = first (k+i-1) observations\n  xtrain &lt;- y[1:(k+i-1)]\n  \n  # test = next 4 observations\n  xtest  &lt;- y[(k+i):(k+i+3)]\n  \n  # fit ARIMA models\n  fit &lt;- Arima(ts(xtrain, frequency=12),\n               order=c(3,1,2),\n               seasonal=list(order=c(0,1,1), period=12))\n\n  fcast &lt;- forecast(fit, h=4)\n\n  fit2 &lt;- Arima(ts(xtrain, frequency=12),\n                order=c(0,1,1),\n                seasonal=list(order=c(2,0,0), period=12))\n\n  fcast2 &lt;- forecast(fit2, h=4)\n\n  # ensure xtest length = 4\n  if (length(xtest)==4 && length(fcast$mean)==4) {\n    rmse1[i,] &lt;- sqrt((fcast$mean - xtest)^2)\n    rmse2[i,] &lt;- sqrt((fcast2$mean - xtest)^2)\n  }\n}\n\n# final RMSE\ncolMeans(rmse1, na.rm=TRUE)\n\n\n[1] 0.4349630 0.6892722 0.7957184 0.9767626\n\n\nCode\ncolMeans(rmse2, na.rm=TRUE)\n\n\n[1] 0.6071018 1.2748304 1.8310814 2.4632177\n\n\n\n\nCode\n##### RMSE Plot using Plotly #####\n# Create a dataframe for RMSE values by quarter\nqr &lt;- c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")\n\nrmse11 &lt;- data.frame(Quarter = qr, RMSE = colMeans(rmse1, na.rm = TRUE))\nrmse22 &lt;- data.frame(Quarter = qr, RMSE = colMeans(rmse2, na.rm = TRUE))\n\n# Generate an interactive RMSE comparison plot\nplot_ly() %&gt;%\n  add_lines(data = rmse11, x = ~Quarter, y = ~RMSE, \n            color = I(\"blue\"), name = \"RMSE1: ARIMA(3,1,2)x(0,1,1)[12]\") %&gt;%\n  add_lines(data = rmse22, x = ~Quarter, y = ~RMSE, \n            color = I(\"red\"), name = \"RMSE2: ARIMA(0,1,1)x(2,0,0)[12]\") %&gt;%\n  layout(\n    title = \"Cross-Validation RMSE\",\n    xaxis = list(title = \"Quarter\"),\n    yaxis = list(title = \"RMSE\"),\n    legend = list(title = \"Model\")\n  )\n\n\n\n\n\n\n\n\n\n\nCode\n# Define the dependent variable (TotalVehicleSales)\ny &lt;- ts_icln\n\n# Define external regressors (all variables except TotalVehicleSales)\nxreg &lt;- cbind(ts_xle, ts_wti, ts_np)\n\n# Fit ARIMA(2,1,0)x(0,0,1)[12] with external regressors\nfit &lt;- Arima(y, order = c(3,1,2), seasonal = list(order = c(0,1,1), period = 12), xreg = xreg)\n#fit1 &lt;- Arima(y, order = c(2,1,2), seasonal = list(order = c(2,0,1), period = 12), xreg = xreg)\n# Display model summary\nsummary(fit)\n\n\nSeries: y \nRegression with ARIMA(3,1,2)(0,1,1)[12] errors \n\nCoefficients:\n         ar1      ar2     ar3      ma1     ma2     sma1  ts_xle  ts_wti   ts_np\n      1.0823  -1.2256  0.4413  -0.8235  0.9999  -0.7606  0.1213  0.0155  3.8612\ns.e.  0.0701   0.0558  0.0748   0.0382  0.0754   0.0864  0.0226  0.0116  1.7681\n\nsigma^2 = 1.781:  log likelihood = -320.74\nAIC=661.49   AICc=662.75   BIC=693.69\n\nTraining set error measures:\n                    ME     RMSE       MAE      MPE     MAPE      MASE\nTraining set 0.1085899 1.258092 0.8648511 1.402603 7.687683 0.2802798\n                    ACF1\nTraining set 0.001177414\n\n\n\n\nThe ARIMAX model suggests a mild downward trend in future ICLN values, driven largely by the projected behavior of the external energy market indicators (XLE, WTI, and HH).\nAlthough the short-term forecast remains relatively tight, the confidence bands expand substantially over longer horizons, reflecting the inherently high volatility of renewable-energy equities and the uncertainty in future energy-market conditions.\nOverall, the model produces a smooth and stable forecast trajectory without unrealistic jumps, indicating a reasonable and well-behaved dynamic specification.\n\n\nCode\n# Fit ARIMA model to each external regressor\nxle_fit &lt;- auto.arima(xreg[, \"ts_xle\"])\n#summary(FinR_fit)\nfxle &lt;- forecast(xle_fit, h = 32)  # Forecast next 32 periods\n\nwti_fit &lt;- auto.arima(xreg[, \"ts_wti\"])\n#summary(Imp_fit)\nfwti &lt;- forecast(wti_fit, h = 32)\n\nhh_fit &lt;- auto.arima(xreg[, \"ts_np\"])\n#summary(CPI_fit)\nfhh &lt;- forecast(hh_fit, h = 32)\n\n\n\n\nCode\n# Create future external regressor matrix using forecasted values\nfxreg &lt;- cbind(XLE = fxle$mean, \n               WTI = fwti$mean, \n               HH = fhh$mean)\n\n# Fit ARIMA(2,0,2)x(0,0,1)[12] with external regressors\nfit &lt;- Arima(y, order = c(3,1,2), seasonal = list(order = c(0,1,1), period = 12), xreg = xreg)\n# Forecast TotalVehicleSales using future external regressors\nfcast &lt;- forecast(fit, xreg = fxreg, h = 32)\n\n# Plot the forecast\nautoplot(fcast) +\n  ggtitle(\"ICLN Prices Forecast\") +\n  xlab(\"Year\") +\n  ylab(\"Value\") +\n  theme_minimal()"
  },
  {
    "objectID": "multivariate.html#var-the-dynamic-relationship-between-clean-and-traditional-energy",
    "href": "multivariate.html#var-the-dynamic-relationship-between-clean-and-traditional-energy",
    "title": "ARIMAX, SARIMAX, and VAR",
    "section": "(3) VAR: The dynamic relationship between clean and traditional energy",
    "text": "(3) VAR: The dynamic relationship between clean and traditional energy\n\n\nCode\ndf &lt;- read.csv(\"data/electric.csv\")\ndf &lt;- df %&gt;%\n  mutate(\n    Description = str_extract(Description, \"(?&lt;=From ).*?(?=,)\"),\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))\n\nwind_df &lt;- df %&gt;%\n  filter(Description == \"Wind\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_wind &lt;- ts(wind_df$Value,\n              start = c(min(wind_df$Year), min(wind_df$Month)),\n              frequency = 12)\n\nsolar_df &lt;- df %&gt;%\n  filter(Description == \"Solar\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_solar &lt;- ts(solar_df$Value,\n              start = c(min(solar_df$Year), min(solar_df$Month)),\n              frequency = 12)\n\ncoal_df &lt;- df %&gt;%\n  filter(Description == \"Coal\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_coal &lt;- ts(coal_df$Value,\n              start = c(min(coal_df$Year), min(coal_df$Month)),\n              frequency = 12)     \n\nn_df &lt;- df %&gt;%\n  filter(Description == \"Natural Gas\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_n &lt;- ts(n_df$Value,\n              start = c(min(n_df$Year), min(n_df$Month)),\n              frequency = 12)        \n\n\n\nVisualizationVARselectInitial selectionCVForecasting\n\n\nFrom a time series perspective:\n\nThe rise of clean energy is accompanied by the decline of traditional energy;\nThere are potential substitution and synergistic relationships among different energy sources;\nTheir mutual influences can be further analyzed using a VAR model.\n\n\n\nCode\ndf_ts &lt;- cbind(ts_wind, ts_solar, ts_coal, ts_n)\ncolnames(df_ts) &lt;- c(\"wind\", \"solar\", \"coal\", \"natural_gas\")\n\nautoplot(df_ts)\n\n\n\n\n\n\n\n\n\n\n\np-values are 8 and 10.\n\n\nCode\nlibrary(vars)\nVARselect(df_ts, type=\"both\")\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n    10     10      8     10 \n\n$criteria\n                  1            2            3            4            5\nAIC(n) 6.635608e+01 6.503473e+01 6.475708e+01 6.445831e+01 6.372948e+01\nHQ(n)  6.647588e+01 6.523440e+01 6.503662e+01 6.481771e+01 6.416875e+01\nSC(n)  6.665530e+01 6.553343e+01 6.545526e+01 6.535597e+01 6.482662e+01\nFPE(n) 6.577950e+28 1.754975e+28 1.329736e+28 9.866202e+27 4.762551e+27\n                  6            7            8            9           10\nAIC(n) 6.340032e+01 6.312212e+01 6.284699e+01 6.270320e+01 6.251556e+01\nHQ(n)  6.391946e+01 6.372113e+01 6.352586e+01 6.346194e+01 6.335416e+01\nSC(n)  6.469694e+01 6.461822e+01 6.454256e+01 6.459825e+01 6.461008e+01\nFPE(n) 3.429250e+27 2.598985e+27 1.976379e+27 1.714463e+27 1.423999e+27\n\n\n\n\nThe two VAR models (p=8 and p=10) showed almost identical fitting results. The log-likelihood of p=10 was slightly higher, but the improvement was limited, while the degrees of freedom were lower. The major significant lags were consistent in both models, indicating that lag order 8 was sufficient to capture the dynamic relationships between variables.\nThere is a certain degree of complementarity between renewable energy sources (wind–solar), while the relationship with fossil fuels (coal, gas) is more of a substitution relationship. The trend term indicates a long-term upward trend for renewable energy and gas-fired power, while the trend for coal-fired power may be a remnant of structural changes.\n\n\nCode\nsummary(vars::VAR(df_ts, p=8, type='both'))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: wind, solar, coal, natural_gas \nDeterministic variables: both \nSample size: 298 \nLog Likelihood: -10915.965 \nRoots of the characteristic polynomial:\n1.025 1.013 1.013 0.9833 0.9833 0.9674 0.9649 0.9649 0.9062 0.9062 0.9001 0.9001 0.8996 0.8996 0.8751 0.8751 0.8366 0.8366 0.7962 0.7962 0.7935 0.7935 0.7819 0.7819 0.7391 0.7391 0.7308 0.7308 0.508 0.508 0.3611 0.3611\nCall:\nvars::VAR(y = df_ts, p = 8, type = \"both\")\n\n\nEstimation results for equation wind: \n===================================== \nwind = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + const + trend \n\n                 Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1         3.817e-01  6.532e-02   5.844  1.5e-08 ***\nsolar.l1        8.492e-02  2.777e-01   0.306  0.76000    \ncoal.l1        -7.911e-03  1.488e-02  -0.532  0.59550    \nnatural_gas.l1 -5.541e-02  1.730e-02  -3.204  0.00152 ** \nwind.l2         1.269e-01  7.289e-02   1.741  0.08291 .  \nsolar.l2       -2.964e-01  3.321e-01  -0.892  0.37299    \ncoal.l2        -2.452e-03  1.848e-02  -0.133  0.89457    \nnatural_gas.l2  8.470e-03  2.109e-02   0.402  0.68832    \nwind.l3        -5.333e-02  7.220e-02  -0.739  0.46074    \nsolar.l3       -2.358e-01  3.504e-01  -0.673  0.50151    \ncoal.l3         9.975e-03  1.813e-02   0.550  0.58259    \nnatural_gas.l3  5.426e-02  2.093e-02   2.592  0.01006 *  \nwind.l4         1.260e-01  7.142e-02   1.764  0.07891 .  \nsolar.l4       -7.508e-01  3.456e-01  -2.172  0.03072 *  \ncoal.l4        -2.849e-02  1.751e-02  -1.627  0.10492    \nnatural_gas.l4 -1.906e-02  2.087e-02  -0.913  0.36193    \nwind.l5         8.101e-02  7.267e-02   1.115  0.26592    \nsolar.l5        1.159e+00  3.630e-01   3.193  0.00158 ** \ncoal.l5        -1.967e-04  1.762e-02  -0.011  0.99110    \nnatural_gas.l5  2.292e-02  2.097e-02   1.093  0.27536    \nwind.l6        -3.436e-02  7.204e-02  -0.477  0.63375    \nsolar.l6        3.396e-01  3.847e-01   0.883  0.37818    \ncoal.l6         7.190e-03  1.801e-02   0.399  0.69004    \nnatural_gas.l6 -1.858e-02  2.088e-02  -0.890  0.37447    \nwind.l7         1.188e-01  7.151e-02   1.661  0.09783 .  \nsolar.l7       -2.243e-01  3.735e-01  -0.601  0.54864    \ncoal.l7        -4.401e-03  1.788e-02  -0.246  0.80577    \nnatural_gas.l7 -3.028e-03  2.146e-02  -0.141  0.88791    \nwind.l8         4.189e-02  6.845e-02   0.612  0.54106    \nsolar.l8        2.887e-02  3.063e-01   0.094  0.92498    \ncoal.l8         1.247e-02  1.531e-02   0.814  0.41618    \nnatural_gas.l8  3.464e-02  1.682e-02   2.059  0.04043 *  \nconst           5.520e+02  3.186e+03   0.173  0.86258    \ntrend           1.330e+01  9.976e+00   1.333  0.18370    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 1808 on 264 degrees of freedom\nMultiple R-Squared: 0.9831, Adjusted R-squared: 0.981 \nF-statistic:   465 on 33 and 264 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation solar: \n====================================== \nsolar = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + const + trend \n\n                 Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1        -4.424e-02  1.408e-02  -3.143 0.001865 ** \nsolar.l1        6.650e-01  5.985e-02  11.110  &lt; 2e-16 ***\ncoal.l1         7.756e-04  3.208e-03   0.242 0.809115    \nnatural_gas.l1 -2.674e-04  3.728e-03  -0.072 0.942857    \nwind.l2        -6.495e-03  1.571e-02  -0.413 0.679610    \nsolar.l2        4.049e-01  7.158e-02   5.656 4.03e-08 ***\ncoal.l2        -2.849e-03  3.983e-03  -0.715 0.475031    \nnatural_gas.l2  1.454e-03  4.546e-03   0.320 0.749265    \nwind.l3         1.708e-02  1.556e-02   1.098 0.273308    \nsolar.l3        1.062e-01  7.551e-02   1.407 0.160708    \ncoal.l3         1.726e-03  3.907e-03   0.442 0.658914    \nnatural_gas.l3  5.200e-04  4.511e-03   0.115 0.908322    \nwind.l4         5.338e-02  1.539e-02   3.468 0.000613 ***\nsolar.l4       -4.428e-01  7.449e-02  -5.944 8.77e-09 ***\ncoal.l4         2.490e-03  3.775e-03   0.660 0.510000    \nnatural_gas.l4 -1.046e-02  4.498e-03  -2.326 0.020780 *  \nwind.l5         3.670e-02  1.566e-02   2.344 0.019838 *  \nsolar.l5       -4.554e-02  7.823e-02  -0.582 0.560931    \ncoal.l5         6.679e-04  3.798e-03   0.176 0.860546    \nnatural_gas.l5  6.769e-03  4.519e-03   1.498 0.135347    \nwind.l6         1.090e-02  1.553e-02   0.702 0.483132    \nsolar.l6       -1.211e-01  8.291e-02  -1.460 0.145359    \ncoal.l6        -1.533e-04  3.881e-03  -0.039 0.968523    \nnatural_gas.l6 -3.809e-03  4.500e-03  -0.846 0.398135    \nwind.l7        -5.198e-02  1.541e-02  -3.373 0.000855 ***\nsolar.l7        1.897e-01  8.049e-02   2.357 0.019154 *  \ncoal.l7        -5.489e-03  3.854e-03  -1.424 0.155557    \nnatural_gas.l7  1.564e-02  4.626e-03   3.380 0.000834 ***\nwind.l8        -5.771e-02  1.475e-02  -3.912 0.000116 ***\nsolar.l8        3.192e-01  6.601e-02   4.836 2.26e-06 ***\ncoal.l8        -1.530e-03  3.299e-03  -0.464 0.643178    \nnatural_gas.l8 -1.090e-02  3.626e-03  -3.005 0.002908 ** \nconst           6.623e+02  6.867e+02   0.965 0.335638    \ntrend           3.185e+00  2.150e+00   1.481 0.139707    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 389.7 on 264 degrees of freedom\nMultiple R-Squared: 0.9963, Adjusted R-squared: 0.9958 \nF-statistic:  2148 on 33 and 264 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation coal: \n===================================== \ncoal = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + const + trend \n\n                 Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1        -4.913e-01  3.039e-01  -1.617 0.107170    \nsolar.l1        1.458e+00  1.292e+00   1.128 0.260250    \ncoal.l1         5.797e-01  6.925e-02   8.370 3.39e-15 ***\nnatural_gas.l1  9.157e-02  8.048e-02   1.138 0.256229    \nwind.l2        -2.036e-02  3.392e-01  -0.060 0.952178    \nsolar.l2        2.205e-01  1.546e+00   0.143 0.886662    \ncoal.l2         7.125e-02  8.600e-02   0.828 0.408165    \nnatural_gas.l2 -2.469e-01  9.815e-02  -2.515 0.012489 *  \nwind.l3         4.889e-01  3.360e-01   1.455 0.146768    \nsolar.l3       -5.972e-01  1.630e+00  -0.366 0.714433    \ncoal.l3        -9.940e-02  8.435e-02  -1.178 0.239688    \nnatural_gas.l3 -1.047e-01  9.739e-02  -1.075 0.283208    \nwind.l4        -3.105e-01  3.323e-01  -0.934 0.350970    \nsolar.l4       -2.604e+00  1.608e+00  -1.619 0.106591    \ncoal.l4        -8.784e-02  8.149e-02  -1.078 0.282100    \nnatural_gas.l4  9.187e-02  9.712e-02   0.946 0.345086    \nwind.l5         9.110e-02  3.381e-01   0.269 0.787830    \nsolar.l5        1.724e+00  1.689e+00   1.021 0.308334    \ncoal.l5         1.852e-01  8.201e-02   2.259 0.024710 *  \nnatural_gas.l5  9.240e-02  9.757e-02   0.947 0.344494    \nwind.l6        -6.651e-01  3.352e-01  -1.984 0.048272 *  \nsolar.l6        2.490e+00  1.790e+00   1.391 0.165470    \ncoal.l6         9.134e-02  8.380e-02   1.090 0.276731    \nnatural_gas.l6 -3.676e-01  9.716e-02  -3.783 0.000191 ***\nwind.l7        -2.770e-01  3.328e-01  -0.832 0.405960    \nsolar.l7       -7.318e-01  1.738e+00  -0.421 0.674063    \ncoal.l7         1.681e-01  8.320e-02   2.020 0.044425 *  \nnatural_gas.l7 -9.292e-02  9.987e-02  -0.930 0.353029    \nwind.l8        -1.741e-01  3.185e-01  -0.547 0.585132    \nsolar.l8       -1.326e+00  1.425e+00  -0.930 0.353097    \ncoal.l8        -3.729e-01  7.123e-02  -5.236 3.36e-07 ***\nnatural_gas.l8 -1.052e-01  7.828e-02  -1.344 0.180069    \nconst           1.065e+05  1.483e+04   7.184 6.90e-12 ***\ntrend           1.840e+02  4.642e+01   3.963 9.52e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 8414 on 264 degrees of freedom\nMultiple R-Squared: 0.9655, Adjusted R-squared: 0.9612 \nF-statistic: 223.8 on 33 and 264 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation natural_gas: \n============================================ \nnatural_gas = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + const + trend \n\n                 Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1         3.289e-02  2.747e-01   0.120  0.90478    \nsolar.l1       -1.059e+00  1.168e+00  -0.907  0.36542    \ncoal.l1        -1.842e-01  6.259e-02  -2.942  0.00355 ** \nnatural_gas.l1  8.112e-01  7.273e-02  11.153  &lt; 2e-16 ***\nwind.l2        -3.452e-01  3.065e-01  -1.126  0.26108    \nsolar.l2        2.348e+00  1.397e+00   1.681  0.09392 .  \ncoal.l2        -3.866e-02  7.772e-02  -0.497  0.61930    \nnatural_gas.l2 -2.646e-01  8.870e-02  -2.983  0.00312 ** \nwind.l3         6.057e-01  3.036e-01   1.995  0.04707 *  \nsolar.l3        3.471e-01  1.473e+00   0.236  0.81397    \ncoal.l3        -1.298e-01  7.623e-02  -1.703  0.08982 .  \nnatural_gas.l3 -1.459e-01  8.802e-02  -1.658  0.09848 .  \nwind.l4        -1.712e-02  3.003e-01  -0.057  0.95459    \nsolar.l4       -1.675e+00  1.453e+00  -1.152  0.25022    \ncoal.l4        -6.420e-02  7.365e-02  -0.872  0.38415    \nnatural_gas.l4  5.628e-02  8.777e-02   0.641  0.52196    \nwind.l5        -5.046e-01  3.056e-01  -1.651  0.09988 .  \nsolar.l5        2.782e+00  1.526e+00   1.823  0.06944 .  \ncoal.l5        -9.806e-02  7.411e-02  -1.323  0.18692    \nnatural_gas.l5  4.493e-02  8.817e-02   0.510  0.61080    \nwind.l6        -6.079e-01  3.029e-01  -2.007  0.04582 *  \nsolar.l6       -2.192e+00  1.618e+00  -1.355  0.17652    \ncoal.l6         2.501e-02  7.573e-02   0.330  0.74151    \nnatural_gas.l6 -2.549e-01  8.781e-02  -2.903  0.00401 ** \nwind.l7         2.773e-01  3.007e-01   0.922  0.35732    \nsolar.l7       -1.510e+00  1.571e+00  -0.961  0.33735    \ncoal.l7         2.857e-01  7.519e-02   3.800  0.00018 ***\nnatural_gas.l7 -1.013e-01  9.026e-02  -1.122  0.26274    \nwind.l8        -3.463e-01  2.878e-01  -1.203  0.23002    \nsolar.l8        1.613e+00  1.288e+00   1.252  0.21166    \ncoal.l8        -2.013e-01  6.437e-02  -3.127  0.00196 ** \nnatural_gas.l8 -1.449e-01  7.074e-02  -2.048  0.04155 *  \nconst           1.125e+05  1.340e+04   8.399 2.79e-15 ***\ntrend           2.832e+02  4.195e+01   6.751 9.30e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 7603 on 264 degrees of freedom\nMultiple R-Squared: 0.963,  Adjusted R-squared: 0.9584 \nF-statistic: 208.2 on 33 and 264 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n                wind  solar     coal natural_gas\nwind         3269310 211148 -2361536    -3011017\nsolar         211148 151858   211409       98698\ncoal        -2361536 211409 70790341    33550343\nnatural_gas -3011017  98698 33550343    57812585\n\nCorrelation matrix of residuals:\n               wind   solar     coal natural_gas\nwind         1.0000 0.29967 -0.15523    -0.21902\nsolar        0.2997 1.00000  0.06448     0.03331\ncoal        -0.1552 0.06448  1.00000     0.52444\nnatural_gas -0.2190 0.03331  0.52444     1.00000\n\n\n\n\nCode\nsummary(vars::VAR(df_ts, p=10, type='both'))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: wind, solar, coal, natural_gas \nDeterministic variables: both \nSample size: 296 \nLog Likelihood: -10764.325 \nRoots of the characteristic polynomial:\n1.025 1.015 1.015 0.994 0.994 0.9747 0.9747 0.9723 0.947 0.947 0.9408 0.9408 0.9232 0.9232 0.9113 0.9113 0.9017 0.9017 0.8924 0.8882 0.8882 0.8693 0.8693 0.8612 0.8612 0.8557 0.8557 0.8204 0.8204 0.7978 0.7978 0.794 0.7455 0.7455 0.7322 0.7322 0.7181 0.5306 0.5217 0.3942\nCall:\nvars::VAR(y = df_ts, p = 10, type = \"both\")\n\n\nEstimation results for equation wind: \n===================================== \nwind = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + wind.l9 + solar.l9 + coal.l9 + natural_gas.l9 + wind.l10 + solar.l10 + coal.l10 + natural_gas.l10 + const + trend \n\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1          3.875e-01  6.672e-02   5.808 1.89e-08 ***\nsolar.l1         1.877e-01  3.186e-01   0.589 0.556364    \ncoal.l1         -4.377e-03  1.535e-02  -0.285 0.775793    \nnatural_gas.l1  -5.808e-02  1.766e-02  -3.288 0.001150 ** \nwind.l2          1.379e-01  7.296e-02   1.891 0.059810 .  \nsolar.l2        -3.957e-01  3.509e-01  -1.128 0.260537    \ncoal.l2         -1.561e-02  1.852e-02  -0.843 0.400165    \nnatural_gas.l2  -5.350e-03  2.145e-02  -0.249 0.803288    \nwind.l3         -4.500e-02  7.289e-02  -0.617 0.537515    \nsolar.l3        -3.016e-01  3.589e-01  -0.840 0.401633    \ncoal.l3          1.443e-02  1.813e-02   0.796 0.426625    \nnatural_gas.l3   6.883e-02  2.164e-02   3.181 0.001649 ** \nwind.l4          1.112e-01  7.274e-02   1.529 0.127627    \nsolar.l4        -7.629e-01  3.582e-01  -2.130 0.034123 *  \ncoal.l4         -4.172e-02  1.827e-02  -2.284 0.023209 *  \nnatural_gas.l4  -1.297e-02  2.150e-02  -0.603 0.546908    \nwind.l5          7.496e-02  7.332e-02   1.022 0.307615    \nsolar.l5         1.262e+00  3.761e-01   3.355 0.000914 ***\ncoal.l5          1.574e-02  1.803e-02   0.873 0.383642    \nnatural_gas.l5   1.345e-03  2.135e-02   0.063 0.949827    \nwind.l6         -1.087e-01  7.378e-02  -1.473 0.141881    \nsolar.l6         1.434e-01  3.901e-01   0.368 0.713483    \ncoal.l6          7.796e-03  1.776e-02   0.439 0.661038    \nnatural_gas.l6  -1.502e-02  2.080e-02  -0.722 0.470960    \nwind.l7          1.345e-01  7.328e-02   1.835 0.067619 .  \nsolar.l7         8.403e-02  3.874e-01   0.217 0.828458    \ncoal.l7         -6.171e-03  1.772e-02  -0.348 0.727916    \nnatural_gas.l7  -6.212e-03  2.149e-02  -0.289 0.772780    \nwind.l8          2.071e-02  7.387e-02   0.280 0.779464    \nsolar.l8         3.247e-01  4.054e-01   0.801 0.423894    \ncoal.l8          2.503e-03  1.822e-02   0.137 0.890843    \nnatural_gas.l8   1.094e-02  2.196e-02   0.498 0.619020    \nwind.l9          7.915e-02  7.561e-02   1.047 0.296193    \nsolar.l9        -1.219e+00  4.298e-01  -2.836 0.004936 ** \ncoal.l9          3.302e-02  1.858e-02   1.778 0.076669 .  \nnatural_gas.l9   2.545e-02  2.223e-02   1.145 0.253211    \nwind.l10        -3.022e-02  6.981e-02  -0.433 0.665480    \nsolar.l10        8.001e-01  3.898e-01   2.053 0.041127 *  \ncoal.l10        -3.500e-02  1.577e-02  -2.220 0.027335 *  \nnatural_gas.l10 -1.921e-02  1.720e-02  -1.116 0.265263    \nconst            4.676e+03  4.020e+03   1.163 0.245875    \ntrend            2.264e+01  1.201e+01   1.885 0.060588 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 1763 on 254 degrees of freedom\nMultiple R-Squared: 0.9844, Adjusted R-squared: 0.9819 \nF-statistic: 390.8 on 41 and 254 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation solar: \n====================================== \nsolar = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + wind.l9 + solar.l9 + coal.l9 + natural_gas.l9 + wind.l10 + solar.l10 + coal.l10 + natural_gas.l10 + const + trend \n\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1         -3.216e-02  1.337e-02  -2.405  0.01688 *  \nsolar.l1         4.952e-01  6.385e-02   7.755 2.14e-13 ***\ncoal.l1          3.695e-03  3.077e-03   1.201  0.23096    \nnatural_gas.l1  -6.061e-03  3.540e-03  -1.712  0.08808 .  \nwind.l2         -1.071e-02  1.462e-02  -0.732  0.46460    \nsolar.l2         3.691e-01  7.034e-02   5.247 3.25e-07 ***\ncoal.l2         -3.696e-03  3.711e-03  -0.996  0.32026    \nnatural_gas.l2   2.660e-03  4.300e-03   0.619  0.53677    \nwind.l3          3.253e-03  1.461e-02   0.223  0.82397    \nsolar.l3         1.886e-01  7.194e-02   2.621  0.00930 ** \ncoal.l3          1.526e-04  3.633e-03   0.042  0.96653    \nnatural_gas.l3   5.833e-03  4.337e-03   1.345  0.17984    \nwind.l4          3.581e-02  1.458e-02   2.456  0.01471 *  \nsolar.l4        -3.702e-01  7.178e-02  -5.157 5.06e-07 ***\ncoal.l4         -8.134e-04  3.662e-03  -0.222  0.82438    \nnatural_gas.l4  -1.105e-02  4.308e-03  -2.566  0.01087 *  \nwind.l5          1.976e-02  1.470e-02   1.345  0.17998    \nsolar.l5         1.505e-02  7.539e-02   0.200  0.84188    \ncoal.l5          3.182e-03  3.614e-03   0.880  0.37953    \nnatural_gas.l5   3.612e-03  4.279e-03   0.844  0.39938    \nwind.l6          3.202e-03  1.479e-02   0.217  0.82877    \nsolar.l6        -1.016e-01  7.819e-02  -1.299  0.19504    \ncoal.l6          1.764e-03  3.559e-03   0.495  0.62069    \nnatural_gas.l6  -5.727e-03  4.169e-03  -1.374  0.17076    \nwind.l7         -2.806e-02  1.469e-02  -1.911  0.05718 .  \nsolar.l7         6.280e-02  7.764e-02   0.809  0.41936    \ncoal.l7         -5.481e-03  3.551e-03  -1.543  0.12399    \nnatural_gas.l7   9.725e-03  4.308e-03   2.258  0.02483 *  \nwind.l8         -6.149e-02  1.481e-02  -4.153 4.48e-05 ***\nsolar.l8        -1.309e-02  8.125e-02  -0.161  0.87211    \ncoal.l8         -2.904e-03  3.652e-03  -0.795  0.42723    \nnatural_gas.l8  -8.497e-03  4.402e-03  -1.930  0.05469 .  \nwind.l9         -1.684e-02  1.516e-02  -1.111  0.26765    \nsolar.l9         2.208e-01  8.614e-02   2.564  0.01094 *  \ncoal.l9          3.251e-03  3.723e-03   0.873  0.38334    \nnatural_gas.l9   3.709e-03  4.455e-03   0.833  0.40585    \nwind.l10         3.428e-02  1.399e-02   2.450  0.01496 *  \nsolar.l10        2.496e-01  7.812e-02   3.194  0.00158 ** \ncoal.l10        -5.278e-03  3.160e-03  -1.670  0.09616 .  \nnatural_gas.l10 -1.813e-03  3.448e-03  -0.526  0.59957    \nconst            1.224e+03  8.057e+02   1.519  0.13000    \ntrend            5.912e+00  2.407e+00   2.456  0.01471 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 353.4 on 254 degrees of freedom\nMultiple R-Squared: 0.9971, Adjusted R-squared: 0.9966 \nF-statistic:  2098 on 41 and 254 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation coal: \n===================================== \ncoal = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + wind.l9 + solar.l9 + coal.l9 + natural_gas.l9 + wind.l10 + solar.l10 + coal.l10 + natural_gas.l10 + const + trend \n\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1         -4.461e-01  3.108e-01  -1.435 0.152404    \nsolar.l1         7.785e-01  1.484e+00   0.525 0.600269    \ncoal.l1          5.831e-01  7.150e-02   8.155 1.61e-14 ***\nnatural_gas.l1   7.192e-02  8.225e-02   0.874 0.382722    \nwind.l2         -1.433e-01  3.398e-01  -0.422 0.673565    \nsolar.l2         4.676e-01  1.634e+00   0.286 0.775052    \ncoal.l2          1.483e-01  8.624e-02   1.720 0.086663 .  \nnatural_gas.l2  -1.968e-01  9.992e-02  -1.970 0.049958 *  \nwind.l3          5.886e-01  3.394e-01   1.734 0.084137 .  \nsolar.l3        -1.404e+00  1.672e+00  -0.840 0.401862    \ncoal.l3         -1.148e-01  8.442e-02  -1.360 0.175103    \nnatural_gas.l3  -1.338e-01  1.008e-01  -1.328 0.185326    \nwind.l4         -3.265e-01  3.388e-01  -0.964 0.336003    \nsolar.l4        -2.138e+00  1.668e+00  -1.282 0.201159    \ncoal.l4         -5.747e-02  8.508e-02  -0.675 0.499997    \nnatural_gas.l4   1.065e-01  1.001e-01   1.064 0.288374    \nwind.l5          3.902e-02  3.415e-01   0.114 0.909105    \nsolar.l5         1.513e+00  1.752e+00   0.864 0.388503    \ncoal.l5          1.229e-01  8.398e-02   1.463 0.144590    \nnatural_gas.l5   1.383e-01  9.943e-02   1.390 0.165619    \nwind.l6         -2.918e-01  3.436e-01  -0.849 0.396512    \nsolar.l6         4.197e+00  1.817e+00   2.310 0.021696 *  \ncoal.l6          7.238e-02  8.270e-02   0.875 0.382335    \nnatural_gas.l6  -3.512e-01  9.688e-02  -3.625 0.000349 ***\nwind.l7         -4.420e-01  3.413e-01  -1.295 0.196480    \nsolar.l7        -1.465e+00  1.804e+00  -0.812 0.417590    \ncoal.l7          1.803e-01  8.251e-02   2.185 0.029817 *  \nnatural_gas.l7  -5.628e-02  1.001e-01  -0.562 0.574407    \nwind.l8         -8.256e-02  3.440e-01  -0.240 0.810547    \nsolar.l8        -2.712e+00  1.888e+00  -1.436 0.152092    \ncoal.l8         -3.032e-01  8.485e-02  -3.574 0.000421 ***\nnatural_gas.l8  -5.455e-02  1.023e-01  -0.533 0.594300    \nwind.l9          4.088e-01  3.522e-01   1.161 0.246778    \nsolar.l9         4.886e-01  2.001e+00   0.244 0.807317    \ncoal.l9         -1.575e-01  8.651e-02  -1.820 0.069913 .  \nnatural_gas.l9  -7.517e-02  1.035e-01  -0.726 0.468340    \nwind.l10        -4.922e-01  3.251e-01  -1.514 0.131328    \nsolar.l10        9.746e-01  1.815e+00   0.537 0.591788    \ncoal.l10         1.721e-01  7.343e-02   2.343 0.019899 *  \nnatural_gas.l10  1.305e-01  8.012e-02   1.629 0.104592    \nconst            7.800e+04  1.872e+04   4.166 4.25e-05 ***\ntrend            1.288e+02  5.593e+01   2.304 0.022046 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 8211 on 254 degrees of freedom\nMultiple R-Squared: 0.9682, Adjusted R-squared: 0.9631 \nF-statistic: 188.6 on 41 and 254 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation natural_gas: \n============================================ \nnatural_gas = wind.l1 + solar.l1 + coal.l1 + natural_gas.l1 + wind.l2 + solar.l2 + coal.l2 + natural_gas.l2 + wind.l3 + solar.l3 + coal.l3 + natural_gas.l3 + wind.l4 + solar.l4 + coal.l4 + natural_gas.l4 + wind.l5 + solar.l5 + coal.l5 + natural_gas.l5 + wind.l6 + solar.l6 + coal.l6 + natural_gas.l6 + wind.l7 + solar.l7 + coal.l7 + natural_gas.l7 + wind.l8 + solar.l8 + coal.l8 + natural_gas.l8 + wind.l9 + solar.l9 + coal.l9 + natural_gas.l9 + wind.l10 + solar.l10 + coal.l10 + natural_gas.l10 + const + trend \n\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nwind.l1          2.169e-01  2.643e-01   0.820  0.41276    \nsolar.l1        -2.938e+00  1.262e+00  -2.328  0.02070 *  \ncoal.l1         -1.538e-01  6.082e-02  -2.529  0.01204 *  \nnatural_gas.l1   7.498e-01  6.997e-02  10.717  &lt; 2e-16 ***\nwind.l2         -4.644e-01  2.890e-01  -1.607  0.10939    \nsolar.l2         1.605e+00  1.390e+00   1.155  0.24925    \ncoal.l2          3.563e-02  7.336e-02   0.486  0.62759    \nnatural_gas.l2  -1.807e-01  8.499e-02  -2.125  0.03451 *  \nwind.l3          6.833e-01  2.887e-01   2.366  0.01871 *  \nsolar.l3        -3.196e-01  1.422e+00  -0.225  0.82234    \ncoal.l3         -1.692e-01  7.181e-02  -2.356  0.01924 *  \nnatural_gas.l3  -9.628e-02  8.572e-02  -1.123  0.26241    \nwind.l4         -2.387e-01  2.882e-01  -0.828  0.40818    \nsolar.l4        -1.098e-02  1.419e+00  -0.008  0.99383    \ncoal.l4         -2.624e-02  7.237e-02  -0.363  0.71726    \nnatural_gas.l4   2.203e-02  8.515e-02   0.259  0.79603    \nwind.l5         -5.692e-01  2.905e-01  -1.959  0.05115 .  \nsolar.l5         3.560e+00  1.490e+00   2.389  0.01763 *  \ncoal.l5         -1.298e-01  7.144e-02  -1.818  0.07030 .  \nnatural_gas.l5   9.238e-02  8.458e-02   1.092  0.27580    \nwind.l6         -1.670e-01  2.923e-01  -0.571  0.56835    \nsolar.l6         3.411e-01  1.545e+00   0.221  0.82550    \ncoal.l6          3.845e-03  7.035e-02   0.055  0.95646    \nnatural_gas.l6  -2.381e-01  8.241e-02  -2.889  0.00420 ** \nwind.l7          2.874e-01  2.903e-01   0.990  0.32315    \nsolar.l7        -4.002e+00  1.535e+00  -2.608  0.00965 ** \ncoal.l7          2.969e-01  7.019e-02   4.230 3.27e-05 ***\nnatural_gas.l7  -9.313e-02  8.514e-02  -1.094  0.27510    \nwind.l8         -1.122e-01  2.927e-01  -0.383  0.70182    \nsolar.l8        -3.448e+00  1.606e+00  -2.147  0.03274 *  \ncoal.l8         -1.158e-01  7.218e-02  -1.605  0.10976    \nnatural_gas.l8  -5.717e-02  8.702e-02  -0.657  0.51179    \nwind.l9          3.537e-01  2.996e-01   1.181  0.23876    \nsolar.l9         4.147e+00  1.703e+00   2.436  0.01554 *  \ncoal.l9         -1.142e-01  7.359e-02  -1.551  0.12203    \nnatural_gas.l9  -9.644e-02  8.804e-02  -1.095  0.27443    \nwind.l10        -8.975e-01  2.766e-01  -3.245  0.00133 ** \nsolar.l10        2.210e+00  1.544e+00   1.431  0.15356    \ncoal.l10         8.528e-02  6.246e-02   1.365  0.17341    \nnatural_gas.l10  1.820e-01  6.815e-02   2.670  0.00806 ** \nconst            7.970e+04  1.593e+04   5.005 1.05e-06 ***\ntrend            2.236e+02  4.758e+01   4.699 4.28e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 6984 on 254 degrees of freedom\nMultiple R-Squared: 0.9696, Adjusted R-squared: 0.9647 \nF-statistic: 197.7 on 41 and 254 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n                wind  solar     coal natural_gas\nwind         3108218 198223 -1490440    -1948601\nsolar         198223 124862   325507       48199\ncoal        -1490440 325507 67415908    27635060\nnatural_gas -1948601  48199 27635060    48780515\n\nCorrelation matrix of residuals:\n               wind   solar    coal natural_gas\nwind         1.0000 0.31819 -0.1030    -0.15825\nsolar        0.3182 1.00000  0.1122     0.01953\ncoal        -0.1030 0.11219  1.0000     0.48190\nnatural_gas -0.1583 0.01953  0.4819     1.00000\n\n\n\n\nThe cross-validation results are very similar. Considering the principle of parsimony, we select VAR(8) as the best model.\n\n\nCode\ndf_ts &lt;- df_ts  \n\ny &lt;- ts(df_ts,\n        start = c(2000, 1),  # Jan 2000\n        frequency = 12)\n\nn &lt;- nrow(df_ts)        # total observations, here 198\nh &lt;- 4                  # forecast horizon = 4 months\nR &lt;- 60                 # choose rolling steps (e.g., 60 months)\nk &lt;- n - h + 1 - R      # initial training size\n\ncat(\"Initial training size k =\", k, \"\\n\")\n\n\nInitial training size k = 243 \n\n\nCode\ncat(\"Rolling steps R =\", R, \"\\n\")\n\n\nRolling steps R = 60 \n\n\nCode\n# RMSE matrices: R rows × 4 forecast horizons × 4 variables\nvars_names &lt;- colnames(df_ts)\nrmse_VAR1 &lt;- array(NA, dim = c(R, h, 4),\n                   dimnames = list(NULL, paste0(\"h\",1:4), vars_names))\nrmse_VAR2 &lt;- array(NA, dim = c(R, h, 4),\n                   dimnames = list(NULL, paste0(\"h\",1:4), vars_names))\n\n# 2. Rolling Forecast Loop\n\nfor (i in 1:R) {\n  \n  # ---- training index ----\n  train_end &lt;- k + i - 1\n  xtrain &lt;- y[1:train_end, ]\n  \n  # ---- test index (next 4 months) ----\n  xtest &lt;- y[(train_end + 1):(train_end + h), ]\n  \n  # VAR(8)\n  fit1 &lt;- VAR(xtrain, p = 8, type = \"const\")\n  fc1 &lt;- predict(fit1, n.ahead = h)\n  \n  # Extract forecasts as matrix h × 4\n  f1mat &lt;- sapply(fc1$fcst, function(x) x[,1])\n  \n  # RMSE for each horizon and variable\n  rmse_VAR1[i, , ] &lt;- sqrt((f1mat - xtest)^2)\n  \n  # VAR(10)\n  fit2 &lt;- VAR(xtrain, p = 10, type = \"const\")\n  fc2 &lt;- predict(fit2, n.ahead = h)\n  \n  f2mat &lt;- sapply(fc2$fcst, function(x) x[,1])\n  \n  rmse_VAR2[i, , ] &lt;- sqrt((f2mat - xtest)^2)\n}\n\n# 3. Compute Average RMSE\n\navg_rmse_VAR1 &lt;- apply(rmse_VAR1, c(2,3), mean, na.rm = TRUE)\navg_rmse_VAR2 &lt;- apply(rmse_VAR2, c(2,3), mean, na.rm = TRUE)\n\nprint(\"Average RMSE (VAR(8)):\")\n\n\n[1] \"Average RMSE (VAR(8)):\"\n\n\nCode\nprint(avg_rmse_VAR1)\n\n\n       wind     solar      coal natural_gas\nh1 3033.775  722.5353  9548.566    10926.18\nh2 3431.019  858.1524 12479.094    14739.77\nh3 3778.627  990.0419 14481.603    15876.96\nh4 3385.318 1108.8745 14758.000    13151.50\n\n\nCode\nprint(\"Average RMSE (VAR(10)):\")\n\n\n[1] \"Average RMSE (VAR(10)):\"\n\n\nCode\nprint(avg_rmse_VAR2)\n\n\n       wind     solar      coal natural_gas\nh1 3182.289  654.1270  9972.004   10372.523\nh2 3575.924  777.7966 11344.345   11750.857\nh3 3587.279  933.6982 12007.739   11004.535\nh4 3411.327 1035.7083 12573.067    9314.433\n\n\nCode\n# 4. Example Plot: Solar RMSE\ndf_plot &lt;- data.frame(\n  step = rep(1:R, 2),\n  rmse = c(rmse_VAR1[,1,\"solar\"], rmse_VAR2[,1,\"solar\"]),\n  model = rep(c(\"VAR(8)\", \"VAR(10)\"), each = R)\n)\n\nggplot(df_plot, aes(x = step, y = rmse, color = model)) +\n  geom_line() +\n  labs(title = \"1-step-ahead RMSE for Solar (Rolling Forecast)\",\n       x = \"Rolling step\",\n       y = \"RMSE\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nThe prediction results based on the VAR(8) model indicate that the proportion of electricity generated by traditional fossil energy (coal and natural gas) is expected to continue to decline, while clean energy (solar and wind) is showing a significant growth trend, reflecting the long-term transformation of the energy structure towards low-carbon and renewable directions.\n\n\nCode\nfit &lt;- VAR(df_ts, p = 8, type = \"both\")\nforecast(fit, h=32) %&gt;%\n  autoplot() +\n  xlab(\"Year\") +\n  theme_minimal()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "A time series is any sequence of measurements taken at regular, equally spaced intervals—seconds, minutes, hours, days, months, quarters, or years. Common examples include weather (daily temperature or rainfall), financial markets (daily stock prices or returns), industry indicators (monthly production or sales), electricity demand, traffic counts, and hospital admissions. In time-series analysis we study how these values evolve: their level, trend, seasonal or calendar patterns (e.g., weekdays vs. weekends, holiday effects), cycles, and anomalies. Typical goals are to describe behavior clearly, forecast future values, and quantify the impact of events or policies.\nBecause observations are ordered in time, nearby points tend to be correlated (autocorrelation). This violates the independent-and-identically-distributed assumption behind many standard statistical methods, so naïve cross-sectional tools often mislead. Time-series work must explicitly handle dependence, trend, and seasonality—for example by differencing, seasonal adjustment, and models that use lagged values and errors (e.g., ARIMA/SARIMA, ARIMAX/SARIMAX with external drivers, VAR for multiple series, state-space/ETS, or GARCH when volatility changes over time). Analysts also watch for structural breaks (e.g., policy shifts, COVID), outliers, and missing periods, and they evaluate models with time-aware validation (rolling or blocked splits) rather than random shuffles."
  },
  {
    "objectID": "index.html#what-is-a-time-series",
    "href": "index.html#what-is-a-time-series",
    "title": "Time Series Analysis",
    "section": "",
    "text": "A time series is any sequence of measurements taken at regular, equally spaced intervals—seconds, minutes, hours, days, months, quarters, or years. Common examples include weather (daily temperature or rainfall), financial markets (daily stock prices or returns), industry indicators (monthly production or sales), electricity demand, traffic counts, and hospital admissions. In time-series analysis we study how these values evolve: their level, trend, seasonal or calendar patterns (e.g., weekdays vs. weekends, holiday effects), cycles, and anomalies. Typical goals are to describe behavior clearly, forecast future values, and quantify the impact of events or policies.\nBecause observations are ordered in time, nearby points tend to be correlated (autocorrelation). This violates the independent-and-identically-distributed assumption behind many standard statistical methods, so naïve cross-sectional tools often mislead. Time-series work must explicitly handle dependence, trend, and seasonality—for example by differencing, seasonal adjustment, and models that use lagged values and errors (e.g., ARIMA/SARIMA, ARIMAX/SARIMAX with external drivers, VAR for multiple series, state-space/ETS, or GARCH when volatility changes over time). Analysts also watch for structural breaks (e.g., policy shifts, COVID), outliers, and missing periods, and they evaluate models with time-aware validation (rolling or blocked splits) rather than random shuffles."
  },
  {
    "objectID": "eda1.html",
    "href": "eda1.html",
    "title": "EDA",
    "section": "",
    "text": "Code\nlibrary(dplyr)\nlibrary(tseries)\nlibrary(stringr)\nlibrary(plotly)\nlibrary(scales)\nlibrary(ggplot2)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(tidyverse) \nlibrary(forecast)\nlibrary(gridExtra)\nlibrary(lubridate)\nCode\ndf &lt;- read.csv(\"data/electric.csv\")\ndf &lt;- df %&gt;%\n  mutate(\n    Description = str_extract(Description, \"(?&lt;=From ).*?(?=,)\"),\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))\nCode\netf_symbols &lt;- c(\"ICLN\", \"XLE\")\n\netf_data &lt;- tq_get(etf_symbols,\n                   from = \"2000-01-01\",\n                   to = Sys.Date(),\n                   get = \"stock.prices\")\n\nicln_monthly &lt;- etf_data %&gt;%\n  filter(symbol == \"ICLN\") %&gt;%\n  tq_transmute(select = adjusted,\n               mutate_fun = to.monthly,\n               indexAt = \"lastof\",\n               col_rename = \"adjusted\")\n\nts_icln &lt;- ts(icln_monthly$adjusted,\n              start = c(year(min(icln_monthly$date)), month(min(icln_monthly$date))),\n              frequency = 12)\n\nxle_monthly &lt;- etf_data %&gt;%\n  filter(symbol == \"XLE\") %&gt;%\n  tq_transmute(select = adjusted,\n               mutate_fun = to.monthly,\n               indexAt = \"lastof\",\n               col_rename = \"adjusted\")\n\nts_xle &lt;- ts(xle_monthly$adjusted,\n              start = c(year(min(xle_monthly$date)), month(min(xle_monthly$date))),\n              frequency = 12)\nCode\ndf_n &lt;- read.csv(\"data/naturalgasprice.csv\")\ndf_n&lt;- df_n %&gt;%\n  mutate(\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Value = as.numeric(Value)) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))%&gt;%\n  arrange(Date)\n\nts_np &lt;- ts(df_n$Value,\n              start = c(min(df_n$Year), min(df_n$Month)),\n              frequency = 12)"
  },
  {
    "objectID": "eda1.html#wind",
    "href": "eda1.html#wind",
    "title": "EDA",
    "section": "Wind",
    "text": "Wind\n\nTime Series PlotLag plotDecompositionACF and PACF PlotsAugmented Dickey-Fuller TestDifferencing\n\n\n\n\nCode\nwind_df &lt;- df %&gt;%\n  filter(Description == \"Wind\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_wind &lt;- ts(wind_df$Value,\n              start = c(min(wind_df$Year), min(wind_df$Month)),\n              frequency = 12)\n\np &lt;- autoplot(ts_wind, colour = \"darkblue\") +\n  ggtitle(\"Wind Electricity Net Generation\")+\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Yanjun Chen (Jenny) is a graduate student in the Data Science and Analytics program at Georgetown University. She comes from Zhengjiang, China. She took her undergraduate degree at the Chinese University of Hong Kong, Shenzhen, majoring in data science and big data technology."
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "About Me",
    "section": "",
    "text": "Yanjun Chen (Jenny) is a graduate student in the Data Science and Analytics program at Georgetown University. She comes from Zhengjiang, China. She took her undergraduate degree at the Chinese University of Hong Kong, Shenzhen, majoring in data science and big data technology."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\n2024: M.S. in Data Sicence and analytics at Georgetown University\n2020: B.S. in Data Sicence and big data technology at Chinese University of Hong Kong (Shenzhen)"
  },
  {
    "objectID": "about.html#academic-interests",
    "href": "about.html#academic-interests",
    "title": "About Me",
    "section": "Academic Interests",
    "text": "Academic Interests\n\nEthics in AI and Data Privacy\nBusiness Analysis\nClimate Change Analysis"
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About Me",
    "section": "Contact",
    "text": "Contact\n\nNet ID: yc1265\nGU Email: yc1265@georgetown.edu"
  },
  {
    "objectID": "DL.html",
    "href": "DL.html",
    "title": "Deep Learning for Time Series",
    "section": "",
    "text": "Code\n# Import packages\nimport numpy as np\nimport plotly.express as px\nimport statsmodels.api as sm\nfrom IPython.display import IFrame\nimport seaborn as sns\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import (\n    mean_squared_error,\n    mean_absolute_percentage_error,\n    mean_absolute_error,\n)\n\n# 读取数据\ndf = pd.read_csv(\"data/electric.csv\")\n\n# 提取 Description 中 “From …,” 的内容\ndf['Description'] = df['Description'].str.extract(r'((?&lt;=From ).*?(?=,))')\n\n\n# 转换 YYYYMM\ndf['YYYYMM'] = df['YYYYMM'].astype(str)\ndf['Year'] = df['YYYYMM'].str.slice(0, 4).astype(int)\ndf['Month'] = df['YYYYMM'].str.slice(4, 6).astype(int)\n\n# 筛选\ndf = df[df['Month'] &lt;= 12]\ndf = df[df['Year'] &gt;= 2000]\n\n# 构造日期列\ndf['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(DAY=1))\n\n# 过滤风能并整理 wind_df\nwind_df = (\n    df[df['Description'] == 'Wind']\n      .dropna(subset=['Value'])\n      .assign(Value=lambda x: pd.to_numeric(x['Value'], errors='coerce'))\n      .sort_values('Date')\n)\nprint(wind_df.head())\n\n\n          MSN  YYYYMM    Value  Column_Order Description  \\\n3881  WYETPUS  200001  645.286            12        Wind   \n3882  WYETPUS  200002  705.904            12        Wind   \n3883  WYETPUS  200003  350.019            12        Wind   \n3884  WYETPUS  200004  330.074            12        Wind   \n3885  WYETPUS  200005  408.095            12        Wind   \n\n                       Unit  Year  Month       Date  \n3881  Million Kilowatthours  2000      1 2000-01-01  \n3882  Million Kilowatthours  2000      2 2000-02-01  \n3883  Million Kilowatthours  2000      3 2000-03-01  \n3884  Million Kilowatthours  2000      4 2000-04-01  \n3885  Million Kilowatthours  2000      5 2000-05-01\nCode\ndf = wind_df\n\ndf = df.rename(columns={\"Date\": \"t\", \"Value\": \"y\"})\n\ndf = df[[\"t\",\"y\"]]\n\nprint(\"CHECK NA:\\n\",df.isna().sum())\n\n\nCHECK NA:\n t    0\ny    0\ndtype: int64\nCode\nt=np.array([*range(0,df.shape[0])])\n\nx=np.array(df['y']).reshape(t.shape[0],1)\n\nfeature_columns=[0] # columns to use as features\n\ntarget_columns=[0]  # columns to use as targets\n\ndef form_arrays(x,lookback=3,delay=1,step=1,feature_columns=[0],target_columns=[0],unique=False,verbose=False):\n    # verbose=True --&gt; report and plot for debugging\n    # unique=True --&gt; don't re-sample: \n    # x1,x2,x3 --&gt; x4 then x4,x5,x6 --&gt; x7 instead of x2,x3,x4 --&gt; x5\n\n    # initialize \n    i_start=0; count=0; \n    \n    # initialize output arrays with samples \n    x_out=[]\n    y_out=[]\n    \n    # sequentially build mini-batch samples\n    while i_start+lookback+delay&lt; x.shape[0]:\n        \n        # define index bounds\n        i_stop=i_start+lookback\n        i_pred=i_stop+delay\n        \n        # report if desired \n        if verbose and count&lt;2: print(\"indice range:\",i_start,i_stop,\"--&gt;\",i_pred)\n\n        # define arrays: \n        # method-1: buggy due to indexing from left \n        # numpy's slicing --&gt; start:stop:step\n        # xtmp=x[i_start:i_stop+1:steps]\n        \n        # method-2: non-vectorized but cleaner\n        indices_to_keep=[]; j=i_stop\n        while  j&gt;=i_start:\n            indices_to_keep.append(j)\n            j=j-step\n\n        # create mini-batch sample\n        xtmp=x[indices_to_keep,:]    # isolate relevant indices\n        xtmp=xtmp[:,feature_columns] # isolate desire features\n        ytmp=x[i_pred,target_columns]\n        x_out.append(xtmp); y_out.append(ytmp); \n        \n        # report if desired \n        if verbose and count&lt;2: print(xtmp, \"--&gt;\",ytmp)\n        if verbose and count&lt;2: print(\"shape:\",xtmp.shape, \"--&gt;\",ytmp.shape)\n\n        # PLOT FIRST SAMPLE IF DESIRED FOR DEBUGGING    \n        if verbose and count&lt;2:\n            fig, ax = plt.subplots()\n            ax.plot(x,'b-')\n            ax.plot(x,'bx')\n            ax.plot(indices_to_keep,xtmp,'go')\n            ax.plot(i_pred*np.ones(len(target_columns)),ytmp,'ro')\n            plt.show()\n            \n        # UPDATE START POINT \n        if unique: i_start+=lookback \n        i_start+=1; count+=1\n        \n    return np.array(x_out),np.array(y_out)\n\ndef regression_report(yt,ytp,yv,yvp):\n    print(\"---------- Regression report ----------\")\n    \n    print(\"TRAINING:\")\n    print(\" RMSE:\",(mean_squared_error(yt,ytp))**(1/2))\n    print(\" MSE:\",mean_squared_error(yt,ytp))\n    print(\" MAE:\",mean_absolute_error(yt,ytp))\n    # print(\" MAPE:\",mean_absolute_percentage_error(Yt,Ytp))\n    \n    # PARITY PLOT\n    fig, ax = plt.subplots()\n    ax.plot(yt,ytp,'ro')\n    ax.plot(yt,yt,'b-')\n    ax.set(xlabel='y_data', ylabel='y_predicted',\n        title='Training data parity plot (line y=x represents a perfect fit)')\n    plt.show()\n    \n    # PLOT PART OF THE PREDICTED TIME-SERIES\n    frac_plot=1.0\n    upper=int(frac_plot*yt.shape[0]); \n    # print(int(0.5*yt.shape[0]))\n    fig, ax = plt.subplots()\n    ax.plot(yt[0:upper],'b-')\n    ax.plot(ytp[0:upper],'r-',alpha=0.5)\n    ax.plot(ytp[0:upper],'ro',alpha=0.25)\n    ax.set(xlabel='index', ylabel='y(t (blue=actual & red=prediction)', title='Training: Time-series prediction')\n    plt.show()\n\n      \n    print(\"VALIDATION:\")\n    print(\" RMSE:\",(mean_squared_error(yv,yvp))**(1/2))\n    print(\" MSE:\",mean_squared_error(yv,yvp))\n    print(\" MAE:\",mean_absolute_error(yv,yvp))\n    # print(\" MAPE:\",mean_absolute_percentage_error(Yt,Ytp))\n    \n    # PARITY PLOT \n    fig, ax = plt.subplots()\n    ax.plot(yv,yvp,'ro')\n    ax.plot(yv,yv,'b-')\n    ax.set(xlabel='y_data', ylabel='y_predicted',\n        title='Validation data parity plot (line y=x represents a perfect fit)')\n    plt.show()\n    \n    # PLOT PART OF THE PREDICTED TIME-SERIES\n    upper=int(frac_plot*yv.shape[0])\n    fig, ax = plt.subplots()\n    ax.plot(yv[0:upper],'b-')\n    ax.plot(yvp[0:upper],'r-',alpha=0.5)\n    ax.plot(yvp[0:upper],'ro',alpha=0.25)\n    ax.set(xlabel='index', ylabel='y(t) (blue=actual & red=prediction)', title='Validation: Time-series prediction')\n    plt.show()\n\ndef history_plot(history):\n    FS=18   #FONT SIZE\n    # PLOTTING THE TRAINING AND VALIDATION LOSS \n    history_dict = history.history\n    loss_values = history_dict[\"loss\"]\n    val_loss_values = history_dict[\"val_loss\"]\n    epochs = range(1, len(loss_values) + 1)\n    plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n    plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n    plt.title(\"Training and validation loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\nCode\nfig, ax = plt.subplots()\nfor i in range(0,x.shape[1]):\n    ax.plot(t, x[:,i],'o',alpha = 0.5)\n    ax.plot(t, x[:,i],\"-\")\nax.plot(t, 0*x[:,0],\"-\") # add baseline for reference \nplt.title(\"Raw Data\")\nplt.show()\nCode\nfig, ax = plt.subplots()\nfor i in range(0,x.shape[1]):\n    ax.plot(t, x[:,i],'o')\n    ax.plot(t, x[:,i],\"-\")\nax.plot(t, 0*x[:,0],\"-\") # add baseline for reference \nplt.title(\"Normalized Data\")\nplt.show()\nCode\nsplit_fraction=0.8\ncut=int(split_fraction*x.shape[0]) \ntt=t[0:cut]; xt=x[0:cut]\ntv=t[cut:]; xv=x[cut:]\n\n# visualize normalized data \nfig, ax = plt.subplots()\nfor i in range(0,x.shape[1]):\n    ax.plot(tt, xt[:,i],'ro',alpha=0.25)\n    ax.plot(tt, xt[:,i],\"g-\")\nfor i in range(0,x.shape[1]):\n    ax.plot(tv, xv[:,i],'bo',alpha=0.25)\n    ax.plot(tv, xv[:,i],\"g-\")\nplt.title(\"Train/Validation Split\")\nplt.show()\nCode\n# training\nL=5; S=1; D=1\nXt,Yt=form_arrays(xt,lookback=L,delay=D,step=S,feature_columns=feature_columns,target_columns=target_columns,unique=False,verbose=False)\n\n# validation\nXv,Yv=form_arrays(xv,lookback=L,delay=D,step=S,feature_columns=feature_columns,target_columns=target_columns,unique=False,verbose=False)\n\nprint(\"training:\",Xt.shape,Yt.shape)\nprint(\"validation:\",Xv.shape,Yv.shape)\n\n\ntraining: (238, 6, 1) (238, 1)\nvalidation: (56, 6, 1) (56, 1)"
  },
  {
    "objectID": "DL.html#univariate-deep-learning-forecasting",
    "href": "DL.html#univariate-deep-learning-forecasting",
    "title": "Deep Learning for Time Series",
    "section": "Univariate Deep Learning Forecasting",
    "text": "Univariate Deep Learning Forecasting\n\nRNNLSTMGRU\n\n\n\n\nCode\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\n\n# HYPERPARAMETERS\noptimizer = \"rmsprop\"\nloss_function = keras.losses.MeanSquaredError()   # ⭐需要实例化\nlearning_rate = 0.001\nnumbers_epochs = 200\nL2 = 0  # 1e-4\ninput_shape = (Xt.shape[1], Xt.shape[2])\n\n# Choose batch size\nbatch_size = 1   # stochastic training\n# batch_size = int(len(x_train)/2.)  # mini-batch training\n# batch_size = len(Xt)               # full batch training\n\n# BUILD MODEL\nrecurrent_hidden_units = 32\n\n# Create model\nmodel = keras.Sequential()\n\n# Add recurrent layer\n# Uncomment one of the following if you want LSTM/GRU:\n# model.add(layers.LSTM(\n# model.add(layers.GRU(\nmodel.add(layers.SimpleRNN(\n    units=recurrent_hidden_units,\n    return_sequences=False,\n    input_shape=input_shape,\n    recurrent_regularizer=regularizers.L2(L2),\n    activation='relu'\n))\n\n# Output layer (scalar regression)\nmodel.add(layers.Dense(1, activation='linear'))\n\n# Compile model (⭐建议将 optimizer 用学习率实例化)\nmodel.compile(\n    optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n    loss=loss_function\n)\n\n# Summary\nmodel.summary()\n\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn (SimpleRNN)          │ (None, 32)             │         1,088 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (Dense)                   │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 1,121 (4.38 KB)\n\n\n\n Trainable params: 1,121 (4.38 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\n\nCode\n# # print(\"initial parameters:\", model.get_weights())\n\n# # COMPILING THE MODEL \nopt = keras.optimizers.RMSprop(learning_rate=learning_rate)\nmodel.compile(optimizer=opt, loss=loss_function)\n\n# TRAINING YOUR MODEL\nhistory = model.fit(Xt,\n                    Yt,\n                    epochs=numbers_epochs,\n                    batch_size=batch_size, verbose=False,\n                    validation_data=(Xv, Yv))\n\n# History plot\nhistory_plot(history)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Predictions \nYtp=model.predict(Xt)\nYvp=model.predict(Xv) \n\n\n\n1/8 ━━━━━━━━━━━━━━━━━━━━ 1s 153ms/step\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step \n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n8/8 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step\n\n\n1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\n\n\n\n\n\n\nCode\n# REPORT\nregression_report(Yt,Ytp,Yv,Yvp)\n\n\n---------- Regression report ----------\nTRAINING:\n RMSE: 1680.0738320989756\n MSE: 2822648.0813037367\n MAE: 1075.543225088424\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVALIDATION:\n RMSE: 5915.738988228709\n MSE: 34995967.776849225\n MAE: 4691.401568638393"
  },
  {
    "objectID": "DL.html#forecasting-performance-reflection",
    "href": "DL.html#forecasting-performance-reflection",
    "title": "Deep Learning for Time Series",
    "section": "Forecasting Performance Reflection",
    "text": "Forecasting Performance Reflection"
  },
  {
    "objectID": "DL.html#multivariate-forecasting",
    "href": "DL.html#multivariate-forecasting",
    "title": "Deep Learning for Time Series",
    "section": "Multivariate Forecasting",
    "text": "Multivariate Forecasting\n\nRNNLSTMGRU"
  },
  {
    "objectID": "DL.html#model-comparison",
    "href": "DL.html#model-comparison",
    "title": "Deep Learning for Time Series",
    "section": "Model Comparison",
    "text": "Model Comparison"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "Code\nlibrary(dplyr)\nlibrary(tseries)\nlibrary(stringr)\nlibrary(plotly)\nlibrary(scales)\nlibrary(ggplot2)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(tidyverse) \nlibrary(forecast)\nlibrary(gridExtra)\nlibrary(lubridate)\nCode\ndf &lt;- read.csv(\"data/electric.csv\")\ndf &lt;- df %&gt;%\n  mutate(\n    Description = str_extract(Description, \"(?&lt;=From ).*?(?=,)\"),\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))\nCode\netf_symbols &lt;- c(\"ICLN\", \"XLE\")\n\netf_data &lt;- tq_get(etf_symbols,\n                   from = \"2000-01-01\",\n                   to = Sys.Date(),\n                   get = \"stock.prices\")\n\nicln_monthly &lt;- etf_data %&gt;%\n  filter(symbol == \"ICLN\") %&gt;%\n  tq_transmute(select = adjusted,\n               mutate_fun = to.monthly,\n               indexAt = \"lastof\",\n               col_rename = \"adjusted\")\n\nts_icln &lt;- ts(icln_monthly$adjusted,\n              start = c(year(min(icln_monthly$date)), month(min(icln_monthly$date))),\n              frequency = 12)\n\nxle_monthly &lt;- etf_data %&gt;%\n  filter(symbol == \"XLE\") %&gt;%\n  tq_transmute(select = adjusted,\n               mutate_fun = to.monthly,\n               indexAt = \"lastof\",\n               col_rename = \"adjusted\")\n\nts_xle &lt;- ts(xle_monthly$adjusted,\n              start = c(year(min(xle_monthly$date)), month(min(xle_monthly$date))),\n              frequency = 12)\nCode\ndf_n &lt;- read.csv(\"data/naturalgasprice.csv\")\ndf_n&lt;- df_n %&gt;%\n  mutate(\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Value = as.numeric(Value)) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))%&gt;%\n  arrange(Date)\n\nts_np &lt;- ts(df_n$Value,\n              start = c(min(df_n$Year), min(df_n$Month)),\n              frequency = 12)"
  },
  {
    "objectID": "EDA.html#time-series-plot",
    "href": "EDA.html#time-series-plot",
    "title": "EDA",
    "section": "Time Series Plot",
    "text": "Time Series Plot\n\nWindCoalNatural GasNuclear Electric PowerHydroelectric PowerSolarWTI Oil priceHenry Hub Natural Gas priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\nwind_df &lt;- df %&gt;%\n  filter(Description == \"Wind\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_wind &lt;- ts(wind_df$Value,\n              start = c(min(wind_df$Year), min(wind_df$Month)),\n              frequency = 12)\n\np &lt;- autoplot(ts_wind, colour = \"darkblue\") +\n  ggtitle(\"Wind Electricity Net Generation\")+\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p)   \n\n\n\n\n\n\nThe time series of wind electricity net generation from 2000 to 2025 reveals a pronounced upward trend, reflecting the rapid expansion of renewable energy capacity. It also exhibits strong seasonality, with recurring intra-annual fluctuations linked to climatic conditions and demand cycles. Moreover, the increasing amplitude of variation over time suggests rising volatility as generation scales up. These features imply that forecasting requires models capable of addressing both trend and seasonality, while the observed dynamics underscore the growing significance of wind energy in the energy transition and the operational challenges of managing its variability.\n\n\n\n\nCode\ncoal_df &lt;- df %&gt;%\n  filter(Description == \"Coal\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_coal &lt;- ts(coal_df$Value,\n              start = c(min(coal_df$Year), min(coal_df$Month)),\n              frequency = 12)\n\np &lt;- autoplot(ts_coal, colour = \"darkblue\") +\n  ggtitle(\"Coal Electricity Net Generation\") +\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p) \n\n\n\n\n\n\nThe time series of coal electricity net generation exhibits a pronounced long-term declining trend, particularly evident after 2010. This structural downturn is accompanied by persistent seasonal fluctuations, indicative of cyclical demand for electricity. The abrupt decline starting around 2012 likely corresponds with policy shifts, environmental regulations, and the increasing competitiveness of alternative energy sources such as natural gas and renewables. The data reflects a fundamental transformation in the energy mix, with coal playing a diminishing role in electricity generation.\n\n\n\n\nCode\nn_df &lt;- df %&gt;%\n  filter(Description == \"Natural Gas\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_n &lt;- ts(n_df$Value,\n              start = c(min(n_df$Year), min(n_df$Month)),\n              frequency = 12)\n\np &lt;- autoplot(ts_n, colour = \"darkblue\") +\n  ggtitle(\"Natural Gas Electricity Net Generation\") +\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p) \n\n\n\n\n\n\nThe net electricity generation from natural gas shows a pronounced upward trend, indicating its growing role as a transitional energy source. It also exhibits strong seasonality, with recurring intra-annual fluctuations linked to climatic conditions and demand cycles. This expansion is driven by the relative cost-efficiency of natural gas, its abundance in domestic supply, and its lower carbon intensity compared with coal. The increasing reliance on natural gas highlights its strategic importance in meeting rising energy demand while supporting decarbonization goals, positioning it as a central component of the evolving energy mix.\n\n\n\n\nCode\nnuclear_df &lt;- df %&gt;%\n  filter(Description == \"Nuclear Electric Power\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_nuclear &lt;- ts(nuclear_df$Value,\n              start = c(min(nuclear_df$Year), min(nuclear_df$Month)),\n              frequency = 12)\n\np &lt;- autoplot(ts_nuclear, colour = \"darkblue\") +\n  ggtitle(\"Nuclear Electric Power Electricity Net Generation\") +\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p) \n\n\n\n\n\n\nThe net electricity generation from nuclear power remains relatively stable over time, reflecting its role as a consistent baseload energy source. Although growth has been limited compared to renewables, nuclear energy continues to provide reliable, low-carbon electricity that supports energy security and decarbonization objectives. Its long-term stability highlights both the technological maturity of nuclear power and the challenges of expanding capacity due to safety concerns, high capital costs, and lengthy regulatory processes.\n\n\n\n\nCode\nhy_df &lt;- df %&gt;%\n  filter(Description == \"Conventional Hydroelectric Power\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_hy &lt;- ts(hy_df$Value,\n              start = c(min(hy_df$Year), min(hy_df$Month)),\n              frequency = 12)\n\np &lt;- autoplot(ts_hy, colour = \"darkblue\") +\n  ggtitle(\"Hydroelectric Power Electricity Net Generation\") +\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p) \n\n\n\n\n\n\nThe net electricity generation from hydroelectric power shows a relatively steady pattern with modest fluctuations, largely influenced by hydrological conditions and regional water resource availability. While it remains a mature and established renewable source, the absence of significant long-term growth reflects geographical and environmental constraints that limit large-scale expansion. Nevertheless, hydroelectricity continues to play a crucial role in providing reliable renewable energy and grid stability, particularly through its flexibility in balancing intermittent solar and wind generation.\n\n\n\n\nCode\nsolar_df &lt;- df %&gt;%\n  filter(Description == \"Solar\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_solar &lt;- ts(solar_df$Value,\n              start = c(min(solar_df$Year), min(solar_df$Month)),\n              frequency = 12)\n\np &lt;- autoplot(ts_solar, colour = \"darkblue\") +\n  ggtitle(\"Solar Electricity Net Generation\") +\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p) \n\n\n\n\n\n\nThe net electricity generation from solar energy demonstrates a strong upward trajectory, reflecting rapid technological advancements, declining production costs, and supportive policy frameworks. This rise underscores the increasing competitiveness of solar power within the broader energy market, as well as its central role in advancing decarbonization and sustainable development objectives. The accelerating growth also highlights shifting investment priorities toward renewable energy and the expanding societal demand for cleaner electricity sources.\n\n\n\n\nCode\nwti &lt;- read.csv(\"data/WTIprice.csv\")\nwti &lt;- wti %&gt;%\n  rename(date = observation_date) %&gt;%\n  mutate(date = as.Date(date)) %&gt;%\n  rename(WTI = POILWTIUSDM) %&gt;%\n  mutate(WTI = as.numeric(WTI))\n\nts_wti &lt;- ts(wti$WTI,\n              start = c(1990, 1),\n              frequency = 12)\n\np &lt;- autoplot(ts_wti, colour = \"darkblue\") +\n  ggtitle(\"WTI Oil price\")+\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p)   \n\n\n\n\n\n\nThe historical trend of West Texas Intermediate (WTI) crude oil prices is characterized by pronounced volatility, reflecting the commodity’s sensitivity to global supply-demand dynamics, geopolitical tensions, and macroeconomic cycles. Periods of sharp spikes, such as during the mid-2000s oil boom, and dramatic collapses, such as in 2008 and 2020, illustrate the market’s exposure to both financial crises and unprecedented demand shocks. Despite these fluctuations, WTI oil remains a key global benchmark, and its long-term movements serve as a critical indicator of energy market stability, investment strategies, and the broader transition toward alternative energy sources.\n\n\n\n\nCode\np &lt;- autoplot(ts_np, colour = \"darkblue\") +\n  ggtitle(\"Henry Hub Natural Gas price \")+\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p)  \n\n\n\n\n\n\nThe Henry Hub natural gas price series exhibits strong seasonal patterns superimposed on a gradually increasing trend. The clear and recurring intra-annual fluctuations reflect consistent seasonal demand cycles, likely driven by heating and cooling needs. Notable volatility spikes, such as those observed in 2008 and 2022, suggest the influence of external shocks or supply disruptions. Unlike the Renewable Energy ETF (ICLN), this series demonstrates more regular and predictable dynamics, indicative of a mature commodity market responsive to both fundamental and cyclical factors.\n\n\n\n\nCode\np &lt;- autoplot(ts_icln, colour = \"darkblue\") +\n  ggtitle(\"Renewable Energy ETF (ICLN) \")+\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p)  \n\n\n\n\n\n\nThe historical price trend of the Renewable Energy ETF (ICLN) reveals a long-term upward movement interrupted by significant short-term volatility. The sharp rise during 2020–2021 likely reflects heightened investor interest in clean energy, possibly influenced by political shifts and global ESG momentum. However, the subsequent decline suggests either market correction or reduced optimism. While no clear seasonal pattern is observed, the data displays cyclic behavior tied to broader macroeconomic and policy-related factors, implying that the clean energy sector is both promising and highly reactive to external stimuli.\n\n\n\n\nCode\np &lt;- autoplot(ts_xle, colour = \"darkblue\") +\n  ggtitle(\"Energy Select Sector SPDR Fund (XLE)\")+\n  xlab(\"Time\") +\n  ylab(\"Value\") +\n  theme_minimal()\n\nggplotly(p)  \n\n\n\n\n\n\nThe time series of the Energy Select Sector SPDR Fund (XLE) displays a long-term upward trend with significant cyclical fluctuations that broadly align with major energy market dynamics. Periods of sharp decline, such as during the 2008 financial crisis and the 2020 pandemic shock, indicate the fund’s sensitivity to macroeconomic downturns and global oil price collapses. While no clear seasonality is evident, the repeated boom–bust cycles reflect the commodity-linked nature of the energy sector, driven by supply-demand imbalances, geopolitical shocks, and structural shifts in global energy consumption. Notably, the strong recovery after 2020 underscores renewed investor confidence in traditional energy despite the concurrent growth of renewable alternatives. This suggests that fossil fuel–linked equities remain resilient and strategically significant in the evolving energy mix."
  },
  {
    "objectID": "EDA.html#lag-plot",
    "href": "EDA.html#lag-plot",
    "title": "EDA",
    "section": "Lag plot",
    "text": "Lag plot\n\nWindCoalNatural GasNuclear Electric PowerHydroelectric PowerSolarWTI Oil priceHenry Hub Natural Gas priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\ngglagplot(ts_wind, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for wind\")+theme(axis.text.x=element_text(angle=45, hjust=1))\n\n\n\n\n\n\n\n\n\nThe autocorrelation across all lags is very strong here.\n\n\n\n\nCode\ngglagplot(ts_coal, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for coal\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe power has the strongest autocorrelation at lag 12. However, the other shows weak autocorrelation.\n\n\n\n\nCode\ngglagplot(ts_n, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for natural gas\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe power has the strongest autocorrelation at lag 12. However, the other shows weak autocorrelation.\n\n\n\n\nCode\ngglagplot(ts_nuclear, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for nuclear electric power\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe power has the strongest autocorrelation at lag 12. However, the other autocorrelation is very weak.\n\n\n\n\nCode\ngglagplot(ts_hy, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for hydroelectric power\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nWe see no autocorrelation amongst any of the lags here.\n\n\n\n\nCode\ngglagplot(ts_solar, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for solar\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe price has the strongest autocorrelation at the first lag. However, after that, the autocorrelation is very weak.\n\n\n\n\nCode\ngglagplot(ts_wti, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for WTI oil price\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe autocorrelation is very strong for the first 3-4 lags. After that, the autocorrelations begin to get exponentially weaker.\n\n\n\n\nCode\ngglagplot(ts_np, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for Natural Gas price\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe price has the strongest autocorrelation at the first lag. However, after that, the autocorrelation is very weak.\n\n\n\n\nCode\ngglagplot(ts_icln, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot fo ICLN\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe autocorrelations are very strong for lags 1 and 2. Lag 3 still has a fairly strong autocorrelation, but it begins to dwindle as the lags progress.\n\n\n\n\nCode\ngglagplot(ts_xle, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for XLE\")+theme(axis.text.x=element_text(angle=45, hjust=1))   \n\n\n\n\n\n\n\n\n\nThe autocorrelation is very strong for the first 3-4 lags. After that, the autocorrelations begin to get exponentially weaker."
  },
  {
    "objectID": "EDA.html#decomposition",
    "href": "EDA.html#decomposition",
    "title": "EDA",
    "section": "Decomposition",
    "text": "Decomposition\n\nWindCoalNatural GasNuclear Electric PowerHydroelectric PowerSolarWTI Oil priceHenry Hub Natural Gas priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_wind, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for wind\") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_coal, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for coal\")  + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_n, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for natural gas\")  + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_nuclear, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for nuclear electric power\")  + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_hy, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for hydroelectric power\") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_solar, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for solar\") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_wti, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for WTI Oil price\") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_np, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for Natural Gas price\") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_icln, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for ICLN\") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndecomposed &lt;- decompose(ts_xle, type = \"multiplicative\")\nautoplot(decomposed) + ggtitle(\"Decomposition Plot for XLE\") + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\nFor all of the data series, these decomposition plots generally align with the conclusions we discussed earlier. They confirm the observed trends, seasonality, and the diminishing impact of past values over time. The decompositions help to visualize the underlying components of each series, such as the trend, seasonality, and residuals, further supporting our initial analysis of the data patterns."
  },
  {
    "objectID": "EDA.html#acf-and-pacf-plots",
    "href": "EDA.html#acf-and-pacf-plots",
    "title": "EDA",
    "section": "ACF and PACF Plots",
    "text": "ACF and PACF Plots\n\nWindCoalNatural GasNuclear Electric PowerHydroelectric PowerSolarWTI Oil priceHenry Hub Natural Gas priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_wind)+ggtitle(\"ACF Plot for Wind\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_wind)+ggtitle(\"PACF Plot for Wind\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nACF plot shows significant lags at all values. The PACF plot only shows significant correlation at the first lag. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_coal)+ggtitle(\"ACF Plot for Coal\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_coal)+ggtitle(\"PACF Plot for Coal\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nACF plot shows significant lags at all values. The PACF plot only shows significant correlation at the first lag. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_n)+ggtitle(\"ACF Plot for Natural Gas\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_n)+ggtitle(\"PACF Plot for Natural Gas\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nACF plot shows significant lags at all values. The PACF plot only shows significant correlation at the first lag. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_nuclear)+ggtitle(\"ACF Plot for Nuclear Electric Power\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_nuclear)+ggtitle(\"PACF Plot for Nuclear Electric Power\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nThe ACF and PACF plots show significant spikes at lag 12 and its multiples, suggesting strong seasonality. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_hy)+ggtitle(\"ACF Plot for Hydroelectric Power\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_hy)+ggtitle(\"PACF Plot for Hydroelectric Power\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nThe ACF and PACF plots show significant spikes at lag 12 and its multiples, suggesting strong seasonality. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_solar)+ggtitle(\"ACF Plot for Solar\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_solar)+ggtitle(\"PACF Plot for Solar\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nACF plot shows significant lags at all values. The PACF plot only shows significant correlation at the first lag. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_wti)+ggtitle(\"ACF Plot for WTI Oil price\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_wti)+ggtitle(\"PACF Plot for WTI Oil price\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nACF plot shows significant lags at all values. The PACF plot only shows significant correlation at the first and second lags. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_np)+ggtitle(\"ACF Plot for Natural Gas price \")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_np)+ggtitle(\"PACF Plot for Natural Gas price \") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nThe ACF and PACF plots show significant spikes at lag 12 and its multiples, suggesting strong seasonality. The series is not stationary and likely requires seasonal differencing to achieve stationarity.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_icln)+ggtitle(\"ACF Plot for ICLN\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_icln)+ggtitle(\"PACF Plot for ICLN\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nACF plot shows significant lags at all values. The PACF plot only shows significant correlation at the first lag. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations.\n\n\n\n\nCode\nnvidiaacf &lt;- ggAcf(ts_xle)+ggtitle(\"ACF Plot for XLE\")+\ngeom_segment(lineend = \"butt\", color = \"darkblue\") +\n  geom_hline(yintercept = 0, color = \"darkblue\") \nnvidiapacf &lt;- ggPacf(ts_xle)+ggtitle(\"PACF Plot for XLE\") + \n  geom_segment(lineend = \"butt\", color = \"darkblue\") +\n    geom_hline(yintercept = 0, color = \"darkblue\") \ngrid.arrange(nvidiaacf, nvidiapacf, nrow=2)\n\n\n\n\n\n\n\n\n\nACF plot shows significant lags at all values. The PACF plot only shows significant correlation at the first lag. Since there are several values above the confidence interval in the ACF plot, we cannot say this plot is stationary due to significant autocorrelations."
  },
  {
    "objectID": "EDA.html#augmented-dickey-fuller-test",
    "href": "EDA.html#augmented-dickey-fuller-test",
    "title": "EDA",
    "section": "Augmented Dickey-Fuller Test",
    "text": "Augmented Dickey-Fuller Test\n\nWindCoalNatural GasNuclear Electric PowerHydroelectric PowerSolarWTI Oil priceHenry Hub Natural Gas priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\nadf.test(ts_wind)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_wind\nDickey-Fuller = -4.3, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_coal)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_coal\nDickey-Fuller = -3.7664, Lag order = 6, p-value = 0.02107\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_n)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_n\nDickey-Fuller = -10.868, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_nuclear)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_nuclear\nDickey-Fuller = -4.4928, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_hy)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_hy\nDickey-Fuller = -8.0505, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_wind)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_wind\nDickey-Fuller = -4.3, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_wti)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_wti\nDickey-Fuller = -2.7519, Lag order = 7, p-value = 0.2598\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_np)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_np\nDickey-Fuller = -4.8703, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_icln)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_icln\nDickey-Fuller = -2.134, Lag order = 5, p-value = 0.5198\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(ts_xle)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_xle\nDickey-Fuller = -1.9316, Lag order = 6, p-value = 0.6052\nalternative hypothesis: stationary\n\n\n\n\n\nThe p-values in the ADF (Augmented Dickey-Fuller) tests for WTI, ICLN and XLE are above 0.05, which means we fail to reject the null hypothesis of the test. This means we need to conduct further modifications to ensure that each plot can become stationary. These three ts align with what we found in our ACF/PACF plots."
  },
  {
    "objectID": "EDA.html#differencing",
    "href": "EDA.html#differencing",
    "title": "EDA",
    "section": "Differencing",
    "text": "Differencing\n\nWTI Oil priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\ndiff1 &lt;- ggAcf(diff(ts_wti), 50, main=\"ACF of First Differencing\")+ theme_bw()+\ngeom_segment(lineend = \"butt\", color = \"#5a3196\") +\n  geom_hline(yintercept = 0, color = \"#5a3196\") \ndiff2 &lt;- ggAcf(diff(ts_wti, 2), 50, main=\"ACF of Second Differencing\")+ theme_bw()+\n  geom_segment(lineend = \"butt\", color = \"#5a3196\") +\n    geom_hline(yintercept = 0, color = \"#5a3196\") \ngrid.arrange(diff1, diff2, nrow=2)\n\n\n\n\n\n\n\n\n\nUsing first differencing, we are able to make the WTI Oil price stationary.\n\n\n\n\nCode\ndiff1 &lt;- ggAcf(diff(ts_icln), 50, main=\"ACF of First Differencing\")+ theme_bw()+\ngeom_segment(lineend = \"butt\", color = \"#5a3196\") +\n  geom_hline(yintercept = 0, color = \"#5a3196\") \ndiff2 &lt;- ggAcf(diff(ts_icln, 2), 50, main=\"ACF of Second Differencing\")+ theme_bw()+\n  geom_segment(lineend = \"butt\", color = \"#5a3196\") +\n    geom_hline(yintercept = 0, color = \"#5a3196\") \ngrid.arrange(diff1, diff2, nrow=2)\n\n\n\n\n\n\n\n\n\nUsing first differencing, we are able to make the ICLN stationary.\n\n\n\n\nCode\ndiff1 &lt;- ggAcf(diff(ts_xle), 50, main=\"ACF of First Differencing\")+ theme_bw()+\ngeom_segment(lineend = \"butt\", color = \"#5a3196\") +\n  geom_hline(yintercept = 0, color = \"#5a3196\") \ndiff2 &lt;- ggAcf(diff(ts_xle, 2), 50, main=\"ACF of Second Differencing\")+ theme_bw()+\n  geom_segment(lineend = \"butt\", color = \"#5a3196\") +\n    geom_hline(yintercept = 0, color = \"#5a3196\") \ngrid.arrange(diff1, diff2, nrow=2)\n\n\n\n\n\n\n\n\n\nUsing first differencing, we are able to make the XLE stationary."
  },
  {
    "objectID": "EDA.html#adf-test-after-differencing",
    "href": "EDA.html#adf-test-after-differencing",
    "title": "EDA",
    "section": "ADF Test after Differencing",
    "text": "ADF Test after Differencing\n\nWTI Oil priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\nadf.test(diff(diff(ts_wti, lag=4)))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(diff(ts_wti, lag = 4))\nDickey-Fuller = -12.678, Lag order = 7, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(diff(diff(ts_icln, lag=4)))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(diff(ts_icln, lag = 4))\nDickey-Fuller = -7.5899, Lag order = 5, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(diff(diff(ts_xle, lag=4)))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(diff(ts_xle, lag = 4))\nDickey-Fuller = -8.4525, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\nAll adjusted tests reveal a p-value of less than 0.05, confirming that our data is now stationary."
  },
  {
    "objectID": "EDA.html#moving-average",
    "href": "EDA.html#moving-average",
    "title": "EDA",
    "section": "Moving Average",
    "text": "Moving Average\n\nWindCoalNatural GasNuclear Electric PowerHydroelectric PowerSolarWTI Oil priceHenry Hub Natural Gas priceRenewable Energy ETF (ICLN)Energy Select Sector SPDR Fund (XLE)\n\n\n\n\nCode\nautoplot(ts_wind) +\n  autolayer(ma(ts_wind, 12), series=\"12-MA\") +\n  autolayer(ma(ts_wind, 24), series=\"24-MA\") +\n  autolayer(ma(ts_wind, 3), series=\"3-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_coal) +\n  autolayer(ma(ts_coal, 12), series=\"12-MA\") +\n  autolayer(ma(ts_coal, 24), series=\"24-MA\") +\n  autolayer(ma(ts_coal, 3), series=\"3-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_n) +\n  autolayer(ma(ts_n, 12), series=\"12-MA\") +\n  autolayer(ma(ts_n, 24), series=\"24-MA\") +\n  autolayer(ma(ts_n, 3), series=\"3-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_nuclear) +\n  autolayer(ma(ts_nuclear, 12), series=\"12-MA\") +\n  autolayer(ma(ts_nuclear, 24), series=\"24-MA\") +\n  autolayer(ma(ts_nuclear, 3), series=\"3-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_hy) +\n  autolayer(ma(ts_hy, 12), series=\"12-MA\") +\n  autolayer(ma(ts_hy, 24), series=\"24-MA\") +\n  autolayer(ma(ts_hy, 3), series=\"3-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_solar) +\n  autolayer(ma(ts_solar, 12), series=\"12-MA\") +\n  autolayer(ma(ts_solar, 24), series=\"24-MA\") +\n  autolayer(ma(ts_solar, 3), series=\"3-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_wti) +\n  autolayer(ma(ts_wti, 20), series=\"20-MA\") +\n  autolayer(ma(ts_wti, 60), series=\"60-MA\") +\n  autolayer(ma(ts_wti, 200), series=\"200-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_np) +\n  autolayer(ma(ts_np, 20), series=\"20-MA\") +\n  autolayer(ma(ts_np, 60), series=\"60-MA\") +\n  autolayer(ma(ts_np, 200), series=\"200-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_icln) +\n  autolayer(ma(ts_icln, 20), series=\"20-MA\") +\n  autolayer(ma(ts_icln, 50), series=\"50-MA\") +\n  autolayer(ma(ts_icln, 200), series=\"200-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nautoplot(ts_xle) +\n  autolayer(ma(ts_xle, 20), series=\"20-MA\") +\n  autolayer(ma(ts_xle, 50), series=\"50-MA\") +\n  autolayer(ma(ts_xle, 200), series=\"200-MA\") +\n  labs(title = \"Moving Average Smoothing\",\n       y = \"Value\",\n       x = \"Time\") +\n  theme_minimal()"
  },
  {
    "objectID": "financial.html",
    "href": "financial.html",
    "title": "Financial TS Models",
    "section": "",
    "text": "The global push toward energy transition has accelerated the development and financialization of clean energy markets. As one of the most widely tracked clean-energy financial instruments, the iShares Global Clean Energy ETF (ICLN) provides a comprehensive benchmark for investors’ expectations about renewable energy technologies such as wind, solar, hydro, and other low-carbon sectors. Because clean energy markets are directly influenced by policy interventions, fossil fuel price shocks, geopolitical risks, and technological progress, the return dynamics of ICLN often exhibit time-varying volatility, volatility clustering, and structural breaks—features that are central to financial time series analysis.\nTo properly characterize these statistical properties and to understand how uncertainty evolves in the clean-energy sector, this study models the return series of ICLN using conditional heteroskedasticity models, specifically GARCH-family models and an integrated ARIMA-GARCH framework. Modeling volatility is crucial because volatility represents the risk and uncertainty associated with clean-energy investments, influences portfolio allocation decisions, and affects the pricing of derivative instruments such as options.\nCode\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggplot2)\nlibrary(seasonal)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(gridExtra)\nlibrary(fpp2)\nlibrary(prophet)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(patchwork)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tsibble)\nlibrary(knitr)\n\netf_data &lt;- tq_get(\"ICLN\",\n                   from = \"2000-01-01\",\n                   to = Sys.Date(),\n                   get = \"stock.prices\")\n\n# 2. Convert to data frame and clean up\nicln_data &lt;- data.frame(etf_data)\nicln_data$date &lt;- as.Date(icln_data$date) # Add date column from rownames"
  },
  {
    "objectID": "financial.html#time-series-plot",
    "href": "financial.html#time-series-plot",
    "title": "Financial TS Models",
    "section": "Time Series Plot",
    "text": "Time Series Plot\n\nVisualizationReturns\n\n\n\n\nCode\n# 5. Plot Adjusted Close Price using ggplot\np &lt;- ggplot(icln_data, aes(x = date, y = adjusted)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"ICLN Prices (2008–Present)\",\n       x = \"Date\",\n       y = \"Adjusted Price (USD)\") +\n  theme_minimal()\n\n# 6. Make it interactive with plotly\nggplotly(p)\n\n\n\n\n\n\n\n\nOverall, the return series exhibits characteristics of high volatility, leptokurtosis, heavy tails, and time-varying variance, which are consistent with the behavioral patterns of high-risk assets such as renewable energy ETFs.\n\n\nCode\nicln_data &lt;- na.omit(icln_data)  # Removes all NAs, including at the end\nbtc_adj &lt;- icln_data$`adjusted`\n\n# Step 3: Convert to time series object\nts_icln &lt;- ts(btc_adj,\n          start = decimal_date(as.Date(\"2008-10-01\")),\n          frequency = 365.25)\n\nreturns &lt;- diff(log(ts_icln))\n\n# Plot log returns using autoplot (works if returns is a ts object)\nautoplot(returns) +\n  ggtitle(\"Monthly Log Returns of ICLN (BTC-USD)\") +\n  xlab(\"Time\") +\n  ylab(\"Log Return\")"
  },
  {
    "objectID": "financial.html#acf-and-pacf-plots",
    "href": "financial.html#acf-and-pacf-plots",
    "title": "Financial TS Models",
    "section": "ACF and PACF Plots",
    "text": "ACF and PACF Plots\n\nReturnsAbsolute and Squared Returns\n\n\nA closer examination of the ACF plot suggests that the return series exhibits characteristics of weak stationarity, with autocorrelations quickly decaying toward zero and no significant long-range dependence.\n\n\nCode\n# Plot ACF of returns\nggAcf(returns, lag.max = 40) +\n  ggtitle(\"ACF of ICLN Log Returns\") +\n  xlab(\"Lag\") +\n  ylab(\"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot PACF of returns\nggPacf(returns, lag.max = 40) +\n  ggtitle(\"PACF of ICLN Log Returns\") +\n  xlab(\"Lag\") +\n  ylab(\"Partial Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nBoth plots exhibit significant autocorrelation, indicating the presence of dependence in the conditional variance rather than in the mean. This pattern is characteristic of volatility clustering, where periods of high and low volatility tend to persist over time.\n\n\nCode\n# ACF of absolute returns (to detect nonlinear serial dependence)\nggAcf(abs(returns), lag.max = 40) +\n  ggtitle(\"ACF of Absolute ICLN Returns\") +\n  xlab(\"Lag\") +\n  ylab(\"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# ACF of squared returns (to check for conditional heteroskedasticity)\nggAcf(returns^2, lag.max = 40) +\n  ggtitle(\"ACF of Squared ICLN Returns\") +\n  xlab(\"Lag\") +\n  ylab(\"Autocorrelation\") +\n  theme_minimal()"
  },
  {
    "objectID": "financial.html#arima-garch-model",
    "href": "financial.html#arima-garch-model",
    "title": "Financial TS Models",
    "section": "ARIMA + GARCH Model",
    "text": "ARIMA + GARCH Model\n\nArchTest()Model SelectionManual Searchauto.arima()Model DiagnosticsModel Fitting\n\n\nSince the p-value is less than 0.05, we reject the null hypothesis, indicating strong evidence for the presence of ARCH(1) effects in the data.\n\n\nCode\n# Load required package\nlibrary(FinTS)\n\n# Perform ARCH LM Test on Bitcoin returns\narch_test_result &lt;- ArchTest(returns, lags = 1, demean = TRUE)\n\n# Print results\nprint(arch_test_result)\n\n\n\n    ARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  returns\nChi-squared = 479.48, df = 1, p-value &lt; 2.2e-16\n\n\n\n\nThe ACF of the log-transformed ICLN prices reveals significant serial correlation, indicating the presence of dependencies between past and current price movements.\n\n\nCode\n# Calculate log bitcoin prices \nicln_log &lt;- log(ts_icln)\n\n# ACF of log returns\nggAcf(icln_log, lag.max = 40) +\n  ggtitle(\"ACF of Log ICLN Prices\") +\n  xlab(\"Lag\") +\n  ylab(\"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# PACF of log returns\nggPacf(icln_log, lag.max = 40) +\n  ggtitle(\"PACF of Log ICLN Prices\") +\n  xlab(\"Lag\") +\n  ylab(\"Partial Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe scattered yet recurring significant spikes in both the ACF and PACF of the returns—especially at early and mid–range lags—indicate non-random structure in the second moment rather than in the mean. Although the returns themselves behave largely like white noise, the persistence seen in the autocorrelation of squared or absolute returns suggests time-varying volatility. This pattern is characteristic of conditional heteroskedasticity, making the series a strong candidate for ARCH/GARCH-type modeling to capture the underlying volatility dynamics.\n\n\nCode\n# Calculate log returns (first differences of log prices)\nicln_log_returns &lt;- diff(log(ts_icln))\n\n# ACF of log returns\nggAcf(icln_log_returns, lag.max = 40) +\n  ggtitle(\"ACF of ICLN Log Returns\") +\n  xlab(\"Lag\") +\n  ylab(\"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# PACF of log returns\nggPacf(icln_log_returns, lag.max = 40) +\n  ggtitle(\"PACF of ICLN Log Returns\") +\n  xlab(\"Lag\") +\n  ylab(\"Partial Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nBased on the lowest AIC and BIC values, the best-fitting models are ARIMA(3,0,4) and ARIMA(0,1,0).\n\n\nCode\n# Function to search over ARIMA(p, d, q) combinations and return model selection metrics\nARIMA.c &lt;- function(p_min, p_max, q_min, q_max, data) {\n  results &lt;- matrix(rep(NA, 6 * 1000), nrow = 1000)\n  colnames(results) &lt;- c(\"p\", \"d\", \"q\", \"AIC\", \"BIC\", \"AICc\")\n\n  for (p in p_min:p_max) {\n    for (q in q_min:q_max) {\n      for (d in 0:2) {\n        if ((p + d + q) &lt;= 8) {  # Complexity constraint\n          fit &lt;- Arima(data, order = c(p, d, q))\n          metrics &lt;- c(p, d, q, fit$aic, fit$bic, fit$aicc)\n          results &lt;- rbind(results, metrics)\n        }\n      }\n    }\n  }\n\n  # Convert to data frame\n  results_df &lt;- as.data.frame(results)\n  colnames(results_df) &lt;- c(\"p\", \"d\", \"q\", \"AIC\", \"BIC\", \"AICc\")\n  return(results_df)\n}\n\n# Apply the function to log prices\noutput &lt;- ARIMA.c(0, 7, 0, 7, data = log(ts_icln))\n\n# Show best models according to different criteria\noutput[which.min(output$AIC), ]   # Best by AIC\n\n\n           p d q       AIC       BIC      AICc\nmetrics.74 3 0 4 -21623.51 -21566.03 -21623.47\n\n\n\n\nCode\noutput[which.min(output$BIC), ]   # Best by BIC\n\n\n          p d q       AIC       BIC      AICc\nmetrics.1 0 1 0 -21612.04 -21605.65 -21612.04\n\n\n\n\nCode\noutput[which.min(output$AICc), ]  # Best by AICc\n\n\n           p d q       AIC       BIC      AICc\nmetrics.74 3 0 4 -21623.51 -21566.03 -21623.47\n\n\n\n\n\n\nCode\n# Automatically select the best ARIMA model for the log-transformed price series\nauto.arima(log(ts_icln))\n\n\nSeries: log(ts_icln) \nARIMA(5,2,0) \n\nCoefficients:\n          ar1      ar2      ar3      ar4      ar5\n      -0.8050  -0.6240  -0.4648  -0.3157  -0.1653\ns.e.   0.0149   0.0186   0.0197   0.0186   0.0149\n\nsigma^2 = 0.0005002:  log likelihood = 10448.73\nAIC=-20885.47   AICc=-20885.45   BIC=-20847.15\n\n\n\n\nAmong the candidate models, SARIMA(0,1,0) provides the best diagnostics: the residuals resemble white noise, the Ljung-Box test fails to reject the null of no autocorrelation, and the model achieves the lowest AIC. Both SARIMA(3,0,4) and SARIMA(5,2,0) display signs of overfitting and leave autocorrelation in the residuals.\n\n\nCode\ndata &lt;- log(ts_icln)\noutput_304 &lt;- capture.output(sarima(data, 3, 0, 4))\n\n\n\n\n\n\n\n\n\n\n\nCode\noutput_520 &lt;- capture.output(sarima(data, 5, 2, 0))\n\n\n\n\n\n\n\n\n\n\n\nCode\noutput_010 &lt;- capture.output(sarima(data, 0, 1, 0))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Define a helper function to extract relevant block\nextract_model_summary &lt;- function(model_output, label = \"\") {\n  cat(\"\\n\\n==================== \", label, \" ====================\\n\")\n  \n  # Look for 'Coefficients' section\n  start &lt;- grep(\"Coefficients\", model_output)\n  if (length(start) == 0) {\n    cat(\"No coefficients found in output.\\n\")\n    return()\n  }\n  \n  # Print from 'Coefficients' line to 10 lines after (or until end)\n  end &lt;- min(start + 10, length(model_output))\n  cat(model_output[start:end], sep = \"\\n\")\n}\n\n# Print cleaned output for each model\nextract_model_summary(output_010, \"SARIMA(0,1,0)\")\n\n\n\n\n====================  SARIMA(0,1,0)  ====================\nCoefficients: \n         Estimate    SE t.value p.value\nconstant   -2e-04 3e-04 -0.5871  0.5572\n\nsigma^2 estimated as 0.0004248939 on 4387 degrees of freedom \n \nAIC = -4.924883  AICc = -4.924882  BIC = -4.921972 \n \n\n\n\n\nCode\nextract_model_summary(output_304, \"SARIMA(3,0,4)\")\n\n\n\n\n====================  SARIMA(3,0,4)  ====================\nCoefficients: \n      Estimate     SE  t.value p.value\nar1     0.2751 0.0099  27.7955  0.0000\nar2    -0.2646 0.0134 -19.6961  0.0000\nar3     0.9893 0.0094 105.0820  0.0000\nma1     0.7471 0.0180  41.4295  0.0000\nma2     1.0226 0.0216  47.3695  0.0000\nma3     0.0421 0.0193   2.1756  0.0296\nma4     0.0262 0.0157   1.6675  0.0955\nxmean   2.4157 5.0683   0.4766  0.6337\n\n\n\n\nCode\nextract_model_summary(output_520, \"SARIMA(5,2,0)\")\n\n\n\n\n====================  SARIMA(5,2,0)  ====================\nCoefficients: \n    Estimate     SE  t.value p.value\nar1  -0.8050 0.0149 -54.0363       0\nar2  -0.6240 0.0186 -33.5012       0\nar3  -0.4648 0.0197 -23.6433       0\nar4  -0.3157 0.0186 -16.9495       0\nar5  -0.1653 0.0149 -11.0997       0\n\nsigma^2 estimated as 0.0004996554 on 4382 degrees of freedom \n \nAIC = -4.760763  AICc = -4.76076  BIC = -4.752028 \n\n\n\n\n\n\nCode\n# Fit ARIMA(4,1,2) model to the log-transformed stock prices\narima_412 &lt;- Arima(log(ts_icln), order = c(0,1,0))\nsummary(arima_412)\n\n\nSeries: log(ts_icln) \nARIMA(0,1,0) \n\nsigma^2 = 0.0004249:  log likelihood = 10807.02\nAIC=-21612.04   AICc=-21612.04   BIC=-21605.65\n\nTraining set error measures:\n                        ME       RMSE        MAE          MPE      MAPE\nTraining set -0.0001820384 0.02061149 0.01368498 -0.009222839 0.5683853\n                   MASE       ACF1\nTraining set 0.04511585 0.01983185"
  },
  {
    "objectID": "financial.html#fit-the-garch-model",
    "href": "financial.html#fit-the-garch-model",
    "title": "Financial TS Models",
    "section": "Fit the GARCH model",
    "text": "Fit the GARCH model\n\nModel SelectionManual SearchModel FittingForecastARIMA(0,1,0)+GARCH(1,1) Model Equation\n\n\nWe can see that the ACF remains significant for the first 40 lags, while the PACF is significant up to lag 9, with a few individual significant spikes thereafter. We will perform a search for q=0:7 and p=0:7.\n\n\nCode\n# Fit ARIMA(2,1,2) model with drift\narima_fit &lt;- Arima(log(ts_icln), order = c(0,1,0))\n\n# Extract residuals\nresiduals_arima &lt;- residuals(arima_fit)\n\n# Plot ACF of residuals\nacf(residuals_arima, main = \"ACF of ARIMA(0,1,0) Residuals\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot ACF of squared residuals (for checking ARCH effects)\nacf(residuals_arima^2, main = \"ACF of Squared Residuals\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot PACF of squared residuals (to identify ARCH order)\npacf(residuals_arima^2, main = \"PACF of Squared Residuals\")\n\n\n\n\n\n\n\n\n\n\n\nThis suggests that the best model is GARCH(1,1), as it yields the lowest AIC, indicating a better fit to the data compared to other models.\n\n\nCode\n# Initialize list to store models\nmodels &lt;- list()\ncc &lt;- 1\n\n# Loop over GARCH(p, q) combinations\nfor (p in 1:7) {\n  for (q in 1:7) {\n    models[[cc]] &lt;- garch(residuals_arima, order = c(q, p), trace = FALSE)\n    cc &lt;- cc + 1\n  }\n}\n\n# Extract AIC values for all models\nGARCH_AIC &lt;- sapply(models, AIC)\n\n# Find and return the best model (lowest AIC)\nbest_index &lt;- which.min(GARCH_AIC)\nmodels[[best_index]]\n\n\n\nCall:\ngarch(x = residuals_arima, order = c(q, p), trace = FALSE)\n\nCoefficient(s):\n       a0         a1         b1  \n3.708e-06  7.790e-02  9.122e-01  \n\n\n\n\nThe GARCH(1,1) model performs well overall: all parameters are highly significant, indicating that the volatility equation has been effectively identified; α+β≈0.99 indicates that volatility has strong persistence, consistent with typical financial time series characteristics.\nThe model handles the autocorrelation of ARIMA residuals and ARCH effects well; both Ljung-Box and ARCH LM tests show that the residuals are no longer significantly correlated with the squared residuals, indicating that the model fits well.\n\n\nCode\nlibrary(fGarch)\ngarch_model &lt;- garchFit(~ garch(1, 1), data = residuals_arima, trace = FALSE)\n\n# Print detailed summary\nsummary(garch_model)\n\n\n\nTitle:\n GARCH Modelling \n\nCall:\n garchFit(formula = ~garch(1, 1), data = residuals_arima, trace = FALSE) \n\nMean and Variance Equation:\n data ~ garch(1, 1)\n&lt;environment: 0x0000020fc6cb7af0&gt;\n [data = residuals_arima]\n\nConditional Distribution:\n norm \n\nCoefficient(s):\n        mu       omega      alpha1       beta1  \n1.7901e-04  3.7338e-06  7.7968e-02  9.1208e-01  \n\nStd. Errors:\n based on Hessian \n\nError Analysis:\n        Estimate  Std. Error  t value Pr(&gt;|t|)    \nmu     1.790e-04   2.145e-04    0.835    0.404    \nomega  3.734e-06   8.037e-07    4.646 3.39e-06 ***\nalpha1 7.797e-02   8.081e-03    9.648  &lt; 2e-16 ***\nbeta1  9.121e-01   8.927e-03  102.173  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLog Likelihood:\n 11833.62    normalized:  2.696199 \n\nDescription:\n Thu Dec  4 14:12:28 2025 by user: Lenovo \n\n\nStandardised Residuals Tests:\n                                  Statistic   p-Value\n Jarque-Bera Test   R    Chi^2  497.5778062 0.0000000\n Shapiro-Wilk Test  R    W        0.9868865 0.0000000\n Ljung-Box Test     R    Q(10)   12.0716363 0.2802908\n Ljung-Box Test     R    Q(15)   14.9076143 0.4580922\n Ljung-Box Test     R    Q(20)   22.9538819 0.2910647\n Ljung-Box Test     R^2  Q(10)   13.5364170 0.1952061\n Ljung-Box Test     R^2  Q(15)   15.6695334 0.4043480\n Ljung-Box Test     R^2  Q(20)   16.7304921 0.6703982\n LM Arch Test       R    TR^2    13.7783686 0.3150847\n\nInformation Criterion Statistics:\n      AIC       BIC       SIC      HQIC \n-5.390576 -5.384755 -5.390577 -5.388522 \n\n\n\n\n\n\nCode\n# Predict 100 steps ahead using the fitted GARCH(1,1) model\ninvisible(predict(garch_model, n.ahead = 100, plot = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\\[\n(1-B)x_t = w_t,\n\\]\n\\[\nx_t = x_{t-1} + w_t.\n\\]\nThe GARCH(1,1) specification is\n\\[\nw_t = \\sigma_t \\epsilon_t,\n\\] \\[\n\\sigma_t^2 = \\omega + \\alpha_1 w_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2.\n\\]\nthe conditional variance equation becomes \\[\n\\sigma_t^2 = 0.0000075 + 0.13\\, w_{t-1}^2 + 0.829\\, \\sigma_{t-1}^2.\n\\]"
  },
  {
    "objectID": "financial.html#directly-garch-model",
    "href": "financial.html#directly-garch-model",
    "title": "Financial TS Models",
    "section": "Directly GARCH Model",
    "text": "Directly GARCH Model\nThis search suggests that a GARCH(1,0) model is the most suitable choice, with the lowest AIC value, indicating the best balance between model complexity and goodness-of-fit.\n\n\nCode\n# Initialize model storage\nmodels &lt;- list()\ncc &lt;- 1\n\n# Grid search for GARCH(p, q), where p = ARCH order, q = GARCH order\nfor (p in 1:10) {\n  for (q in 0:10) {\n    models[[cc]] &lt;- garch(returns, order = c(q, p), trace = FALSE)\n    cc &lt;- cc + 1\n  }\n}\n\n# Extract AIC values\ngarch_aic &lt;- sapply(models, AIC)\n\n# Find best model (lowest AIC)\nbest_index &lt;- which.min(GARCH_AIC)\nmodels[[best_index]]\n\n\n\nCall:\ngarch(x = returns, order = c(q, p), trace = FALSE)\n\nCoefficient(s):\n       a0         a1  \n0.0002612  0.3970424"
  },
  {
    "objectID": "financial.html#cross-validation",
    "href": "financial.html#cross-validation",
    "title": "Financial TS Models",
    "section": "Cross Validation",
    "text": "Cross Validation\nIt’s look like just the ARIMA + GARCH(1,1) model is slightly better.\n\n\nCode\n# Step 1: Prepare data\nlog.b &lt;- log(ts_icln)\nreturns &lt;- diff(log.b)\n# Set rolling window parameters\nk &lt;- 600  # 20% of data length as initial training size\nn &lt;- length(returns)\n\n# Initialize error storage\nerr1 &lt;- c()  # ARIMA + GARCH(1,1)\nerr2 &lt;- c()  # GARCH(1,0)\nerr3 &lt;- c()  # ARCH(4)\n\n# Rolling forecast loop\nfor (i in 1:(n - k)) {\n  \n  # Training and test data\n  xtrain &lt;- log.b[1:(k - 1) + i]\n  xtest &lt;- log.b[k + i]\n  \n  ## Model 1: ARIMA(2,1,2) + GARCH(1,2) on residuals\n  arima.fit &lt;- Arima(xtrain, order = c(0, 1, 0), include.drift = TRUE)\n  arima.res &lt;- residuals(arima.fit)\n  fit1 &lt;- garchFit(~ garch(1, 1), data = arima.res, trace = FALSE)\n  fcast1 &lt;- predict(fit1, n.ahead = 1)\n  \n  ## Model 2: GARCH(1,2) on returns\n  returns_train &lt;- diff(xtrain)\n  fit2 &lt;- garchFit(~ garch(1, 0), data = returns_train, trace = FALSE)\n  fcast2 &lt;- predict(fit2, n.ahead = 1)\n  \n  ## Model 3: ARCH(4) on returns (new model)\n  fit3 &lt;- garchFit(~ garch(4, 0), data = returns_train, trace = FALSE)\n  fcast3 &lt;- predict(fit3, n.ahead = 1)\n  \n  # Forecasting log price (meanForecast is on returns, so add to last value of xtrain)\n  pred1 &lt;- tail(xtrain, 1) + fcast1$meanForecast\n  pred2 &lt;- tail(xtrain, 1) + fcast2$meanForecast\n  pred3 &lt;- tail(xtrain, 1) + fcast3$meanForecast  # ARCH(4) forecast\n\n  # Squared errors for each model\n  err1 &lt;- c(err1, (pred1 - xtest)^2)\n  err2 &lt;- c(err2, (pred2 - xtest)^2)\n  err3 &lt;- c(err3, (pred3 - xtest)^2)\n}\n\n# Calculate RMSE for each model\nRMSE1 &lt;- sqrt(mean(err1))  # ARIMA + GARCH(1,2)\nRMSE2 &lt;- sqrt(mean(err2))  # GARCH(1,2)\nRMSE3 &lt;- sqrt(mean(err3))  # ARCH(4)\n\n# Print results\ncat(\"RMSE (ARIMA + GARCH(1,1)):\", RMSE1, \"\\n\")\n\n\nRMSE (ARIMA + GARCH(1,1)): 0.01688587 \n\n\n\n\nCode\ncat(\"RMSE (GARCH(1,0))      :\", RMSE2, \"\\n\")\n\n\nRMSE (GARCH(1,0))      : 0.01691158 \n\n\n\n\nCode\ncat(\"RMSE (ARCH(4))         :\", RMSE3, \"\\n\")\n\n\nRMSE (ARCH(4))         : 0.01691356"
  },
  {
    "objectID": "financial.html#volatality-plot",
    "href": "financial.html#volatality-plot",
    "title": "Financial TS Models",
    "section": "Volatality Plot",
    "text": "Volatality Plot\nThe GARCH-estimated conditional variance for ICLN exhibits clear and economically interpretable volatility dynamics. The plot shows several pronounced volatility spikes—most notably during the 2008–2009 financial crisis and again around early 2020 during the COVID-19 pandemic. These periods correspond to well-known episodes of extreme market stress and uncertainty, confirming that the model successfully captures volatility clustering.\nBetween these major events, the conditional variance drops sharply and remains relatively low, with only occasional moderate fluctuations. This pattern reflects the typical behavior of financial time series: prolonged periods of calm punctuated by short bursts of intense volatility. The smooth decay after each spike indicates strong GARCH persistence, meaning past shocks continue to influence volatility for an extended period.\nOverall, the volatility plot confirms that the GARCH model effectively captures the time-varying, mean-reverting, and clustered nature of ICLN’s return volatility, and it aligns well with major macroeconomic events known to drive renewable-energy equity fluctuations.\n\n\nCode\n# Extract the conditional variances from GARCH\nht &lt;- garch_model@h.t\n\n# Create dataframe and plot\nvol_df &lt;- data.frame(Date = icln_data$date, Volatility = ht)\n\np &lt;- ggplot(vol_df, aes(x = Date, y = Volatility)) +\n  geom_line(color = \"#ff9933\") +\n  labs(\n    title = \"Volatility Plot (Conditional Variance from GARCH Model)\",\n    x = \"Date\",\n    y = \"Conditional Variance\"\n  ) +\n  theme_minimal()\n\nggplotly(p)"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Energy Transition: A Time Series Perspective",
    "section": "",
    "text": "The world is undergoing a profound transformation in how energy is produced, consumed, and financed. Historically, global economic growth has been tightly coupled with fossil fuels such as oil, coal, and natural gas. However, mounting evidence of climate change, advances in clean technologies, and shifting government policies have accelerated the global transition toward renewable energy. This transition—often described as the “energy transition”—is reshaping markets, altering geopolitical balances, and influencing the financial system.\nFrom a data science perspective, this topic provides a unique opportunity to explore long-term structural trends alongside short-term volatility. Energy data exhibits strong seasonality (e.g., higher natural gas demand in winter, increased electricity demand during summer heat waves), as well as structural breaks (such as the 2015 Paris Agreement or the 2020 oil price crash). It also connects multiple domains: technology costs, consumer behavior, financial market reactions, and environmental policy.\nUnderstanding these dynamics is not just an academic exercise—governments, investors, and industries rely on such analyses to guide decision-making in the face of uncertainty."
  },
  {
    "objectID": "introduction.html#topic-explanation",
    "href": "introduction.html#topic-explanation",
    "title": "Energy Transition: A Time Series Perspective",
    "section": "",
    "text": "The world is undergoing a profound transformation in how energy is produced, consumed, and financed. Historically, global economic growth has been tightly coupled with fossil fuels such as oil, coal, and natural gas. However, mounting evidence of climate change, advances in clean technologies, and shifting government policies have accelerated the global transition toward renewable energy. This transition—often described as the “energy transition”—is reshaping markets, altering geopolitical balances, and influencing the financial system.\nFrom a data science perspective, this topic provides a unique opportunity to explore long-term structural trends alongside short-term volatility. Energy data exhibits strong seasonality (e.g., higher natural gas demand in winter, increased electricity demand during summer heat waves), as well as structural breaks (such as the 2015 Paris Agreement or the 2020 oil price crash). It also connects multiple domains: technology costs, consumer behavior, financial market reactions, and environmental policy.\nUnderstanding these dynamics is not just an academic exercise—governments, investors, and industries rely on such analyses to guide decision-making in the face of uncertainty."
  },
  {
    "objectID": "introduction.html#the-big-picture",
    "href": "introduction.html#the-big-picture",
    "title": "Energy Transition: A Time Series Perspective",
    "section": "The Big Picture",
    "text": "The Big Picture\n\n\n\n\n\nThe global shift to clean energy is one of the most significant transformations shaping the 21st-century economy, with implications spanning technology, markets, policy, and finance. This analysis will consider the following five main areas:\nLong-Run Evolution of Power Generation Mix: This theme examines how the composition of electricity generation—wind, solar, natural gas, coal, nuclear, and hydro—has shifted over time. It focuses on long-term decarbonization trends, structural breakpoints, and the growing role of renewables.\nSeasonality & Climate Drivers: This theme investigates seasonal and climatic patterns in different generation sources and how temperature, irradiance, wind patterns, and hydrology influence renewable and fossil-fuel generation.\nLinkages and Causality in Energy Prices: This theme analyzes dynamic interactions among WTI crude oil, Henry Hub natural gas, and energy-related financial indices, focusing on short-run spillovers, long-run cointegration, and causal relationships.\nFinancial Dynamics of Clean Energy Assets (Return & Volatility Behavior): This theme focuses on price behavior, return dynamics, volatility clustering, and risk spillovers in clean energy ETFs (ICLE/ICLN), especially relative to traditional energy ETFs such as XLE.\nDynamic Interactions within Multi-Energy Systems (Inter-Energy Dynamics): This theme analyzes how different energy sources interact in a multi-energy system—whether renewables displace fossil fuels, whether natural gas complements variable renewables, and how shocks propagate through the generation network."
  },
  {
    "objectID": "introduction.html#literature-review",
    "href": "introduction.html#literature-review",
    "title": "Energy Transition: A Time Series Perspective",
    "section": "Literature Review",
    "text": "Literature Review\nLong-Run Evolution of Power Generation Mix\nGlobal studies show that the power sector is undergoing consistent structural decarbonization. Large-scale industry reports, such as BP’s Statistical Review1 and the IEA’s World Energy Outlook2, document that renewable generation is expanding faster than fossil fuels.\nAcademic literature emphasizes that declining technology costs and supportive policies play a major role in accelerating renewable adoption3. BloombergNEF identifies several “cost-parity tipping points,” where renewables become cheaper than fossil alternatives4, reinforcing long-run structural shifts.\nSeasonality and Climate-Driven Dynamics of Energy Supply\nSolar power’s strong dependence on irradiance and seasonal temperature cycles has been widely documented5. Wind power output is shaped by atmospheric circulation patterns, which vary by season and region6.\nNatural gas generation typically peaks during winter months due to heating demand, as shown in U.S. EIA research7. Hydropower output depends on precipitation and seasonal water availabilityhanasaki2018?, and climate variability is increasingly recognized as a source of short-run volatility in renewable generation across multiple studies.\nLinkages and Causality in Energy Prices\nOil price shocks affect broader energy markets through production costs and macroeconomic channels8.\nStudies show mixed evidence of integration between oil and natural gas: some periods show price comovement9, while others suggest partial decoupling depending on market structure10.\nFinancial literature further indicates strong causal links between energy prices and sector-level equity indices11, with volatility intensifying during crises, as observed in connectedness research12.\nFinancial Dynamics of Clean Energy Assets\nClean energy equities are highly sensitive to fluctuations in oil prices, as shown in early work on alternative energy stocks13.\nClean energy assets display strong volatility clustering, making GARCH-family models appropriate for risk analysis14.\nMore recent work suggests these assets are gradually transitioning from being predominantly policy-driven to more market-driven15, yet they remain exposed to macro-energy shocks.\nCross-asset spillovers—especially during periods of market stress—can be analyzed through the connectedness framework proposed in12.\nDynamic Interactions within Multi-Energy Systems\nRenewable energy expansion often displaces fossil-fuel generation, consistent with evidence of long-term “crowding out” effects16.\nNatural gas plays a critical role as a flexible generation source that compensates for wind and solar intermittency17.\nRecent system-level analyses highlight that shocks can propagate across coal, gas, and renewable sources through substitution and complementarity channels18.\nThese dynamic interactions underscore the importance of VAR and structural modeling approaches in understanding modern electricity systems."
  },
  {
    "objectID": "introduction.html#guiding-questions",
    "href": "introduction.html#guiding-questions",
    "title": "Energy Transition: A Time Series Perspective",
    "section": "Guiding Questions",
    "text": "Guiding Questions\n\nHas the power generation structure (wind, solar, gas, coal, nuclear, hydro) consistently shifted towards clean energy over the past decade? How rapidly has this shift occurred?\nDo clean energy sources such as wind, solar, and hydropower exhibit significant and stable seasonal patterns? Is this seasonality changing?\nHow much does weather (temperature or HDD/CDD) affect solar, wind, and natural gas power generation? Are there any lag effects?\nIs there a significant correlation between oil prices (WTI) and natural gas prices (Henry Hub)? Which leads the other?\nDoes natural gas price (HH) significantly affect natural gas power generation? And does it exhibit different elasticities in winter and summer?\nDo changes in fossil fuel prices “squeeze out” or “promote” renewable energy generation (such as solar/wind)?\nIs there a spillover effect in returns and volatility between clean energy ETFs (ICLE/ICLN) and traditional energy ETFs (XLE)? 8. Do clean energy ETFs (ICLE/ICLN) exhibit significant volatility clustering (GARCH characteristics)? Are their risk levels higher than those of traditional energy ETFs?\nAre there substitution relationships within multi-energy systems (wind/solar/coal/gas/nuclear/hydro)? For example, will wind and solar power displace coal gas?\nHow do exogenous shocks in the energy market (surges in oil prices, abnormal temperatures) propagate among different energy sources through the VAR system?"
  },
  {
    "objectID": "univariate.html",
    "href": "univariate.html",
    "title": "ARMA, ARIMA, and SARIMA Models",
    "section": "",
    "text": "Examine how the composition of power generation (wind, solar, coal, natural gas, nuclear, hydro) has evolved over time and how each source exhibits seasonal patterns. This captures the structural shift of the energy transition.\nCode\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggplot2)\nlibrary(seasonal)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(gridExtra)\nlibrary(fpp2)\nlibrary(prophet)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(patchwork)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tsibble)\nlibrary(knitr)\n\ndf &lt;- read.csv(\"data/electric.csv\")\ndf &lt;- df %&gt;%\n  mutate(\n    Description = str_extract(Description, \"(?&lt;=From ).*?(?=,)\"),\n    YYYYMM = as.character(YYYYMM),\n    Year = as.integer(substr(YYYYMM, 1, 4)),\n    Month = as.integer(substr(YYYYMM, 5, 6))\n  ) %&gt;%\n  filter(Month &lt;= 12) %&gt;%\n  filter(Year &gt;= 2000) %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, \"01\", sep = \"-\")))"
  },
  {
    "objectID": "univariate.html#wind",
    "href": "univariate.html#wind",
    "title": "ARMA, ARIMA, and SARIMA Models",
    "section": "Wind",
    "text": "Wind\n\n\nCode\nwind_df &lt;- df %&gt;%\n  filter(Description == \"Wind\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_wind &lt;- ts(wind_df$Value,\n              start = c(min(wind_df$Year), min(wind_df$Month)),\n              frequency = 12)\n\n\n\nLog TransformationSeasonal DifferencingAugmented Dickey-Fuller TestACF and PACFManual ARIMAModel diagnostic and equationauto.arima()ForecastingBenchmark\n\n\nThe log-transformed, first-differenced series is more stationary than the first difference of the original scale. In the original-scale differences, variability increases toward the end—evidence of heteroskedasticity and residual non-stationarity. The log transform stabilizes the variance, so the differenced log series fluctuates around a roughly constant mean with nearly constant variation. However, the ACF still shows seasonal dependence (spikes at lags 12, 24, …). To address this remaining structure, we should apply a seasonal difference on top of the ordinary difference—i.e., compute —to remove the seasonal correlation.\n\n\nCode\n# Extract vectors\ndates &lt;- wind_df$Date\ny     &lt;- as.numeric(wind_df$Value)\n\ndiff_orig &lt;- diff(y)\ndiff_log  &lt;- diff(log(pmax(y, .Machine$double.eps)))  # safe log if any zeros\ndate_d    &lt;- dates[-1]\n\n# Data frames for ggplot\ndf_orig &lt;- data.frame(Date = date_d, Diff = diff_orig)\ndf_log  &lt;- data.frame(Date = date_d, Diff = diff_log)\n\n# Panel 1: differenced original\np1 &lt;- ggplot(df_orig, aes(x = Date, y = Diff)) +\n  geom_line(color = \"steelblue\") +\n  labs(title = \"First Difference (Original Scale)\",\n       x = \"Year\", y = \"First Difference\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"5 years\") +\n  theme_minimal()\n\n# Panel 2: differenced log\np2 &lt;- ggplot(df_log, aes(x = Date, y = Diff)) +\n  geom_line(color = \"firebrick\") +\n  labs(title = \"First Difference (Log Scale)\",\n       x = \"Year\", y = \"First Difference (log)\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"5 years\") +\n  theme_minimal()\n\n# Stack vertically\np1 / p2\n\n\n\n\n\n\n\n\n\n\n\nACF: Original series. Here it is evident that there is very high autocorrelation, including seasonal correlation, with highly significant serial correlation at seasonal lags. However, due to heteroscedasticity in the data, we need a log transformation.\nACF: log(xt) — ordinary diff. Here we can see the ordinary serial correlation is minimal compared to the raw series data ACF, but there is high seasonal correlation remains at lags 12, 24, etc. So we will need seasonal differencing.\nACF: log(xt) — seasonal diff. Here, when we apply seasonal differencing, we can see that the seasonal correlation has become very small, but the series is still not stationary due to high correlation from the ordinary lags. Our goal is to convert the data into a stationary process as a first step for our modeling process; therefore, we need both ordinary differencing on top of seasonal differencing.\nACF: log(xt) — ordinary + seasonal diff. With both ordinary and seasonal differencing, the series is now more stationary.\n\n\nCode\n# Log series (safe for zeros)\nlog_ts  &lt;- log(pmax(ts_wind, .Machine$double.eps))\n\n# Differencing\nd_log   &lt;- diff(log_ts)              # ordinary diff of log\nsd_log  &lt;- diff(log_ts, lag = 12)    # seasonal diff of log\nosd_log &lt;- diff(d_log,  lag = 12)    # first + seasonal diff of log\n\n# ACF plots\np1 &lt;- ggAcf(ts_wind,   lag.max = 60) + ggtitle(\"ACF: Original series\") +\n  theme_minimal()\np2 &lt;- ggAcf(d_log,   lag.max = 60) + ggtitle(\"ACF: log(xt)-ordinary diff)\") +\n  theme_minimal()\np3 &lt;- ggAcf(sd_log,  lag.max = 60) + ggtitle(\"ACF: log(xt)-seasonal diff\") +\n  theme_minimal()\np4 &lt;- ggAcf(osd_log, lag.max = 60) + ggtitle(\"ACF:log(xt)-ordinary + seasonal diff\") +\n  theme_minimal()\n\n# Arrange in a 2x2 grid\n(p1 | p2) / (p3 | p4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf.test(osd_log)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  osd_log\nDickey-Fuller = -9.8337, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\np = 0:4, d = 1, q = 1, P = 0:1, D = 1, Q = 1\n\n\nCode\nacf &lt;-  ggAcf(osd_log, lag.max = 60) + ggtitle(\"ACF:log(xt)-ordinary + seasonal diff\") +\n  theme_minimal()\n\npacf &lt;- ggPacf(osd_log, lag.max = 60) + ggtitle(\"PACF:log(xt)-ordinary + seasonal diff\") +\n  theme_minimal()\n\ngrid.arrange(acf, pacf, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q&lt;=9)\n          {\n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=3,P1=1,P2=3,Q1=1,Q2=3,data=log_ts)\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q       AIC       BIC      AICc\n25 1 1 1 0 1 1 -311.6715 -296.9508 -311.5326\n\n\n\n\n\nStandardized Residuals: The residuals fluctuate randomly around zero with no visible trend or seasonal pattern. Variance appears stable over time. Suggests residuals behave like white noise.\nACF of Residuals: Most autocorrelations are within the blue confidence bounds.No significant spikes → no serial correlation remains. Indicates good model fit.\nNormal Q–Q Plot: Points mostly lie on the 45° line, with slight deviation in the tails. Minor departure from normality at extremes, but acceptable for large samples.\nLjung–Box Test p-values: Many p-values fall below 0.05, which suggests that some autocorrelation remains in the residuals. Therefore, the white-noise assumption is not fully met, and the model may still have room for improvement.\n\n\\[\n(1 - 0.3321B)(1 - B)(1 - B^{12})y_t\n= (1 - 0.8416B)(1 - 0.8160B^{12})\\varepsilon_t\n\\]\n\n\nCode\nmodel_output &lt;- capture.output(sarima(log_ts, 1,1,1, 0,1,1,12))\n\n\n\n\n\n\n\n\n\nCode\nstart_line &lt;- grep(\"Coefficients\", model_output)  \nend_line &lt;- length(model_output)\ncat(model_output[start_line:end_line], sep = \"\\n\")\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1    0.3321 0.0737   4.5082       0\nma1   -0.8416 0.0393 -21.4253       0\nsma1  -0.8160 0.0491 -16.6176       0\n\nsigma^2 estimated as 0.01874347 on 290 degrees of freedom \n \nAIC = -1.063725  AICc = -1.063442  BIC = -1.013484 \n \n\n\n\n\nDifferent from the chosen model.\nAlthough auto.arima() proposed a more complex model, the manual model achieved lower AIC and better residual diagnostics, suggesting it provides a more parsimonious and robust fit. The difference arises because auto.arima() relies on automated information criteria search, which may not always align with manual diagnostic evaluation.\n\n\nCode\nauto.arima(log_ts)\n\n\nSeries: log_ts \nARIMA(1,1,3)(2,1,2)[12] \n\nCoefficients:\n         ar1      ma1      ma2      ma3     sar1    sar2     sma1     sma2\n      0.2718  -0.7911  -0.0085  -0.0312  -0.6830  0.0756  -0.1658  -0.5369\ns.e.  0.4079   0.4073   0.2308   0.1104   0.2856  0.1124   0.2788   0.2025\n\nsigma^2 = 0.01899:  log likelihood = 161.75\nAIC=-305.5   AICc=-304.86   BIC=-272.37\n\n\n\n\nThe ARIMA(1,1,1)(0,1,1)[12] model provides a reasonable forecast for wind electricity net generation.\nThe results suggest that:\n\nWind electricity generation will continue increasing in the coming years, following the established long-term growth trend.\nSeasonal fluctuations remain evident, showing that generation tends to rise and fall periodically (likely due to seasonal wind patterns).\nThe forecast intervals are relatively tight, implying that future wind generation is expected to remain within predictable bounds, barring major policy or climate disruptions.\n\n\n\nCode\nfit &lt;- Arima(log_ts, order=c(1,1,1), seasonal=c(0,1,1))\nfit %&gt;% forecast(h=36) %&gt;% autoplot() #next 3 years\n\n\n\n\n\n\n\n\n\n\n\n\nThe ARIMA model outperforms all benchmark models.\nThis indicates ARIMA captures both the underlying trend and seasonality of the wind generation data, making it the most reliable forecasting model among those tested.\n\n\n\nCode\n# Generate forecasts\nmean_forecast &lt;- forecast(meanf(log_ts, h = 36))\nnaive_forecast &lt;- forecast(naive(log_ts, h = 36))\nsnaive_forecast &lt;- forecast(snaive(log_ts, h = 36))\ndrift_forecast &lt;- forecast(rwf(log_ts, h = 36, drift = TRUE))\narima_forecast &lt;- forecast(fit, h = 36)\n\n# Convert forecasts to data frame\n# Extract forecasted values properly\nforecast_df &lt;- data.frame(\n  Date = seq(max(df_log$Date) %m+% months(1), by = \"month\", length.out = 36),\n  Mean = as.numeric(mean_forecast$mean),    # Extract mean forecast\n  Naive = as.numeric(naive_forecast$mean),\n  SNaive = as.numeric(snaive_forecast$mean),\n  Drift = as.numeric(drift_forecast$mean),\n  ARIMA = as.numeric(arima_forecast$mean)\n)\n\n# Plot with ggplot2\np &lt;- ggplot(wind_df, aes(x = Date, y = log(Value))) +\n  geom_line(color = \"black\", size = 1) +  # Actual Data\n  geom_line(data = forecast_df, aes(x = Date, y = Mean, color = \"Mean\"), linewidth = 1, linetype = \"dashed\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Naive, color = \"Naïve\"), linewidth = 1, linetype = \"dotted\") +\n  geom_line(data = forecast_df, aes(x = Date, y = SNaive, color = \"Seasonal Naïve\"), linewidth = 1, linetype = \"dotdash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Drift, color = \"Drift\"), linewidth = 1, linetype = \"twodash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = ARIMA, color = \"ARIMA Fit\"), linewidth = 1) +\n  ggtitle(\"Wind Electricity Net Generation Forecast\") +\n  xlab(\"Year\") + ylab(\"Value\") +\n  scale_color_manual(values = c(\"Mean\" = \"blue\", \"Naïve\" = \"red\", \n                                \"Seasonal Naïve\" = \"green\", \"Drift\" = \"orange\", \n                                \"ARIMA Fit\" = \"purple\")) +\n  guides(colour = guide_legend(title = \"Forecast Methods\")) +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\n\n\n\nCode\n# Compute Accuracy Metrics Safely\nget_acc &lt;- function(model, name) {\n  acc &lt;- as.data.frame(accuracy(model))\n  rownames(acc) &lt;- NULL\n  acc$Method &lt;- name\n  return(acc)\n}\n\nacc_list &lt;- list(\n  get_acc(mean_forecast, \"Mean\"),\n  get_acc(naive_forecast, \"Naïve\"),\n  get_acc(snaive_forecast, \"SNaïve\"),\n  get_acc(drift_forecast, \"Drift\"),\n  get_acc(arima_forecast, \"ARIMA\")\n)\n\nacc_df &lt;- dplyr::bind_rows(acc_list)\n\nacc_summary &lt;- acc_df %&gt;%\n  dplyr::select(Method, RMSE, MAE, MAPE, MASE, ACF1) %&gt;%\n  dplyr::distinct()\n\nprint(acc_summary)\n\n\n  Method      RMSE        MAE      MAPE      MASE         ACF1\n1   Mean 1.4314929 1.24259431 15.262636 5.7652178  0.985950234\n2  Naïve 0.1737855 0.13286537  1.578536 0.6164504 -0.085979421\n3 SNaïve 0.2702475 0.21553293  2.609653 1.0000000  0.503213485\n4  Drift 0.1732856 0.13259742  1.576074 0.6152072 -0.085979421\n5  ARIMA 0.1339741 0.09925709  1.187064 0.4605194  0.005138504"
  },
  {
    "objectID": "univariate.html#solar",
    "href": "univariate.html#solar",
    "title": "ARMA, ARIMA, and SARIMA Models",
    "section": "Solar",
    "text": "Solar\n\n\nCode\nsolar_df &lt;- df %&gt;%\n  filter(Description == \"Solar\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_solar &lt;- ts(solar_df$Value,\n              start = c(min(solar_df$Year), min(solar_df$Month)),\n              frequency = 12)\n\n\n\nLog TransformationSeasonal DifferencingAugmented Dickey-Fuller TestACF and PACFManual ARIMAModel diagnostic and equationauto.arima()ForecastingBenchmark\n\n\nThe log-transformed, first-differenced series is more stationary than the first difference of the original scale. In the original-scale differences, variability increases toward the end—evidence of heteroskedasticity and residual non-stationarity. The log transform stabilizes the variance, so the differenced log series fluctuates around a roughly constant mean with nearly constant variation. However, the ACF still shows seasonal dependence (spikes at lags 12, 24, …). To address this remaining structure, we should apply a seasonal difference on top of the ordinary difference—i.e., compute —to remove the seasonal correlation.\n\n\nCode\n# Extract vectors\ndates &lt;- solar_df$Date\ny     &lt;- as.numeric(solar_df$Value)\n\ndiff_orig &lt;- diff(y)\ndiff_log  &lt;- diff(log(pmax(y, .Machine$double.eps)))  # safe log if any zeros\ndate_d    &lt;- dates[-1]\n\n# Data frames for ggplot\ndf_orig &lt;- data.frame(Date = date_d, Diff = diff_orig)\ndf_log  &lt;- data.frame(Date = date_d, Diff = diff_log)\n\n# Panel 1: differenced original\np1 &lt;- ggplot(df_orig, aes(x = Date, y = Diff)) +\n  geom_line(color = \"steelblue\") +\n  labs(title = \"First Difference (Original Scale)\",\n       x = \"Year\", y = \"First Difference\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"5 years\") +\n  theme_minimal()\n\n# Panel 2: differenced log\np2 &lt;- ggplot(df_log, aes(x = Date, y = Diff)) +\n  geom_line(color = \"firebrick\") +\n  labs(title = \"First Difference (Log Scale)\",\n       x = \"Year\", y = \"First Difference (log)\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"5 years\") +\n  theme_minimal()\n\n# Stack vertically\np1 / p2\n\n\n\n\n\n\n\n\n\n\n\nACF: Original series. Here it is evident that there is very high autocorrelation, including seasonal correlation, with highly significant serial correlation at seasonal lags. However, due to heteroscedasticity in the data, we need a log transformation.\nACF: log(xt) — ordinary diff. Here we can see the ordinary serial correlation is minimal compared to the raw series data ACF, but there is high seasonal correlation remains at lags 12, 24, etc. So we will need seasonal differencing.\nACF: log(xt) — seasonal diff. Here, when we apply seasonal differencing, we can see that the seasonal correlation has become very small, but the series is still not stationary due to high correlation from the ordinary lags. Our goal is to convert the data into a stationary process as a first step for our modeling process; therefore, we need both ordinary differencing on top of seasonal differencing.\nACF: log(xt) — ordinary + seasonal diff. With both ordinary and seasonal differencing, the series is now more stationary.\n\n\nCode\n# Log series (safe for zeros)\nlog_ts  &lt;- log(pmax(ts_solar, .Machine$double.eps))\n\n# Differencing\nd_log   &lt;- diff(log_ts)              # ordinary diff of log\nsd_log  &lt;- diff(log_ts, lag = 12)    # seasonal diff of log\nosd_log &lt;- diff(d_log,  lag = 12)    # first + seasonal diff of log\n\n# ACF plots\np1 &lt;- ggAcf(ts_solar,   lag.max = 60) + ggtitle(\"ACF: Original series\") +\n  theme_minimal()\np2 &lt;- ggAcf(d_log,   lag.max = 60) + ggtitle(\"ACF: log(xt)-ordinary diff)\") +\n  theme_minimal()\np3 &lt;- ggAcf(sd_log,  lag.max = 60) + ggtitle(\"ACF: log(xt)-seasonal diff\") +\n  theme_minimal()\np4 &lt;- ggAcf(osd_log, lag.max = 60) + ggtitle(\"ACF:log(xt)-ordinary + seasonal diff\") +\n  theme_minimal()\n\n# Arrange in a 2x2 grid\n(p1 | p2) / (p3 | p4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf.test(osd_log)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  osd_log\nDickey-Fuller = -10.723, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\np = 0:4, d = 1, q = 1, P = 0:3, D = 1, Q = 0:3\n\n\nCode\nacf &lt;-  ggAcf(osd_log, lag.max = 60) + ggtitle(\"ACF:log(xt)-ordinary + seasonal diff\") +\n  theme_minimal()\n\npacf &lt;- ggPacf(osd_log, lag.max = 60) + ggtitle(\"PACF:log(xt)-ordinary + seasonal diff\") +\n  theme_minimal()\n\ngrid.arrange(acf, pacf, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q&lt;=9)\n          {\n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=5,q1=1,q2=3,P1=1,P2=4,Q1=1,Q2=4,data=log_ts)\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q     AIC      BIC     AICc\n27 1 1 1 0 1 1 20.4737 35.19439 20.61259\n\n\n\n\n\nStandardized Residuals: The residuals fluctuate randomly around zero with no visible trend or seasonal pattern. Variance appears stable over time. Suggests residuals behave like white noise.\nACF of Residuals: Most autocorrelations are within the blue confidence bounds. No significant spikes → no serial correlation remains. Indicates good model fit.\nNormal Q–Q Plot: Points mostly lie on the 45° line, with slight deviation in the tails. Minor departure from normality at extremes, but acceptable for large samples.\nLjung–Box Test p-values: Some p-values above 0.05 across lags → we fail to reject the null hypothesis of no autocorrelation. Residuals are uncorrelated.\n\n\\[\n(1 - 0.1385B)(1 - B)(1 - B^{12})y_t\n= (1 + 0.8088B)(1 + 0.2874B^{12})\\varepsilon_t\n\\]\n\n\nCode\nmodel_output &lt;- capture.output(sarima(log_ts, 1,1,1, 0,1,1,12))\n\n\n\n\n\n\n\n\n\nCode\nstart_line &lt;- grep(\"Coefficients\", model_output)  \nend_line &lt;- length(model_output)\ncat(model_output[start_line:end_line], sep = \"\\n\")\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1    0.1385 0.0744   1.8614  0.0637\nma1   -0.8088 0.0428 -18.8908  0.0000\nsma1  -0.2874 0.0734  -3.9144  0.0001\n\nsigma^2 estimated as 0.06069645 on 290 degrees of freedom \n \nAIC = 0.06987611  AICc = 0.07015954  BIC = 0.1201174 \n \n\n\n\n\nDifferent from the chosen model.\nAlthough both models fit reasonably well, the manual model has lower AIC, AICc, and BIC, indicating superior performance. The difference likely arises from auto.arima()’s automated search limitations and the manual model’s closer alignment with the observed autocorrelation structure and residual diagnostics.\n\n\nCode\nauto.arima(log_ts)\n\n\nSeries: log_ts \nARIMA(0,1,1)(2,1,0)[12] \n\nCoefficients:\n          ma1     sar1     sar2\n      -0.7511  -0.2300  -0.1172\ns.e.   0.0459   0.0641   0.0657\n\nsigma^2 = 0.06217:  log likelihood = -8.13\nAIC=24.25   AICc=24.39   BIC=38.97\n\n\n\n\nThe results indicate a continued strong upward trend in solar power generation, reflecting the ongoing expansion of renewable energy capacity and technological improvements in solar energy efficiency. The seasonal pattern remains evident, suggesting that solar generation continues to fluctuate cyclically throughout the year, likely influenced by weather and solar conditions. The widening confidence bands illustrate increasing uncertainty over time, which is typical in medium-term forecasts. Overall, the model provides a good fit to the historical data and projects a steady growth trajectory for solar electricity generation, consistent with global energy transition trends.\n\n\nCode\nfit &lt;- Arima(log_ts, order=c(1,1,1), seasonal=c(0,1,1))\nfit %&gt;% forecast(h=36) %&gt;% autoplot() #next 3 years\n\n\n\n\n\n\n\n\n\n\n\n\nThe ARIMA model outperforms all benchmark models.\nThis indicates ARIMA captures both the underlying trend and seasonality of the solar generation data, making it the most reliable forecasting model among those tested.\n\n\n\nCode\n# Generate forecasts\nmean_forecast &lt;- forecast(meanf(log_ts, h = 36))\nnaive_forecast &lt;- forecast(naive(log_ts, h = 36))\nsnaive_forecast &lt;- forecast(snaive(log_ts, h = 36))\ndrift_forecast &lt;- forecast(rwf(log_ts, h = 36, drift = TRUE))\narima_forecast &lt;- forecast(fit, h = 36)\n\n# Convert forecasts to data frame\n# Extract forecasted values properly\nforecast_df &lt;- data.frame(\n  Date = seq(max(df_log$Date) %m+% months(1), by = \"month\", length.out = 36),\n  Mean = as.numeric(mean_forecast$mean),    # Extract mean forecast\n  Naive = as.numeric(naive_forecast$mean),\n  SNaive = as.numeric(snaive_forecast$mean),\n  Drift = as.numeric(drift_forecast$mean),\n  ARIMA = as.numeric(arima_forecast$mean)\n)\n\n# Plot with ggplot2\np &lt;- ggplot(solar_df, aes(x = Date, y = log(Value))) +\n  geom_line(color = \"black\", size = 1) +  # Actual Data\n  geom_line(data = forecast_df, aes(x = Date, y = Mean, color = \"Mean\"), linewidth = 1, linetype = \"dashed\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Naive, color = \"Naïve\"), linewidth = 1, linetype = \"dotted\") +\n  geom_line(data = forecast_df, aes(x = Date, y = SNaive, color = \"Seasonal Naïve\"), linewidth = 1, linetype = \"dotdash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Drift, color = \"Drift\"), linewidth = 1, linetype = \"twodash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = ARIMA, color = \"ARIMA Fit\"), linewidth = 1) +\n  ggtitle(\"Solar Electricity Net Generation Forecast\") +\n  xlab(\"Year\") + ylab(\"Value\") +\n  scale_color_manual(values = c(\"Mean\" = \"blue\", \"Naïve\" = \"red\", \n                                \"Seasonal Naïve\" = \"green\", \"Drift\" = \"orange\", \n                                \"ARIMA Fit\" = \"purple\")) +\n  guides(colour = guide_legend(title = \"Forecast Methods\")) +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\n\n\n\nCode\n# Compute Accuracy Metrics Safely\nget_acc &lt;- function(model, name) {\n  acc &lt;- as.data.frame(accuracy(model))\n  rownames(acc) &lt;- NULL\n  acc$Method &lt;- name\n  return(acc)\n}\n\nacc_list &lt;- list(\n  get_acc(mean_forecast, \"Mean\"),\n  get_acc(naive_forecast, \"Naïve\"),\n  get_acc(snaive_forecast, \"SNaïve\"),\n  get_acc(drift_forecast, \"Drift\"),\n  get_acc(arima_forecast, \"ARIMA\")\n)\n\nacc_df &lt;- dplyr::bind_rows(acc_list)\n\nacc_summary &lt;- acc_df %&gt;%\n  dplyr::select(Method, RMSE, MAE, MAPE, MASE, ACF1) %&gt;%\n  dplyr::distinct()\n\nprint(acc_summary)\n\n\n  Method      RMSE       MAE      MAPE      MASE         ACF1\n1   Mean 2.5126153 2.2927864 51.296079 6.8673608  0.975314008\n2  Naïve 0.4513865 0.2963849  9.040657 0.8877329  0.206852172\n3 SNaïve 0.4290561 0.3338672  6.919360 1.0000000  0.591550598\n4  Drift 0.4505947 0.2955583  9.067843 0.8852571  0.206852172\n5  ARIMA 0.2410778 0.1505371  4.232683 0.4508891 -0.006054956"
  },
  {
    "objectID": "univariate.html#hydroelectric-power",
    "href": "univariate.html#hydroelectric-power",
    "title": "ARMA, ARIMA, and SARIMA Models",
    "section": "Hydroelectric Power",
    "text": "Hydroelectric Power\n\n\nCode\nhy_df &lt;- df %&gt;%\n  filter(Description == \"Conventional Hydroelectric Power\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_hy &lt;- ts(hy_df$Value,\n              start = c(min(hy_df$Year), min(hy_df$Month)),\n              frequency = 12)\n\n\n\nSeasonal DifferencingAugmented Dickey-Fuller TestACF and PACFManual ARIMAModel diagnostic and equationauto.arima()ForecastingBenchmark\n\n\nACF: First diff, there is high seasonal correlation remains at lags 12, 24, etc. So we will need seasonal differencing.\nACF: SSeasonal diff. Here, when we apply seasonal differencing, we can see that the seasonal correlation has become very small, but the series is still not stationary due to high correlation from the ordinary lags. Our goal is to convert the data into a stationary process as a first step for our modeling process; therefore, we need both ordinary differencing on top of seasonal differencing.\nACF: First + seasonal diff. With both ordinary and seasonal differencing, the series is now more stationary.\n\n\nCode\n# Differencing\nd   &lt;- diff(ts_hy)              \nsd &lt;- diff(ts_hy, lag = 12)    \nosd &lt;- diff(d,  lag = 12)    # first + seasonal diff of log\n\n# ACF plots\np2 &lt;- ggAcf(d, lag.max = 60) + ggtitle(\"ACF: First diff\") +\n  theme_minimal()\np3 &lt;- ggAcf(sd,  lag.max = 60) + ggtitle(\"ACF: Seasonal diff\") +\n  theme_minimal()\np4 &lt;- ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\n# Arrange in a 2x2 grid\ngrid.arrange(p2, p3,p4, nrow=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf.test(osd)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  osd\nDickey-Fuller = -8.3022, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\np = 0:2, d = 1, q = 1:2, P = 0:4, D = 1, Q = 0:2\n\n\nCode\nacf &lt;-  ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\npacf &lt;- ggPacf(osd, lag.max = 60) + ggtitle(\"PACF: First + seasonal diff\") +\n  theme_minimal()\n\ngrid.arrange(acf, pacf, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q&lt;=9)\n          {\n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=3,P1=1,P2=5,Q1=1,Q2=3,data=ts_hy)\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n26 1 1 1 0 1 1 5231.433 5246.154 5231.572\n\n\n\n\n\nStandardized Residuals: The residuals fluctuate randomly around zero with no visible trend or seasonal pattern. Variance appears stable over time. Suggests residuals behave like white noise.\nACF of Residuals: All autocorrelations are within the blue confidence bounds.No significant spikes → no serial correlation remains. Indicates good model fit.\nNormal Q–Q Plot: Points mostly lie on the 45° line, with slight deviation in the tails. Minor departure from normality at extremes, but acceptable for large samples.\nLjung–Box Test p-values: Most p-values above 0.05 across lags → we fail to reject the null hypothesis of no autocorrelation. Residuals are uncorrelated.\n\n\\[\n(1 - 0.7231B)(1 - B)(1 - B^{12})y_t\n= (1 - 0.9722B)(1 - 0.8675B^{12})\\varepsilon_t\n\\]\n\n\nCode\nmodel_output &lt;- capture.output(sarima(ts_hy, 1,1,1, 0,1,1,12))\n\n\n\n\n\n\n\n\n\nCode\nstart_line &lt;- grep(\"Coefficients\", model_output)  \nend_line &lt;- length(model_output)\ncat(model_output[start_line:end_line], sep = \"\\n\")\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1    0.7231 0.0543  13.3083       0\nma1   -0.9722 0.0286 -33.9398       0\nsma1  -0.8675 0.0527 -16.4557       0\n\nsigma^2 estimated as 3023036 on 290 degrees of freedom \n \nAIC = 17.85472  AICc = 17.85501  BIC = 17.90496 \n \n\n\n\n\n\nDifferent from the chosen model.\nlthough both models fit well, the manual model has lower AIC and BIC, suggesting a marginally better and more parsimonious fit.\nThe main difference stems from auto.arima() using no differencing but adding a drift term to capture trend, whereas the manual model uses differencing to achieve stationarity.\nThis reflects two equivalent approaches to handling non-stationarity—either differencing or including a deterministic drift term.\n\n\n\nCode\nauto.arima(ts_hy)\n\n\nSeries: ts_hy \nARIMA(1,0,2)(0,1,1)[12] with drift \n\nCoefficients:\n         ar1      ma1      ma2     sma1    drift\n      0.8174  -0.0553  -0.1345  -0.8623  -2.6766\ns.e.  0.0595   0.0851   0.0756   0.0502   6.9912\n\nsigma^2 = 3009594:  log likelihood = -2616\nAIC=5244   AICc=5244.29   BIC=5266.1\n\n\n\n\nThe historical data show strong seasonal variation and substantial short-term fluctuations, reflecting the natural dependency of hydroelectric output on rainfall patterns, reservoir levels, and seasonal water availability. The model captures these seasonal cycles well, as seen in the repeating peaks and troughs in the forecasted period. The forecast indicates that hydroelectric generation will likely remain stable overall, without a pronounced long-term upward or downward trend. However, the wide confidence intervals suggest considerable uncertainty, emphasizing the sensitivity of hydroelectric generation to unpredictable climatic and environmental factors. In summary, the model predicts a continuation of historical variability, with hydroelectric power maintaining a consistent but fluctuating contribution to total electricity generation.\n\n\nCode\nfit &lt;- Arima(ts_hy, order=c(1,1,1), seasonal=c(0,1,1))\nfit %&gt;% forecast(h=36) %&gt;% autoplot() #next 3 years\n\n\n\n\n\n\n\n\n\n\n\n\nThe ARIMA model outperforms all benchmark models.\nThis indicates ARIMA captures both the underlying trend and seasonality of the hydroelectirc power generation data, making it the most reliable forecasting model among those tested.\n\n\n\nCode\n# Generate forecasts\nmean_forecast &lt;- forecast(meanf(ts_hy, h = 36))\nnaive_forecast &lt;- forecast(naive(ts_hy, h = 36))\nsnaive_forecast &lt;- forecast(snaive(ts_hy, h = 36))\ndrift_forecast &lt;- forecast(rwf(ts_hy, h = 36, drift = TRUE))\narima_forecast &lt;- forecast(fit, h = 36)\n\n# Convert forecasts to data frame\n# Extract forecasted values properly\nforecast_df &lt;- data.frame(\n  Date = seq(max(hy_df$Date) %m+% months(1), by = \"month\", length.out = 36),\n  Mean = as.numeric(mean_forecast$mean),    # Extract mean forecast\n  Naive = as.numeric(naive_forecast$mean),\n  SNaive = as.numeric(snaive_forecast$mean),\n  Drift = as.numeric(drift_forecast$mean),\n  ARIMA = as.numeric(arima_forecast$mean)\n)\n\n# Plot with ggplot2\np &lt;- ggplot(hy_df, aes(x = Date, y = Value)) +\n  geom_line(color = \"black\", size = 1) +  # Actual Data\n  geom_line(data = forecast_df, aes(x = Date, y = Mean, color = \"Mean\"), linewidth = 1, linetype = \"dashed\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Naive, color = \"Naïve\"), linewidth = 1, linetype = \"dotted\") +\n  geom_line(data = forecast_df, aes(x = Date, y = SNaive, color = \"Seasonal Naïve\"), linewidth = 1, linetype = \"dotdash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Drift, color = \"Drift\"), linewidth = 1, linetype = \"twodash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = ARIMA, color = \"ARIMA Fit\"), linewidth = 1) +\n  ggtitle(\"Hydroelectric Power Electricity Net Generation Forecast\") +\n  xlab(\"Year\") + ylab(\"Value\") +\n  scale_color_manual(values = c(\"Mean\" = \"blue\", \"Naïve\" = \"red\", \n                                \"Seasonal Naïve\" = \"green\", \"Drift\" = \"orange\", \n                                \"ARIMA Fit\" = \"purple\")) +\n  guides(colour = guide_legend(title = \"Forecast Methods\")) +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\n\n\n\nCode\n# Compute Accuracy Metrics Safely\nget_acc &lt;- function(model, name) {\n  acc &lt;- as.data.frame(accuracy(model))\n  rownames(acc) &lt;- NULL\n  acc$Method &lt;- name\n  return(acc)\n}\n\nacc_list &lt;- list(\n  get_acc(mean_forecast, \"Mean\"),\n  get_acc(naive_forecast, \"Naïve\"),\n  get_acc(snaive_forecast, \"SNaïve\"),\n  get_acc(drift_forecast, \"Drift\"),\n  get_acc(arima_forecast, \"ARIMA\")\n)\n\nacc_df &lt;- dplyr::bind_rows(acc_list)\n\nacc_summary &lt;- acc_df %&gt;%\n  dplyr::select(Method, RMSE, MAE, MAPE, MASE, ACF1) %&gt;%\n  dplyr::distinct()\n\nprint(acc_summary)\n\n\n  Method     RMSE      MAE      MAPE      MASE       ACF1\n1   Mean 3888.367 3166.621 14.662552 1.3703977 0.71861624\n2  Naïve 2916.527 2429.328 11.093069 1.0513240 0.10957299\n3 SNaïve 3100.902 2310.732 10.290935 1.0000000 0.69707977\n4  Drift 2916.506 2429.581 11.092488 1.0514337 0.10957299\n5  ARIMA 1701.365 1272.890  5.706318 0.5508601 0.01820591"
  },
  {
    "objectID": "univariate.html#coal",
    "href": "univariate.html#coal",
    "title": "ARMA, ARIMA, and SARIMA Models",
    "section": "Coal",
    "text": "Coal\n\n\nCode\ncoal_df &lt;- df %&gt;%\n  filter(Description == \"Coal\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_coal &lt;- ts(coal_df$Value,\n              start = c(min(coal_df$Year), min(coal_df$Month)),\n              frequency = 12)\n\n\n\nSeasonal DifferencingAugmented Dickey-Fuller TestACF and PACFManual ARIMAModel diagnostic and equationauto.arima()ForecastingBenchmark\n\n\nACF: First diff, there is high seasonal correlation remains at lags 12, 24, etc. So we will need seasonal differencing.\nACF: SSeasonal diff. Here, when we apply seasonal differencing, we can see that the seasonal correlation has become very small, but the series is still not stationary due to high correlation from the ordinary lags. Our goal is to convert the data into a stationary process as a first step for our modeling process; therefore, we need both ordinary differencing on top of seasonal differencing.\nACF: First + seasonal diff. With both ordinary and seasonal differencing, the series is now more stationary.\n\n\nCode\n# Differencing\nd   &lt;- diff(ts_coal)              \nsd &lt;- diff(ts_coal, lag = 12)    \nosd &lt;- diff(d,  lag = 12)    # first + seasonal diff of log\n\n# ACF plots\np2 &lt;- ggAcf(d, lag.max = 60) + ggtitle(\"ACF: First diff)\") +\n  theme_minimal()\np3 &lt;- ggAcf(sd,  lag.max = 60) + ggtitle(\"ACF: seasonal diff\") +\n  theme_minimal()\np4 &lt;- ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\n# Arrange in a 2x2 grid\ngrid.arrange(p2, p3, p4, nrow=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf.test(osd)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  osd\nDickey-Fuller = -7.2102, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\np = 0:2, d = 1, q = 1, P = 0:3, D = 1, Q = 1\n\n\nCode\nacf &lt;-  ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\npacf &lt;- ggPacf(osd, lag.max = 60) + ggtitle(\"PACF: First + seasonal diff\") +\n  theme_minimal()\n\ngrid.arrange(acf, pacf, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q&lt;=9)\n          {\n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=3,P1=1,P2=4,Q1=1,Q2=3,data=ts_coal)\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n26 1 1 1 0 1 1 6008.907 6023.628 6009.046\n\n\n\n\n\nStandardized Residuals: The residuals fluctuate randomly around zero with no visible trend or seasonal pattern. Variance appears stable over time. Suggests residuals behave like white noise.\nACF of Residuals: Most autocorrelations are within the blue confidence bounds. No significant spikes → no serial correlation remains. Indicates good model fit.\nNormal Q–Q Plot: Points mostly lie on the 45° line, with slight deviation in the tails. Minor departure from normality at extremes, but acceptable for large samples.\nLjung–Box Test p-values: Most p-values above 0.05 across lags → we fail to reject the null hypothesis of no autocorrelation. Residuals are uncorrelated.\n\n\\[\n(1 - 0.403B)(1 - B)(1 - B^{12})y_t\n= (1 + 0.725B)(1 + 0.887B^{12})\\varepsilon_t\n\\]\n\n\nCode\nmodel_output &lt;- capture.output(sarima(ts_coal, 1,1,1, 0,1,1,12))\n\n\n\n\n\n\n\n\n\nCode\nstart_line &lt;- grep(\"Coefficients\", model_output)  \nend_line &lt;- length(model_output)\ncat(model_output[start_line:end_line], sep = \"\\n\")\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1     0.403 0.1523   2.6454  0.0086\nma1    -0.725 0.1209  -5.9952  0.0000\nsma1   -0.887 0.0412 -21.5194  0.0000\n\nsigma^2 estimated as 43094604 on 290 degrees of freedom \n \nAIC = 20.50821  AICc = 20.5085  BIC = 20.55846 \n \n\n\n\n\n\nDifferent from the chosen model.\nWhile both capture the same seasonal structure, the manual model performs slightly better (lower AIC/BIC).\nThe key distinction is that auto.arima() modeled trend using a drift term without differencing, whereas the manual model used first differencing to achieve stationarity.\nThis difference likely explains why the manual model provides a better overall fit.\n\n\n\nCode\nauto.arima(ts_coal)\n\n\nSeries: ts_coal \nARIMA(1,0,2)(0,1,1)[12] with drift \n\nCoefficients:\n         ar1      ma1      ma2     sma1      drift\n      0.9649  -0.3056  -0.1263  -0.8775  -386.5401\ns.e.  0.0202   0.0621   0.0620   0.0441    81.6279\n\nsigma^2 = 43243688:  log likelihood = -3008.1\nAIC=6028.2   AICc=6028.49   BIC=6050.3\n\n\n\n\nThe historical data display a clear long-term downward trend, reflecting the steady decline of coal use in power generation due to rising environmental regulations, aging infrastructure, and the shift toward cleaner energy sources. The model captures both this declining trend and the persistent seasonal fluctuations, likely associated with changes in energy demand across different months. The forecast suggests that coal generation will continue to decrease modestly over the next few years, with values remaining substantially below their early-2000s levels. The widening confidence intervals highlight growing uncertainty, possibly reflecting volatility in energy policy, fuel prices, and demand patterns. Overall, the results are consistent with the ongoing energy transition away from fossil fuels toward renewable alternatives.\n\n\nCode\nfit &lt;- Arima(ts_coal, order=c(1,1,1), seasonal=c(0,1,1))\nfit %&gt;% forecast(h=36) %&gt;% autoplot() #next 3 years\n\n\n\n\n\n\n\n\n\n\n\n\nThe ARIMA model outperforms all benchmark models.\nThis indicates ARIMA captures both the underlying trend and seasonality of the coal generation data, making it the most reliable forecasting model among those tested.\n\n\n\nCode\n# Generate forecasts\nmean_forecast &lt;- forecast(meanf(ts_coal, h = 36))\nnaive_forecast &lt;- forecast(naive(ts_coal, h = 36))\nsnaive_forecast &lt;- forecast(snaive(ts_coal, h = 36))\ndrift_forecast &lt;- forecast(rwf(ts_coal, h = 36, drift = TRUE))\narima_forecast &lt;- forecast(fit, h = 36)\n\n# Convert forecasts to data frame\n# Extract forecasted values properly\nforecast_df &lt;- data.frame(\n  Date = seq(max(coal_df$Date) %m+% months(1), by = \"month\", length.out = 36),\n  Mean = as.numeric(mean_forecast$mean),    # Extract mean forecast\n  Naive = as.numeric(naive_forecast$mean),\n  SNaive = as.numeric(snaive_forecast$mean),\n  Drift = as.numeric(drift_forecast$mean),\n  ARIMA = as.numeric(arima_forecast$mean)\n)\n\n# Plot with ggplot2\np &lt;- ggplot(coal_df, aes(x = Date, y = Value)) +\n  geom_line(color = \"black\", size = 1) +  # Actual Data\n  geom_line(data = forecast_df, aes(x = Date, y = Mean, color = \"Mean\"), linewidth = 1, linetype = \"dashed\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Naive, color = \"Naïve\"), linewidth = 1, linetype = \"dotted\") +\n  geom_line(data = forecast_df, aes(x = Date, y = SNaive, color = \"Seasonal Naïve\"), linewidth = 1, linetype = \"dotdash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Drift, color = \"Drift\"), linewidth = 1, linetype = \"twodash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = ARIMA, color = \"ARIMA Fit\"), linewidth = 1) +\n  ggtitle(\"Coal Electricity Net Generation Forecast\") +\n  xlab(\"Year\") + ylab(\"Value\") +\n  scale_color_manual(values = c(\"Mean\" = \"blue\", \"Naïve\" = \"red\", \n                                \"Seasonal Naïve\" = \"green\", \"Drift\" = \"orange\", \n                                \"ARIMA Fit\" = \"purple\")) +\n  guides(colour = guide_legend(title = \"Forecast Methods\")) +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\n\n\n\nCode\n# Compute Accuracy Metrics Safely\nget_acc &lt;- function(model, name) {\n  acc &lt;- as.data.frame(accuracy(model))\n  rownames(acc) &lt;- NULL\n  acc$Method &lt;- name\n  return(acc)\n}\n\nacc_list &lt;- list(\n  get_acc(mean_forecast, \"Mean\"),\n  get_acc(naive_forecast, \"Naïve\"),\n  get_acc(snaive_forecast, \"SNaïve\"),\n  get_acc(drift_forecast, \"Drift\"),\n  get_acc(arima_forecast, \"ARIMA\")\n)\n\nacc_df &lt;- dplyr::bind_rows(acc_list)\n\nacc_summary &lt;- acc_df %&gt;%\n  dplyr::select(Method, RMSE, MAE, MAPE, MASE, ACF1) %&gt;%\n  dplyr::distinct()\n\nprint(acc_summary)\n\n\n  Method     RMSE       MAE      MAPE     MASE         ACF1\n1   Mean 42640.17 37209.407 40.976347 3.825499  0.937508230\n2  Naïve 14378.81 12006.462 11.190410 1.234384  0.194003508\n3 SNaïve 12907.03  9726.681 10.295471 1.000000  0.728652099\n4  Drift 14373.98 12005.322 11.164493 1.234267  0.194003508\n5  ARIMA  6423.78  4684.944  4.742525 0.481659 -0.004676138"
  },
  {
    "objectID": "univariate.html#nuclear-electric-power",
    "href": "univariate.html#nuclear-electric-power",
    "title": "ARMA, ARIMA, and SARIMA Models",
    "section": "Nuclear Electric Power",
    "text": "Nuclear Electric Power\n\n\nCode\nnuclear_df &lt;- df %&gt;%\n  filter(Description == \"Nuclear Electric Power\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_nuclear &lt;- ts(nuclear_df$Value,\n              start = c(min(nuclear_df$Year), min(nuclear_df$Month)),\n              frequency = 12)\n\n\n\nSeasonal DifferencingAugmented Dickey-Fuller TestACF and PACFManual ARIMAModel diagnostic and equationauto.arima()ForecastingBenchmark\n\n\nACF: First diff, there is high seasonal correlation remains at lags 12, 24, etc. So we will need seasonal differencing.\nACF: SSeasonal diff. Here, when we apply seasonal differencing, we can see that the seasonal correlation has become very small, but the series is still not stationary due to high correlation from the ordinary lags. Our goal is to convert the data into a stationary process as a first step for our modeling process; therefore, we need both ordinary differencing on top of seasonal differencing.\nACF: First + seasonal diff. With both ordinary and seasonal differencing, the series is now more stationary.\n\n\nCode\n# Differencing\nd   &lt;- diff(ts_nuclear)              \nsd &lt;- diff(ts_nuclear, lag = 12)    \nosd &lt;- diff(d,  lag = 12)    # first + seasonal diff of log\n\n# ACF plots\np2 &lt;- ggAcf(d, lag.max = 60) + ggtitle(\"ACF: First diff)\") +\n  theme_minimal()\np3 &lt;- ggAcf(sd,  lag.max = 60) + ggtitle(\"ACF: seasonal diff\") +\n  theme_minimal()\np4 &lt;- ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\n# Arrange in a 2x2 grid\ngrid.arrange(p2, p3, p4, nrow=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf.test(osd)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  osd\nDickey-Fuller = -9.6711, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\np = 0:2, d = 1, q = 0:2, P = 0:2, D = 1, Q = 1\n\n\nCode\nacf &lt;-  ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\npacf &lt;- ggPacf(osd, lag.max = 60) + ggtitle(\"PACF: First + seasonal diff\") +\n  theme_minimal()\n\ngrid.arrange(acf, pacf, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q&lt;=9)\n          {\n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=3,P1=1,P2=3,Q1=1,Q2=3,data=ts_nuclear)\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC   AICc\n25 1 1 1 0 1 1 5128.561 5143.281 5128.7\n\n\n\n\n\nStandardized Residuals: The residuals fluctuate randomly around zero with no visible trend or seasonal pattern. Variance appears stable over time. Suggests residuals behave like white noise.\nACF of Residuals: Most autocorrelations are within the blue confidence bounds. No significant spikes → no serial correlation remains. Indicates good model fit.\nNormal Q–Q Plot: Points mostly lie on the 45° line, with slight deviation in the tails. Minor departure from normality at extremes, but acceptable for large samples.\nLjung–Box Test p-values: Some p-values above 0.05 across lags → we fail to reject the null hypothesis of no autocorrelation. Residuals are uncorrelated. But the model may still have room for improvement.\n\n\\[\n(1 - 0.5737B)(1 - B)(1 - B^{12})y_t\n= (1 + 0.9381B)(1 + 0.9185B^{12})\\varepsilon_t\n\\]\n\n\nCode\nmodel_output &lt;- capture.output(sarima(ts_nuclear, 1,1,1, 0,1,1,12))\n\n\n\n\n\n\n\n\n\nCode\nstart_line &lt;- grep(\"Coefficients\", model_output)  \nend_line &lt;- length(model_output)\ncat(model_output[start_line:end_line], sep = \"\\n\")\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1    0.5737 0.0584   9.8262       0\nma1   -0.9381 0.0258 -36.3730       0\nsma1  -0.9185 0.0610 -15.0617       0\n\nsigma^2 estimated as 2096780 on 290 degrees of freedom \n \nAIC = 17.50362  AICc = 17.5039  BIC = 17.55386 \n \n\n\n\n\n\nDifferent from the chosen model.\n\nWhile both capture seasonality, the manual model achieves significantly lower AIC, AICc, and BIC, indicating a more parsimonious and better-fitting structure.\nThe difference arises mainly from auto.arima() omitting non-seasonal differencing and compensating with additional AR terms, whereas the manual model achieves stationarity through differencing — a more efficient representation of the data’s underlying process.\n\n\n\nCode\nauto.arima(ts_nuclear)\n\n\nSeries: ts_nuclear \nARIMA(2,0,1)(2,1,0)[12] \n\nCoefficients:\n         ar1      ar2      ma1     sar1     sar2\n      1.4360  -0.4696  -0.8603  -0.6827  -0.4051\ns.e.  0.1346   0.1056   0.1111   0.0567   0.0576\n\nsigma^2 = 2409619:  log likelihood = -2578.65\nAIC=5169.3   AICc=5169.59   BIC=5191.4\n\n\n\n\nThe forecasts suggest that future production will maintain similar seasonal fluctuations without a significant upward or downward long-term trend. The confidence bands widen progressively, reflecting growing uncertainty over time but still indicate overall stability in nuclear output.\n\n\nCode\nfit &lt;- Arima(ts_nuclear, order=c(1,1,1), seasonal=c(0,1,1))\nfit %&gt;% forecast(h=36) %&gt;% autoplot() #next 3 years\n\n\n\n\n\n\n\n\n\n\n\n\nThe ARIMA model outperforms all benchmark models.\nThis indicates ARIMA captures both the underlying trend and seasonality of the nuclear electric power generation data, making it the most reliable forecasting model among those tested.\n\n\n\nCode\n# Generate forecasts\nmean_forecast &lt;- forecast(meanf(ts_nuclear, h = 36))\nnaive_forecast &lt;- forecast(naive(ts_nuclear, h = 36))\nsnaive_forecast &lt;- forecast(snaive(ts_nuclear, h = 36))\ndrift_forecast &lt;- forecast(rwf(ts_nuclear, h = 36, drift = TRUE))\narima_forecast &lt;- forecast(fit, h = 36)\n\n# Convert forecasts to data frame\n# Extract forecasted values properly\nforecast_df &lt;- data.frame(\n  Date = seq(max(nuclear_df$Date) %m+% months(1), by = \"month\", length.out = 36),\n  Mean = as.numeric(mean_forecast$mean),    # Extract mean forecast\n  Naive = as.numeric(naive_forecast$mean),\n  SNaive = as.numeric(snaive_forecast$mean),\n  Drift = as.numeric(drift_forecast$mean),\n  ARIMA = as.numeric(arima_forecast$mean)\n)\n\n# Plot with ggplot2\np &lt;- ggplot(nuclear_df, aes(x = Date, y = Value)) +\n  geom_line(color = \"black\", size = 1) +  # Actual Data\n  geom_line(data = forecast_df, aes(x = Date, y = Mean, color = \"Mean\"), linewidth = 1, linetype = \"dashed\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Naive, color = \"Naïve\"), linewidth = 1, linetype = \"dotted\") +\n  geom_line(data = forecast_df, aes(x = Date, y = SNaive, color = \"Seasonal Naïve\"), linewidth = 1, linetype = \"dotdash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Drift, color = \"Drift\"), linewidth = 1, linetype = \"twodash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = ARIMA, color = \"ARIMA Fit\"), linewidth = 1) +\n  ggtitle(\"Nuclear Electricity Net Generation Forecast\") +\n  xlab(\"Year\") + ylab(\"Value\") +\n  scale_color_manual(values = c(\"Mean\" = \"blue\", \"Naïve\" = \"red\", \n                                \"Seasonal Naïve\" = \"green\", \"Drift\" = \"orange\", \n                                \"ARIMA Fit\" = \"purple\")) +\n  guides(colour = guide_legend(title = \"Forecast Methods\")) +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\n\n\n\nCode\n# Compute Accuracy Metrics Safely\nget_acc &lt;- function(model, name) {\n  acc &lt;- as.data.frame(accuracy(model))\n  rownames(acc) &lt;- NULL\n  acc$Method &lt;- name\n  return(acc)\n}\n\nacc_list &lt;- list(\n  get_acc(mean_forecast, \"Mean\"),\n  get_acc(naive_forecast, \"Naïve\"),\n  get_acc(snaive_forecast, \"SNaïve\"),\n  get_acc(drift_forecast, \"Drift\"),\n  get_acc(arima_forecast, \"ARIMA\")\n)\n\nacc_df &lt;- dplyr::bind_rows(acc_list)\n\nacc_summary &lt;- acc_df %&gt;%\n  dplyr::select(Method, RMSE, MAE, MAPE, MASE, ACF1) %&gt;%\n  dplyr::distinct()\n\nprint(acc_summary)\n\n\n  Method     RMSE      MAE     MAPE      MASE         ACF1\n1   Mean 4830.375 4046.201 6.239002 2.2678504  0.416270652\n2  Naïve 5219.463 4349.728 6.746890 2.4379737  0.054355211\n3 SNaïve 2328.150 1784.157 2.769507 1.0000000  0.579157589\n4  Drift 5219.442 4351.436 6.748660 2.4389311  0.054355211\n5  ARIMA 1416.998 1079.747 1.676060 0.6051862 -0.001624595\n\n\n\n\n\n\nNatural gas\n\n\nCode\nn_df &lt;- df %&gt;%\n  filter(Description == \"Natural Gas\") %&gt;%\n  filter(!is.na(Value)) %&gt;% \n  mutate(Value = as.numeric(Value)) %&gt;%\n  arrange(Date)\n\nts_n &lt;- ts(n_df$Value,\n              start = c(min(n_df$Year), min(n_df$Month)),\n              frequency = 12)\n\n\n\nSeasonal DifferencingAugmented Dickey-Fuller TestACF and PACFManual ARIMAModel diagnostic and equationauto.arima()ForecastingBenchmark\n\n\nACF: First diff, there is high seasonal correlation remains at lags 12, 24, etc. So we will need seasonal differencing.\nACF: SSeasonal diff. Here, when we apply seasonal differencing, we can see that the seasonal correlation has become very small, but the series is still not stationary due to high correlation from the ordinary lags. Our goal is to convert the data into a stationary process as a first step for our modeling process; therefore, we need both ordinary differencing on top of seasonal differencing.\nACF: First + seasonal diff. With both ordinary and seasonal differencing, the series is now more stationary.\n\n\nCode\n# Differencing\nd   &lt;- diff(ts_n)              \nsd &lt;- diff(ts_n, lag = 12)    \nosd &lt;- diff(d,  lag = 12)    # first + seasonal diff of log\n\n# ACF plots\np2 &lt;- ggAcf(d, lag.max = 60) + ggtitle(\"ACF: Firstdiff)\") +\n  theme_minimal()\np3 &lt;- ggAcf(sd,  lag.max = 60) + ggtitle(\"ACF: seasonal diff\") +\n  theme_minimal()\np4 &lt;- ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\n# Arrange in a 2x2 grid\ngrid.arrange(p2, p3, p4, nrow=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf.test(osd)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  osd\nDickey-Fuller = -7.3548, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\np = 0:2, d = 1, q = 1, P = 0:3, D = 1, Q = 1\n\n\nCode\nacf &lt;-  ggAcf(osd, lag.max = 60) + ggtitle(\"ACF: First + seasonal diff\") +\n  theme_minimal()\n\npacf &lt;- ggPacf(osd, lag.max = 60) + ggtitle(\"PACF: First + seasonal diff\") +\n  theme_minimal()\n\ngrid.arrange(acf, pacf, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){\n  \n  temp=c()\n  d=1\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*35),nrow=35)\n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          if(p+d+q+P+D+Q&lt;=9)\n          {\n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n          }\n        }\n      }\n    }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  temp\n}\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=3,P1=1,P2=4,Q1=1,Q2=3,data=ts_n)\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC     BIC     AICc\n26 1 1 1 0 1 1 5885.629 5900.35 5885.768\n\n\n\n\n\nStandardized Residuals: The residuals fluctuate randomly around zero with no visible trend or seasonal pattern. Variance appears stable over time. Suggests residuals behave like white noise.\nACF of Residuals: Most autocorrelations are within the blue confidence bounds. No significant spikes → no serial correlation remains. Indicates good model fit.\nNormal Q–Q Plot: Points mostly lie on the 45° line, with slight deviation in the tails. Minor departure from normality at extremes, but acceptable for large samples.\nLjung–Box Test p-values: The results indicate that the values fall below the 0.05 (5% significance) threshold, signifying remaining correlation and the need for model improvement.\n\n\\[\n(1 - 0.7163B)(1 - B)(1 - B^{12})y_t\n= (1 + 0.987B)(1 + 0.67B^{12})\\varepsilon_t\n\\]\n\n\nCode\nmodel_output &lt;- capture.output(sarima(ts_n, 1,1,1, 0,1,1,12))\n\n\n\n\n\n\n\n\n\nCode\nstart_line &lt;- grep(\"Coefficients\", model_output)  \nend_line &lt;- length(model_output)\ncat(model_output[start_line:end_line], sep = \"\\n\")\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nar1    0.7163 0.0438  16.3393       0\nma1   -0.9870 0.0130 -76.2095       0\nsma1  -0.6700 0.0456 -14.6973       0\n\nsigma^2 estimated as 29081574 on 290 degrees of freedom \n \nAIC = 20.08747  AICc = 20.08775  BIC = 20.13771 \n \n\n\n\n\n\nDifferent from the chosen model.\n\nWhile both capture similar autoregressive, moving-average, and seasonal patterns, the manual model applies differencing rather than drift to handle trend.\nThe manual model achieves lower AIC, BIC, and AICc, indicating a better overall fit.\nThe difference likely arises from auto.arima() treating the series as trend-stationary, whereas the manual model assumes stochastic non-stationarity and achieves stationarity through differencing.\n\n\n\nCode\nauto.arima(ts_n)\n\n\nSeries: ts_n \nARIMA(1,0,1)(0,1,1)[12] with drift \n\nCoefficients:\n         ar1      ma1     sma1     drift\n      0.7872  -0.1362  -0.6513  357.7353\ns.e.  0.0519   0.0873   0.0464   39.4676\n\nsigma^2 = 29029334:  log likelihood = -2944.83\nAIC=5899.66   AICc=5899.87   BIC=5918.07\n\n\n\n\nThe ARIMA model captures both the strong upward trend and pronounced seasonality of natural gas electricity generation. Forecasts indicate that production will continue to rise, with similar seasonal variation patterns in the future. While uncertainty increases over time, the general outlook suggests a stable and sustained growth trajectory for natural gas as a key source of electricity generation.\n\n\nCode\nfit &lt;- Arima(ts_n, order=c(1,1,1), seasonal=c(0,1,1))\nfit %&gt;% forecast(h=36) %&gt;% autoplot() #next 3 years\n\n\n\n\n\n\n\n\n\n\n\n\nThe ARIMA model outperforms all benchmark models.\nThis indicates ARIMA captures both the underlying trend and seasonality of the natural gas generation data, making it the most reliable forecasting model among those tested.\n\n\n\nCode\n# Generate forecasts\nmean_forecast &lt;- forecast(meanf(ts_n, h = 36))\nnaive_forecast &lt;- forecast(naive(ts_n, h = 36))\nsnaive_forecast &lt;- forecast(snaive(ts_n, h = 36))\ndrift_forecast &lt;- forecast(rwf(ts_n, h = 36, drift = TRUE))\narima_forecast &lt;- forecast(fit, h = 36)\n\n# Convert forecasts to data frame\n# Extract forecasted values properly\nforecast_df &lt;- data.frame(\n  Date = seq(max(n_df$Date) %m+% months(1), by = \"month\", length.out = 36),\n  Mean = as.numeric(mean_forecast$mean),    # Extract mean forecast\n  Naive = as.numeric(naive_forecast$mean),\n  SNaive = as.numeric(snaive_forecast$mean),\n  Drift = as.numeric(drift_forecast$mean),\n  ARIMA = as.numeric(arima_forecast$mean)\n)\n\n# Plot with ggplot2\np &lt;- ggplot(n_df, aes(x = Date, y = Value)) +\n  geom_line(color = \"black\", size = 1) +  # Actual Data\n  geom_line(data = forecast_df, aes(x = Date, y = Mean, color = \"Mean\"), linewidth = 1, linetype = \"dashed\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Naive, color = \"Naïve\"), linewidth = 1, linetype = \"dotted\") +\n  geom_line(data = forecast_df, aes(x = Date, y = SNaive, color = \"Seasonal Naïve\"), linewidth = 1, linetype = \"dotdash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = Drift, color = \"Drift\"), linewidth = 1, linetype = \"twodash\") +\n  geom_line(data = forecast_df, aes(x = Date, y = ARIMA, color = \"ARIMA Fit\"), linewidth = 1) +\n  ggtitle(\"Natural gas Electricity Net Generation Forecast\") +\n  xlab(\"Year\") + ylab(\"Value\") +\n  scale_color_manual(values = c(\"Mean\" = \"blue\", \"Naïve\" = \"red\", \n                                \"Seasonal Naïve\" = \"green\", \"Drift\" = \"orange\", \n                                \"ARIMA Fit\" = \"purple\")) +\n  guides(colour = guide_legend(title = \"Forecast Methods\")) +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\n\n\n\nCode\n# Compute Accuracy Metrics Safely\nget_acc &lt;- function(model, name) {\n  acc &lt;- as.data.frame(accuracy(model))\n  rownames(acc) &lt;- NULL\n  acc$Method &lt;- name\n  return(acc)\n}\n\nacc_list &lt;- list(\n  get_acc(mean_forecast, \"Mean\"),\n  get_acc(naive_forecast, \"Naïve\"),\n  get_acc(snaive_forecast, \"SNaïve\"),\n  get_acc(drift_forecast, \"Drift\"),\n  get_acc(arima_forecast, \"ARIMA\")\n)\n\nacc_df &lt;- dplyr::bind_rows(acc_list)\n\nacc_summary &lt;- acc_df %&gt;%\n  dplyr::select(Method, RMSE, MAE, MAPE, MASE, ACF1) %&gt;%\n  dplyr::distinct()\n\nprint(acc_summary)\n\n\n  Method      RMSE       MAE      MAPE      MASE        ACF1\n1   Mean 37465.944 31034.916 39.069482 3.8842614  0.91669955\n2  Naïve 14436.325 11248.988 11.692600 1.4078985  0.35515252\n3 SNaïve 10136.920  7989.914  8.353621 1.0000000  0.71789508\n4  Drift 14430.419 11232.898 11.682334 1.4058847  0.35515252\n5  ARIMA  5276.948  4146.816  4.555594 0.5190063 -0.06335833"
  }
]